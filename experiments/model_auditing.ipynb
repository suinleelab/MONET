{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(os.path.abspath(\"compare_manual-230410.ipynb\"), pythonpath=True)\n",
    "import os\n",
    "\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ed405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import tqdm\n",
    "from IPython import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b56d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /System/Library/Fonts/Supplemental ~/.local/share/fonts/\n",
    "# rm -fr ~/.cache/matplotlib\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.edgecolor']='1.0'\n",
    "plt.rcParams['legend.framealpha']=0\n",
    "\n",
    "# https://github.com/dsc/colorbrewer-python/blob/master/colorbrewer.py\n",
    "\n",
    "Set1 = {\n",
    "    3: [[228,26,28], [55,126,184], [77,175,74]],\n",
    "    4: [[228,26,28], [55,126,184], [77,175,74], [152,78,163]],\n",
    "    5: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0]],\n",
    "    6: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51]],\n",
    "    7: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40]],\n",
    "    8: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191]],\n",
    "    9: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191], [153,153,153]],\n",
    "}\n",
    "\n",
    "Paired = {\n",
    "    3: [(166,206,227), [31,120,180], [178,223,138]],\n",
    "    4: [[166,206,227], [31,120,180], [178,223,138], [51,160,44]],\n",
    "    5: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153]],\n",
    "    6: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28]],\n",
    "    7: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111]],\n",
    "    8: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0]],\n",
    "    9: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214]],\n",
    "    10: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154]],\n",
    "    11: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153]],\n",
    "    12: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153], [177,89,40]]\n",
    "}\n",
    "\n",
    "color_qual_7=['#F53345',\n",
    "            '#87D303',\n",
    "            '#04CBCC',\n",
    "            '#8650CD',\n",
    "            (160/256, 95/256, 0),\n",
    "            '#F5A637',              \n",
    "            '#DBD783',            \n",
    "             ]\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb738447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "import tqdm.contrib.concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MONET.datamodules.multiplex_datamodule import MultiplexDatamodule\n",
    "from MONET.utils.loader import custom_collate_per_key, dataloader_apply_func\n",
    "from MONET.utils.metrics import skincon_calcualte_auc_all\n",
    "from MONET.utils.static import (\n",
    "    concept_to_prompt,\n",
    "    fitzpatrick17k_disease_label,\n",
    "    fitzpatrick17k_ninelabel,\n",
    "    fitzpatrick17k_threelabel,\n",
    "    skincon_cols,\n",
    ")\n",
    "from MONET.utils.text_processing import generate_prompt_token_from_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7824f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_to_exppath(wandb, log_path=\"/gscratch/cse/chanwkim/MONET_log/train/runs\"):\n",
    "    log_path = Path(log_path)\n",
    "    for experiment in os.listdir(log_path):\n",
    "        if os.path.exists(log_path / experiment / \"wandb\"):\n",
    "            filenames = os.listdir(log_path / experiment / \"wandb\")\n",
    "            filename = [filename for filename in filenames if filename.startswith(\"run\")][0][-8:]\n",
    "            if filename == wandb:\n",
    "                return log_path / experiment\n",
    "    raise RuntimeError(\"not found\")\n",
    "\n",
    "\n",
    "exppath = wandb_to_exppath(\n",
    "    wandb=\"baqqmm5v\", log_path=\"/projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs\"\n",
    ")\n",
    "print([exppath / \"checkpoints\" / ckpt for ckpt in os.listdir(exppath / \"checkpoints/\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataloader(dataset_name):    \n",
    "    if dataset_name==\"clinical_fd_clean_nodup_nooverlap\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"clinical_fd_clean_nodup_nooverlap=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()  \n",
    "        \n",
    "    elif dataset_name==\"derm7pt_derm_nodup\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"derm7pt_derm_nodup=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()    \n",
    "        \n",
    "    elif dataset_name==\"derm7pt_clinical_nodup\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"derm7pt_clinical_nodup=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()   \n",
    "        \n",
    "    elif dataset_name==\"derm7pt\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"derm7pt=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()\n",
    "        \n",
    "    elif dataset_name==\"allpubmedtextbook\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"pubmed=all,textbook=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()\n",
    "        \n",
    "        dataloader = dm.test_dataloader()          \n",
    "    \n",
    "    elif dataset_name==\"isic_nodup_nooverlap\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"isic_nodup_nooverlap=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader() \n",
    "        \n",
    "    elif dataset_name==\"proveai\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"proveai=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()         \n",
    "        \n",
    "    return {\"dataloader\": dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1025d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    variable_dict.setdefault(dataset_name, {})\n",
    "    variable_dict[dataset_name].update(setup_dataloader(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32959de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1407964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zt0n2xd0\"\n",
    "model_device = \"cuda:5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"contrastive.yaml\")\n",
    "cfg_model.net.model_name_or_path = \"ViT-L/14\"\n",
    "cfg_model.net.device = model_device\n",
    "cfg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hydra.utils.instantiate(cfg_model)\n",
    "model.to(model_device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03460efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_dir = {\n",
    "    \"zt0n2xd0\": \"logs/train/runs/2023-01-17_20-58-15/checkpoints/last.ckpt\",\n",
    "}\n",
    "if model_name != \"ViT-L/14\":\n",
    "    model_path = model_path_dir[model_name]\n",
    "    loaded = torch.load(model_path, map_location=model_device)\n",
    "    model.load_state_dict(loaded[\"state_dict\"])\n",
    "    print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zt0n2xd0\"\n",
    "model_device = \"cuda:5\"\n",
    "\n",
    "cfg_model = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"contrastive.yaml\")\n",
    "cfg_model.net.model_name_or_path = \"ViT-L/14\"\n",
    "cfg_model.net.device = model_device\n",
    "cfg_model\n",
    "\n",
    "model_vanilla = hydra.utils.instantiate(cfg_model)\n",
    "model_vanilla.to(model_device)\n",
    "model_vanilla.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b73529",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb07842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"contrastive.yaml\")\n",
    "cfg_model.net.model_name_or_path = \"ViT-L/14\"\n",
    "cfg_model.net.device = \"cpu\"\n",
    "cfg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hydra.utils.instantiate(cfg_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecde544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_dir = {\n",
    "    \"zt0n2xd0\": \"logs/train/runs/2023-01-17_20-58-15/checkpoints/last.ckpt\",\n",
    "}\n",
    "if model_name != \"ViT-L/14\":\n",
    "    model_path = model_path_dir[model_name]\n",
    "    loaded = torch.load(model_path, map_location=model_device)\n",
    "    model.load_state_dict(loaded[\"state_dict\"])\n",
    "    print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test, preprocess_test = clip.load(\"ViT-L/14\", device=\"cpu\", jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07791d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_weights=model_loaded.net.model.state_dict()\n",
    "model_test.load_state_dict(clip_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d172ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clip_weights, \"logs/train/runs/2023-01-17_20-58-15/checkpoints/last_clip.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b02988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs/2023-01-17_20-58-15/checkpoints/last_clip.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_weights_=torch.load(\"/projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs/2023-01-17_20-58-15/checkpoints/last_clip.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb88bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_weights[\"visual.transformer.resblocks.1.ln_2.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_weights_[\"visual.transformer.resblocks.1.ln_2.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb195a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_feautures_test=model_test.encode_image(\n",
    "        variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"dataloader\"].dataset[1][\"image\"].unsqueeze(0)\n",
    "                                                )\n",
    "    image_features=model.model_step_with_image({\"image\": variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"dataloader\"].dataset[1][\"image\"].unsqueeze(0)})\n",
    "    \n",
    "    assert (image_feautures_test==image_features[\"image_features\"]).all()\n",
    "    \n",
    "    text_feautures_test=model_test.encode_text(clip.tokenize([\"This is a diagram\"]))\n",
    "    \n",
    "    text_features=model.model_step_with_text({\"text\": clip.tokenize([\"This is a diagram\"])})\n",
    "    \n",
    "    assert (text_feautures_test==text_features[\"text_features\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da347a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4320d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e50fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77dcc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feautures_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(text_feautures_test==text_features[\"text_features\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a04a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443d0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b999050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_step_with_image??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7de3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feautures_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"dataloader\"].dataset[1][\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369296e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda95b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f908c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa95d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1505d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh logs/train/runs/2023-01-17_20-58-15/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85387028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dceae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://aimslab.cs.washington.edu/MONET/weight.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_test=torch.load(\"weight.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e00c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ee8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e07fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72facd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b77821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ee839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_func(batch):\n",
    "    with torch.no_grad():\n",
    "        batch[\"image\"] = batch[\"image\"].to(model_device)\n",
    "        image_features = model.model_step_with_image(batch)[\"image_features\"]\n",
    "        image_features_vanilla = model_vanilla.model_step_with_image(batch)[\"image_features\"]\n",
    "    # print(batch[\"metadata\"])\n",
    "    return {\n",
    "        \"image_features\": image_features.detach().cpu(),\n",
    "        \"image_features_vanilla\": image_features_vanilla.detach().cpu(),\n",
    "        \"metadata\": batch[\"metadata\"],\n",
    "    }\n",
    "\n",
    "def setup_features(dataset_name, dataloader):\n",
    "    if dataset_name==\"isic_nodup_nooverlap\":\n",
    "        loader_applied = torch.load(log_dir/\"image_features\"/\"isic_nodup_nooverlap.pt\", map_location=\"cpu\")\n",
    "        image_features = loader_applied[\"image_features\"].cpu()\n",
    "        metadata_all = loader_applied[\"metadata_all\"]\n",
    "\n",
    "        return {\"image_features\":image_features, \n",
    "#                 \"image_features_vanilla\":image_features_vanilla,\n",
    "                \"metadata_all\": metadata_all}\n",
    "    \n",
    "    else:\n",
    "        loader_applied = dataloader_apply_func(\n",
    "            dataloader=dataloader,\n",
    "            func=batch_func,\n",
    "            collate_fn=custom_collate_per_key,\n",
    "        )\n",
    "        image_features = loader_applied[\"image_features\"].cpu()\n",
    "        image_features_vanilla = loader_applied[\"image_features_vanilla\"].cpu()\n",
    "        metadata_all = loader_applied[\"metadata\"]\n",
    "\n",
    "        return {\"image_features\":image_features, \n",
    "                \"image_features_vanilla\":image_features_vanilla,\n",
    "                \"metadata_all\": metadata_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf28403",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [ \"proveai\"\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d43022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [ \"proveai\"\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\",\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cba19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def get_layer_feature(model, feature_layer_name, image):\n",
    "    # image = self.normalize(self.toTensor(img)).unsqueeze(0).to(self.device)\n",
    "    # embedding = torch.zeros(image.shape[0], num_features, 1, 1).to(image.device)\n",
    "    feature_layer = model._modules.get(feature_layer_name)\n",
    "\n",
    "    embedding = []\n",
    "\n",
    "    def copyData(module, input, output):\n",
    "        embedding.append(output.data)\n",
    "\n",
    "    h = feature_layer.register_forward_hook(copyData)\n",
    "    out = model(image.to(image.device))\n",
    "    h.remove()\n",
    "    embedding = embedding[0]\n",
    "    assert embedding.shape[0] == image.shape[0], f\"{embedding.shape[0]} != {image.shape[0]}\"\n",
    "    assert embedding.shape[2] == 1, f\"{embedding.shape[2]} != 1\"\n",
    "    assert embedding.shape[2] == 1, f\"{embedding.shape[3]} != 1\"\n",
    "    return embedding[:, :, 0, 0]\n",
    "\n",
    "def batch_func_efficientnet(batch):\n",
    "    with torch.no_grad():\n",
    "        efficientnet_feature = get_layer_feature(\n",
    "            efficientnet, \"avgpool\", batch[\"image\"].to(efficientnet_device)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"efficientnet_feature\": efficientnet_feature.detach().cpu(),\n",
    "        \"metadata\": batch[\"metadata\"],\n",
    "    }\n",
    "\n",
    "def setup_features_efficientnet(dataset_name, dataloader):\n",
    "    loader_applied = dataloader_apply_func(\n",
    "        dataloader=dataloader,\n",
    "        func=batch_func_efficientnet,\n",
    "        collate_fn=custom_collate_per_key,\n",
    "    )\n",
    "    image_features = loader_applied[\"efficientnet_feature\"].cpu()\n",
    "\n",
    "    return {\"efficientnet_feature\":image_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ec9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_device=\"cuda:2\"\n",
    "efficientnet = torchvision.models.efficientnet_v2_s(\n",
    "    weights=torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    ").to(efficientnet_device)\n",
    "efficientnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"proveai\",\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features_efficientnet(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\",\n",
    "                    ]:\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_features_efficientnet(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b539b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc50ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_diagnosis_malignant_mapping=\\\n",
    "{'AIMP':'indeterminate',\n",
    "'acrochordon':'benign',\n",
    "'actinic keratosis':'benign', # \n",
    "'angiofibroma or fibrous papule':'benign', \n",
    "'angiokeratoma':'benign',\n",
    "'angioma':'benign',\n",
    "'atypical melanocytic proliferation':'indeterminate',\n",
    "'atypical spitz tumor':'indeterminate', #\n",
    "'basal cell carcinoma':'malignant', #\n",
    "'cafe-au-lait macule':'benign',\n",
    "'clear cell acanthoma':'benign',\n",
    "'dermatofibroma':'benign', #\n",
    "'lentigo NOS':'benign',\n",
    "'lentigo simplex':'benign',\n",
    "'lichenoid keratosis':'benign',\n",
    "'melanoma':'malignant',\n",
    "'melanoma metastasis':'malignant',\n",
    "'neurofibroma':'benign',\n",
    "'nevus':'benign',\n",
    "'other':'indeterminate',\n",
    "'pigmented benign keratosis':'benign', #??\n",
    "'scar':'benign',\n",
    "'seborrheic keratosis':'benign',\n",
    "'solar lentigo':'benign',\n",
    "'squamous cell carcinoma':'malignant',\n",
    "'vascular lesion':'benign', # \n",
    "'verruca':'benign'\n",
    "}\n",
    "\n",
    "def isic_map_diagnosis_malignant(diagnosis, benign_malignant):\n",
    "#     if diagnosis==\"basal cell carcinoma\":\n",
    "#         print(diagnosis_malignant_mapping[diagnosis], benign_malignant)    \n",
    "    if isinstance(benign_malignant, str):\n",
    "        return benign_malignant\n",
    "    elif diagnosis in isic_diagnosis_malignant_mapping.keys():\n",
    "        return isic_diagnosis_malignant_mapping[diagnosis]\n",
    "    elif np.isnan(diagnosis):\n",
    "        return \"indeterminate\"\n",
    "    else:\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "derm7pt_diagnosis_malignant_mapping=\\\n",
    "{   'basal cell carcinoma':'malignant', \n",
    "    'blue nevus': 'benign', #\n",
    "    'clark nevus':'benign', # \n",
    "    'combined nevus': 'benign', #\n",
    "    'congenital nevus': 'benign', #\n",
    "    'dermal nevus': 'benign', \n",
    "    'dermatofibroma':'benign', \n",
    "    'lentigo': 'benign',\n",
    "    'melanoma (in situ)': 'malignant',\n",
    "    'melanoma (less than 0.76 mm)': 'malignant',\n",
    "    'melanoma (0.76 to 1.5 mm)': 'malignant',\n",
    "    'melanoma (more than 1.5 mm)': 'malignant',\n",
    "    'melanoma metastasis': 'malignant',\n",
    "    'melanosis': 'benign',# \n",
    "    'miscellaneous': 'unknown', #\n",
    "    'recurrent nevus': 'benign', #\n",
    "    'reed or spitz nevus': 'benign', #\n",
    "    'seborrheic keratosis':'benign',\n",
    "    'vascular lesion': 'benign', \n",
    "    'melanoma': 'malignant',\n",
    "}\n",
    "\n",
    "def derm7pt_map_diagnosis_malignant(diagnosis):\n",
    "#     if diagnosis==\"basal cell carcinoma\":\n",
    "#         print(diagnosis_malignant_mapping[diagnosis], benign_malignant)    \n",
    "    if diagnosis in derm7pt_diagnosis_malignant_mapping.keys():\n",
    "        return derm7pt_diagnosis_malignant_mapping[diagnosis]\n",
    "    elif np.isnan(diagnosis):\n",
    "        return \"indeterminate\"\n",
    "    else:\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdd666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2924de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config(dataset_name, metadata_all):\n",
    "    if \"clinical_fd_clean\" in dataset_name:\n",
    "        y_pos=(((metadata_all[\"source\"]==\"fitz\")&(metadata_all[\"three_partition_label\"]==\"malignant\"))|\n",
    "              ((metadata_all[\"source\"]==\"ddi\")&(metadata_all[\"malignant\"] == True))).values\n",
    "        \n",
    "        valid_idx=(metadata_all[\"skincon_Do not consider this image\"]!=1).values\n",
    "        \n",
    "        concept_list=skincon_cols\n",
    "    \n",
    "        \n",
    "    elif \"isic\" in dataset_name:  \n",
    "        metadata_all[\"benign_malignant_full\"]=\\\n",
    "        metadata_all.apply(lambda x: isic_map_diagnosis_malignant(x[\"diagnosis\"], x[\"benign_malignant\"]), axis=1)\n",
    "        #metadata_all[\"benign_malignant_full\"].value_counts()\n",
    "        #metadata_all.groupby(\"diagnosis\").apply(lambda x: x[\"benign_malignant_full\"].value_counts())\n",
    "        metadata_all[\"benign_malignant_bool\"]=metadata_all[\"benign_malignant_full\"].str.contains(\"malignant\")\n",
    "        \n",
    "        y_pos=metadata_all[\"benign_malignant_bool\"].values\n",
    "        \n",
    "        valid_idx = (metadata_all[\"benign_malignant_full\"].str.contains(\"malignant\")|metadata_all[\"benign_malignant_full\"].str.contains(\"benign\")).values\n",
    "        \n",
    "        \n",
    "        concept_list=skincon_cols\n",
    "        \n",
    "        concept_list=concept_list+\\\n",
    "                            [\"purple pen\", \n",
    "                             \"finger\", \n",
    "                             \"nail\", \n",
    "                             \"pinkish\", \n",
    "                             \"red\", \n",
    "                             \"hair\", \n",
    "                             \"orange sticker\", \n",
    "                             \"blue sticker\", \n",
    "                             \"red sticker\",\n",
    "                             \"dermoscope border\",\n",
    "                             \"gel\",\n",
    "                             \"malignant\",\n",
    "                             \"melanoma\"]      \n",
    "        \n",
    "        \n",
    "        concept_list=concept_list+[f\"derm7ptconcept_{derm7ptconcept}\" for derm7ptconcept in [\"pigment network\", \"typical pigment network\", \"atypical pigment network\",\n",
    "                                   \"regression structure\",\n",
    "                                   \"pigmentation\", \"regular pigmentation\", \"irregular pigmentation\",\n",
    "                                   \"blue whitish veil\", \n",
    "                                   \"vascular structures\", \"typical vascular structures\", \"atypical vascular structures\",\n",
    "                                   \"streaks\", \"regular streaks\", \"irregular streaks\",\n",
    "                                   \"dots and globules\", \"regular dots and globules\", \"irregular dots and globules\",\n",
    "                                  ]]\n",
    "        \n",
    "        concept_list=concept_list+[f\"isicconcept_{isicconcept}\" for isicconcept in [\"pigment_network\", \n",
    "                                                                                   \"negative_network\",\n",
    "                                                                                   \"milia_like_cyst\", \n",
    "                                                                                   \"streaks\", \n",
    "                                                                                   \"globules\"]]\n",
    "        \n",
    "        concept_list=concept_list+[f\"disease_{disease_name}\" for disease_name in ['seborrheic keratosis', 'nevus', 'squamous cell carcinoma',\n",
    "                        'melanoma', 'lichenoid keratosis', 'lentigo',\n",
    "                        'actinic keratosis', 'basal cell carcinoma', 'dermatofibroma',\n",
    "                        'atypical melanocytic proliferation', 'verruca',\n",
    "                        'clear cell acanthoma', 'angiofibroma or fibrous papule', 'scar',\n",
    "                        'angioma', 'atypical spitz tumor', 'solar lentigo', 'AIMP',\n",
    "                        'neurofibroma', 'lentigo simplex', 'acrochordon', \n",
    "                        'angiokeratoma', 'vascular lesion', 'cafe-au-lait macule',\n",
    "                        'pigmented benign keratosis']]\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif \"proveai\" in dataset_name:  \n",
    "        metadata_all\n",
    "        \n",
    "        prove_logits_true=pd.read_csv(\"data/proveai/isic_upd_rev.csv\",index_col=0).rename(columns={\"truth\": \"y_pos\"})\n",
    "        \n",
    "        y_pos=prove_logits_true.set_index(\"image_name\")[\"y_pos\"].loc[metadata_all.index].values\n",
    "        \n",
    "#         y_pos=prove_logits_true.set_index(\"image_name\")[\"target\"].loc[metadata_all.index]>0.05\n",
    "        \n",
    "        valid_idx = ~np.isnan(y_pos)\n",
    "        \n",
    "        \n",
    "        concept_list=skincon_cols\n",
    "        \n",
    "        concept_list=concept_list+\\\n",
    "                            [\"purple pen\", \n",
    "                             \"finger\", \n",
    "                             \"nail\", \n",
    "                             \"pinkish\", \n",
    "                             \"red\", \n",
    "                             \"hair\", \n",
    "                             \"orange sticker\", \n",
    "                             \"blue sticker\", \n",
    "                             \"red sticker\",\n",
    "                             \"dermoscope border\",\n",
    "                             \"gel\",\n",
    "                             \"malignant\",\n",
    "                             \"melanoma\"]      \n",
    "        \n",
    "        \n",
    "        concept_list=concept_list+[f\"derm7ptconcept_{derm7ptconcept}\" for derm7ptconcept in [\"pigment network\", \"typical pigment network\", \"atypical pigment network\",\n",
    "                                   \"regression structure\",\n",
    "                                   \"pigmentation\", \"regular pigmentation\", \"irregular pigmentation\",\n",
    "                                   \"blue whitish veil\", \n",
    "                                   \"vascular structures\", \"typical vascular structures\", \"atypical vascular structures\",\n",
    "                                   \"streaks\", \"regular streaks\", \"irregular streaks\",\n",
    "                                   \"dots and globules\", \"regular dots and globules\", \"irregular dots and globules\",\n",
    "                                  ]]\n",
    "        \n",
    "        concept_list=concept_list+[f\"isicconcept_{isicconcept}\" for isicconcept in [\"pigment_network\", \n",
    "                                                                                   \"negative_network\",\n",
    "                                                                                   \"milia_like_cyst\", \n",
    "                                                                                   \"streaks\", \n",
    "                                                                                   \"globules\"]]\n",
    "        \n",
    "        concept_list=concept_list+[f\"disease_{disease_name}\" for disease_name in ['seborrheic keratosis', 'nevus', 'squamous cell carcinoma',\n",
    "                        'melanoma', 'lichenoid keratosis', 'lentigo',\n",
    "                        'actinic keratosis', 'basal cell carcinoma', 'dermatofibroma',\n",
    "                        'atypical melanocytic proliferation', 'verruca',\n",
    "                        'clear cell acanthoma', 'angiofibroma or fibrous papule', 'scar',\n",
    "                        'angioma', 'atypical spitz tumor', 'solar lentigo', 'AIMP',\n",
    "                        'neurofibroma', 'lentigo simplex', 'acrochordon', \n",
    "                        'angiokeratoma', 'vascular lesion', 'cafe-au-lait macule',\n",
    "                        'pigmented benign keratosis']]        \n",
    "        \n",
    "    elif \"derm7pt\" in dataset_name:  \n",
    "        metadata_all[\"benign_malignant_full\"]=\\\n",
    "        metadata_all.apply(lambda x: derm7pt_map_diagnosis_malignant(x[\"diagnosis\"]), axis=1)\n",
    "        metadata_all[\"benign_malignant_bool\"]=metadata_all[\"benign_malignant_full\"].str.contains(\"malignant\")\n",
    "        \n",
    "        y_pos=metadata_all[\"benign_malignant_bool\"].values\n",
    "        \n",
    "        valid_idx = (~metadata_all[\"diagnosis\"].isnull()).values\n",
    "        \n",
    "        concept_list=skincon_cols\n",
    "        \n",
    "        concept_list=concept_list+\\\n",
    "                            [\"purple pen\", \n",
    "                             \"finger\", \n",
    "                             \"nail\", \n",
    "                             \"pinkish\", \n",
    "                             \"red\", \n",
    "                             \"hair\", \n",
    "                             \"orange sticker\", \n",
    "                             \"blue sticker\", \n",
    "                             \"red sticker\",\n",
    "                             \"dermoscope border\",\n",
    "                             \"gel\",\n",
    "                             \"malignant\",\n",
    "                             \"melanoma\"]        \n",
    "        \n",
    "        concept_list=concept_list+[f\"derm7ptconcept_{derm7ptconcept}\" for derm7ptconcept in [\"pigment network\", \"typical pigment network\", \"atypical pigment network\",\n",
    "                                   \"regression structure\",\n",
    "                                   \"pigmentation\", \"regular pigmentation\", \"irregular pigmentation\",\n",
    "                                   \"blue whitish veil\", \n",
    "                                   \"vascular structures\", \"typical vascular structures\", \"atypical vascular structures\",\n",
    "                                   \"streaks\", \"regular streaks\", \"irregular streaks\",\n",
    "                                   \"dots and globules\", \"regular dots and globules\", \"irregular dots and globules\",\n",
    "                                  ]]\n",
    "        \n",
    "        concept_list=concept_list+[f\"isicconcept_{isicconcept}\" for isicconcept in [\"pigment_network\", \n",
    "                                                                                   \"negative_network\",\n",
    "                                                                                   \"milia_like_cyst\", \n",
    "                                                                                   \"streaks\", \n",
    "                                                                                   \"globules\"]]\n",
    "             \n",
    "        \n",
    "        concept_list=concept_list+[f\"disease_{disease_name}\" for disease_name in ['basal cell carcinoma', 'blue nevus', 'clark nevus',\n",
    "                                                               'combined nevus', 'congenital nevus', 'dermal nevus',\n",
    "                                                               'dermatofibroma', 'lentigo', 'melanoma', 'melanosis',\n",
    "                                                                'recurrent nevus', 'reed or spitz nevus',\n",
    "                                                               'seborrheic keratosis', 'vascular lesion']]   \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    return {\"valid_idx\": valid_idx,\n",
    "            \"y_pos\": y_pos,\n",
    "            \"metadata_all\": metadata_all,\n",
    "            \"concept_list\": concept_list}\n",
    "\n",
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\"]:\n",
    "    variable_dict[dataset_name].update(\n",
    "        set_config(dataset_name, variable_dict[dataset_name][\"metadata_all\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/proveai/isic_upd.csv\", index_col=0)#.rename(columns={\"truth\": \"y_pos\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e07e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/proveai/isic_upd_rev.csv\", index_col=0)#.rename(columns={\"truth\": \"y_pos\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bd3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true=pd.read_csv(\"data/proveai/isic_upd_rev.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    variable_dict[dataset_name].update(\n",
    "        set_config(dataset_name, variable_dict[dataset_name][\"metadata_all\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb105d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embedding(dataset_name, image_features):\n",
    "    #prompt_ref_tokenized = clip.tokenize(prompt_ref, truncate=True)\n",
    "    #output = model.model_step_with_text({\"text\": prompt_ref_tokenized.to(model_device)})\n",
    "    #prompt_ref_embedding=output[\"text_features\"].detach().cpu()\n",
    "    #prompt_ref_embedding_norm=prompt_ref_embedding/prompt_ref_embedding.norm(dim=1, keepdim=True)      \n",
    "    \n",
    "    image_features_norm = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    return {\"image_features_norm\": image_features_norm}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    if (\"clinical_fd_clean\" in dataset_name) or (\"derm7pt\" in dataset_name):\n",
    "        variable_dict[dataset_name].update(\n",
    "            {\"image_features_vanilla_norm\":normalize_embedding(dataset_name, \n",
    "                            variable_dict[dataset_name][\"image_features_vanilla\"])[\"image_features_norm\"]}\n",
    "        )           \n",
    "    variable_dict[dataset_name].update(\n",
    "        {\"image_features_norm\":normalize_embedding(dataset_name, \n",
    "                        variable_dict[dataset_name][\"image_features\"])[\"image_features_norm\"]}\n",
    "    )  \n",
    "#     variable_dict[dataset_name].update(\n",
    "#         {\"image_features_vanilla_norm\":normalize_embedding(dataset_name, \n",
    "#                         variable_dict[dataset_name][\"image_features_vanilla\"])[\"image_features_norm\"]}\n",
    "#     )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [ \"proveai\"\n",
    "                    ]:\n",
    "    if (\"clinical_fd_clean\" in dataset_name) or (\"derm7pt\" in dataset_name):\n",
    "        variable_dict[dataset_name].update(\n",
    "            {\"image_features_vanilla_norm\":normalize_embedding(dataset_name, \n",
    "                            variable_dict[dataset_name][\"image_features_vanilla\"])[\"image_features_norm\"]}\n",
    "        )           \n",
    "    variable_dict[dataset_name].update(\n",
    "        {\"image_features_norm\":normalize_embedding(dataset_name, \n",
    "                        variable_dict[dataset_name][\"image_features\"])[\"image_features_norm\"]}\n",
    "    )  \n",
    "#     variable_dict[dataset_name].update(\n",
    "#         {\"image_features_vanilla_norm\":normalize_embedding(dataset_name, \n",
    "#                         variable_dict[dataset_name][\"image_features_vanilla\"])[\"image_features_norm\"]}\n",
    "#     )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5413c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_embedding(dataset_name, concept_list, clip_model):\n",
    "    prompt_info={}\n",
    "    \n",
    "    for concept_name in concept_list:\n",
    "        if \"clinical_fd_clean\" in dataset_name:\n",
    "            prompt_dict, text_counter = concept_to_prompt(concept_name[8:])\n",
    "            prompt_engineered_list = []\n",
    "            for k, v in prompt_dict.items():\n",
    "                if k != \"original\":\n",
    "                    prompt_engineered_list += v    \n",
    "            concept_term_list = list(set([prompt.replace(\"This is \", \"\").replace(\"This photo is \", \"\").replace(\"This lesion is \", \"\").replace(\"skin has become \", \"\").lower()\n",
    "                                      for prompt in prompt_engineered_list]))\n",
    "            prompt_template_list=[\"This is skin image of {}\", \"This is dermatology image of {}\", \"This is image of {}\"]\n",
    "            #prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]            \n",
    "            prompt_target=[[prompt_template.format(term) for term in concept_term_list] for prompt_template in prompt_template_list]\n",
    "            \n",
    "            prompt_ref = [[\"This is skin image\"], [\"This is dermatology image\"], [\"This is image\"]]        \n",
    "        \n",
    "        elif \"isic\" in dataset_name:\n",
    "            if concept_name.startswith(\"skincon_\"):\n",
    "                prompt_dict, text_counter = concept_to_prompt(concept_name[8:])\n",
    "                prompt_engineered_list = []\n",
    "                for k, v in prompt_dict.items():\n",
    "                    if k != \"original\":\n",
    "                        prompt_engineered_list += v\n",
    "\n",
    "                concept_term_list = list(set([prompt.replace(\"This is \", \"\").replace(\"This photo is \", \"\").replace(\"This lesion is \", \"\").replace(\"skin has become \", \"\").lower()\n",
    "                                          for prompt in prompt_engineered_list]))\n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                prompt_ref = [\"This is dermatoscopy\", \"This is dermoscopy\"]\n",
    "                prompt_target=[[prompt_template.format(term) for term in concept_term_list] for prompt_template in prompt_template_list]\n",
    "                prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]] \n",
    "                \n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]] \n",
    "                \n",
    "                \n",
    "            elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "                derm7ptconcept=concept_name[15:]\n",
    "                if derm7ptconcept==\"pigment network\":\n",
    "                    concept_term_list=[\"pigment network\", \"brown lines forming a grid-like reticular pattern\"]\n",
    "                    concept_term_list=[\"pigment network\", \"intersecting brown lines\"]\n",
    "                elif derm7ptconcept==\"typical pigment network\":\n",
    "                    concept_term_list=[\"typical pigment network\", \"regularly meshed pigment network\",]\n",
    "                elif derm7ptconcept==\"atypical pigment network\":\n",
    "#                     concept_term_list=[\"pigment network\", \"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                    #concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\", \"branched streaks\"]\n",
    "                    concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                elif derm7ptconcept==\"regression structure\":\n",
    "                    concept_term_list=[\"regression structure\"]\n",
    "                elif derm7ptconcept==\"pigmentation\":\n",
    "#                     concept_term_list=[\"pigmented\", \"pigmented lesion\"]\n",
    "                    concept_term_list=[\"pigmented\", \"pigmented lesion\", \"colored lesion\"]    \n",
    "                elif derm7ptconcept==\"regular pigmentation\":\n",
    "                    concept_term_list=[\"regular pigmentation\", \"uniform and consistent coloration\"]\n",
    "                elif derm7ptconcept==\"irregular pigmentation\":\n",
    "                    concept_term_list=[\"irregular pigmentation\"]\n",
    "                elif derm7ptconcept==\"blue whitish veil\":\n",
    "                    concept_term_list=[\"blue whitish veil\",\"blue white veil\"]\n",
    "                elif derm7ptconcept==\"vascular structures\":\n",
    "                    concept_term_list=[\"vascular structures\"]\n",
    "                    concept_term_list=[\"vascular structures\", \"Hairpin vessels\", \"Comma vessels\", \"dotted vessels\", \"arborizing vessels\"]\n",
    "                elif derm7ptconcept==\"typical vascular structures\":\n",
    "                    concept_term_list=[\"typical vascular structures\"]\n",
    "                elif derm7ptconcept==\"atypical vascular structures\":\n",
    "                    concept_term_list=[\"atypical vascular structures\"]\n",
    "                elif derm7ptconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif derm7ptconcept==\"regular streaks\":\n",
    "                    concept_term_list=[\"regular streaks\", \"uniformly spaced linear patterns\"]\n",
    "                elif derm7ptconcept==\"irregular streaks\":\n",
    "                    concept_term_list=[\"irregular streaks\"]\n",
    "                elif derm7ptconcept==\"dots and globules\":\n",
    "                    #concept_term_list=[\"dots and globules\", \"tiny, pinpoint pigmented specks\", \"Small, darkly pigmented dots\"]\n",
    "                    concept_term_list=[\"tiny dots\", \"globules\", \"dot clusters\", \"globule clusters\"]\n",
    "                    concept_term_list=[\"dots and globules\", \"scattered globules\"]#, \"dots and globules clusters\"] 0.57\n",
    "                    concept_term_list=[\"black dots and globules\", \"brown dots and globules\", \"scattered globules\"] #0.\n",
    "                elif derm7ptconcept==\"regular dots and globules\":\n",
    "                    concept_term_list=[\"regular dots and globules\"]\n",
    "                elif derm7ptconcept==\"irregular dots and globules\":\n",
    "                    concept_term_list=[\"irregular dots and globules\"]\n",
    "                else:\n",
    "                    raise ValueError(derm7ptconcept)         \n",
    "                    \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]]                     \n",
    "                \n",
    "            elif concept_name.startswith(\"isicconcept_\"):\n",
    "                isicconcept=concept_name[12:]\n",
    "                if isicconcept==\"pigment_network\":\n",
    "                    concept_term_list=[\"pigment network\"]\n",
    "                elif isicconcept==\"negative_network\":\n",
    "                    concept_term_list=[\"negative network\"]\n",
    "                elif isicconcept==\"milia_like_cyst\":\n",
    "                    concept_term_list=[\"milia like cyst\"]\n",
    "                    concept_term_list=[\"seborrheic keratosis\"]\n",
    "                elif isicconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif isicconcept==\"globules\":\n",
    "                    concept_term_list=[\"globules\"]\n",
    "                else:\n",
    "                    raise ValueError(isicconcept)                \n",
    "            \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]]                 \n",
    "                \n",
    "            elif concept_name.startswith(\"disease_\"):  \n",
    "                if concept_name==\"disease_AIMP\":\n",
    "                    disease_name=concept_name[8:]\n",
    "                    prompt_target=[[\"This is dermatoscopy of AIMP\",\n",
    "                                    \"This is dermatoscopy of Atypical intraepidermal melanocytic proliferation\"],\n",
    "                                   [\"This is dermoscopy of AIMP\",\n",
    "                                    \"This is dermoscopy of Atypical intraepidermal melanocytic proliferation\"]]\n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                else:\n",
    "                    disease_name=concept_name[8:]\n",
    "                    prompt_target=[[f\"This is dermatoscopy of {disease_name}\"],\n",
    "                                   [f\"This is dermoscopy of {disease_name}\"]] \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                \n",
    "            else:\n",
    "                if concept_name==\"gel\":\n",
    "                    #concept_term_list=[\"water drop\", 'gel', \"fluid\"]\n",
    "                    prompt_target=[[\"This is dermatoscopy of water drop\", \"This is dermatoscopy of gel\", \"This is dermatoscopy of dermoscopy liquid\"],\n",
    "                                   [\"This is dermoscopy of water drop\", \"This is dermoscopy of gel\", \"This is dermoscopy of dermoscopy liquid\"],\n",
    "                                  ]\n",
    "                    prompt_target=[[\"This is dermatoscopy of gel\"],\n",
    "                                   [\"This is dermoscopy of gel\"],\n",
    "                                  ]                    \n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], \n",
    "                                  [\"This is dermoscopy\"]]\n",
    "                elif concept_name==\"dermoscope border\":\n",
    "                    concept_term_list=[\"dermoscope\"]\n",
    "                    prompt_target=[\"This is hole\"]\n",
    "                    prompt_target=[\"This is scope hole\", \"This is circle\", \"This is dermoscope\"]\n",
    "                    #prompt_target=[[\"This is dermatoscopy of dermoscope\", \"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_target=[[\"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_ref = [[\"This is dermatoscopy\"]]\n",
    "                    \n",
    "                else:\n",
    "                    concept_term_list=[concept_name]\n",
    "                    prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                    prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                    \n",
    "                    \n",
    "        elif \"proveai\" in dataset_name:\n",
    "            if concept_name.startswith(\"skincon_\"):\n",
    "                prompt_dict, text_counter = concept_to_prompt(concept_name[8:])\n",
    "                prompt_engineered_list = []\n",
    "                for k, v in prompt_dict.items():\n",
    "                    if k != \"original\":\n",
    "                        prompt_engineered_list += v\n",
    "\n",
    "                concept_term_list = list(set([prompt.replace(\"This is \", \"\").replace(\"This photo is \", \"\").replace(\"This lesion is \", \"\").replace(\"skin has become \", \"\").lower()\n",
    "                                          for prompt in prompt_engineered_list]))\n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                prompt_ref = [\"This is dermatoscopy\", \"This is dermoscopy\"]\n",
    "                prompt_target=[[prompt_template.format(term) for term in concept_term_list] for prompt_template in prompt_template_list]\n",
    "                prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]] \n",
    "                \n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]] \n",
    "                \n",
    "                \n",
    "            elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "                derm7ptconcept=concept_name[15:]\n",
    "                if derm7ptconcept==\"pigment network\":\n",
    "                    concept_term_list=[\"pigment network\", \"brown lines forming a grid-like reticular pattern\"]\n",
    "                    concept_term_list=[\"pigment network\", \"intersecting brown lines\"]\n",
    "                elif derm7ptconcept==\"typical pigment network\":\n",
    "                    concept_term_list=[\"typical pigment network\", \"regularly meshed pigment network\",]\n",
    "                elif derm7ptconcept==\"atypical pigment network\":\n",
    "#                     concept_term_list=[\"pigment network\", \"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                    #concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\", \"branched streaks\"]\n",
    "                    concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                elif derm7ptconcept==\"regression structure\":\n",
    "                    concept_term_list=[\"regression structure\"]\n",
    "                elif derm7ptconcept==\"pigmentation\":\n",
    "#                     concept_term_list=[\"pigmented\", \"pigmented lesion\"]\n",
    "                    concept_term_list=[\"pigmented\", \"pigmented lesion\", \"colored lesion\"]    \n",
    "                elif derm7ptconcept==\"regular pigmentation\":\n",
    "                    concept_term_list=[\"regular pigmentation\", \"uniform and consistent coloration\"]\n",
    "                elif derm7ptconcept==\"irregular pigmentation\":\n",
    "                    concept_term_list=[\"irregular pigmentation\"]\n",
    "                elif derm7ptconcept==\"blue whitish veil\":\n",
    "                    concept_term_list=[\"blue whitish veil\",\"blue white veil\"]\n",
    "                elif derm7ptconcept==\"vascular structures\":\n",
    "                    concept_term_list=[\"vascular structures\"]\n",
    "                    concept_term_list=[\"vascular structures\", \"Hairpin vessels\", \"Comma vessels\", \"dotted vessels\", \"arborizing vessels\"]\n",
    "                elif derm7ptconcept==\"typical vascular structures\":\n",
    "                    concept_term_list=[\"typical vascular structures\"]\n",
    "                elif derm7ptconcept==\"atypical vascular structures\":\n",
    "                    concept_term_list=[\"atypical vascular structures\"]\n",
    "                elif derm7ptconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif derm7ptconcept==\"regular streaks\":\n",
    "                    concept_term_list=[\"regular streaks\", \"uniformly spaced linear patterns\"]\n",
    "                elif derm7ptconcept==\"irregular streaks\":\n",
    "                    concept_term_list=[\"irregular streaks\"]\n",
    "                elif derm7ptconcept==\"dots and globules\":\n",
    "                    #concept_term_list=[\"dots and globules\", \"tiny, pinpoint pigmented specks\", \"Small, darkly pigmented dots\"]\n",
    "                    concept_term_list=[\"tiny dots\", \"globules\", \"dot clusters\", \"globule clusters\"]\n",
    "                    concept_term_list=[\"dots and globules\", \"scattered globules\"]#, \"dots and globules clusters\"] 0.57\n",
    "                    concept_term_list=[\"black dots and globules\", \"brown dots and globules\", \"scattered globules\"] #0.\n",
    "                elif derm7ptconcept==\"regular dots and globules\":\n",
    "                    concept_term_list=[\"regular dots and globules\"]\n",
    "                elif derm7ptconcept==\"irregular dots and globules\":\n",
    "                    concept_term_list=[\"irregular dots and globules\"]\n",
    "                else:\n",
    "                    raise ValueError(derm7ptconcept)         \n",
    "                    \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]]                     \n",
    "                \n",
    "            elif concept_name.startswith(\"isicconcept_\"):\n",
    "                isicconcept=concept_name[12:]\n",
    "                if isicconcept==\"pigment_network\":\n",
    "                    concept_term_list=[\"pigment network\"]\n",
    "                elif isicconcept==\"negative_network\":\n",
    "                    concept_term_list=[\"negative network\"]\n",
    "                elif isicconcept==\"milia_like_cyst\":\n",
    "                    concept_term_list=[\"milia like cyst\"]\n",
    "                    concept_term_list=[\"seborrheic keratosis\"]\n",
    "                elif isicconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif isicconcept==\"globules\":\n",
    "                    concept_term_list=[\"globules\"]\n",
    "                else:\n",
    "                    raise ValueError(isicconcept)                \n",
    "            \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]]                 \n",
    "                \n",
    "            elif concept_name.startswith(\"disease_\"):  \n",
    "                if concept_name==\"disease_AIMP\":\n",
    "                    disease_name=concept_name[8:]\n",
    "                    prompt_target=[[\"This is dermatoscopy of AIMP\",\n",
    "                                    \"This is dermatoscopy of Atypical intraepidermal melanocytic proliferation\"],\n",
    "                                   [\"This is dermoscopy of AIMP\",\n",
    "                                    \"This is dermoscopy of Atypical intraepidermal melanocytic proliferation\"]]\n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                else:\n",
    "                    disease_name=concept_name[8:]\n",
    "                    prompt_target=[[f\"This is dermatoscopy of {disease_name}\"],\n",
    "                                   [f\"This is dermoscopy of {disease_name}\"]] \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                \n",
    "            else:\n",
    "                if concept_name==\"gel\":\n",
    "                    #concept_term_list=[\"water drop\", 'gel', \"fluid\"]\n",
    "                    prompt_target=[[\"This is dermatoscopy of water drop\", \"This is dermatoscopy of gel\", \"This is dermatoscopy of dermoscopy liquid\"],\n",
    "                                   [\"This is dermoscopy of water drop\", \"This is dermoscopy of gel\", \"This is dermoscopy of dermoscopy liquid\"],\n",
    "                                  ]\n",
    "                    prompt_target=[[\"This is dermatoscopy of gel\"],\n",
    "                                   [\"This is dermoscopy of gel\"],\n",
    "                                  ]                    \n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], \n",
    "                                  [\"This is dermoscopy\"]]\n",
    "                elif concept_name==\"dermoscope border\":\n",
    "                    concept_term_list=[\"dermoscope\"]\n",
    "                    prompt_target=[\"This is hole\"]\n",
    "                    prompt_target=[\"This is scope hole\", \"This is circle\", \"This is dermoscope\"]\n",
    "                    #prompt_target=[[\"This is dermatoscopy of dermoscope\", \"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_target=[[\"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_ref = [[\"This is dermatoscopy\"]]\n",
    "                    \n",
    "                else:\n",
    "                    concept_term_list=[concept_name]\n",
    "                    prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                    prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        elif \"derm7pt_derm\" in dataset_name:\n",
    "            if concept_name.startswith(\"skincon_\"):\n",
    "                prompt_dict, text_counter = concept_to_prompt(concept_name[8:])\n",
    "                prompt_engineered_list = []\n",
    "                for k, v in prompt_dict.items():\n",
    "                    if k != \"original\":\n",
    "                        prompt_engineered_list += v\n",
    "\n",
    "                concept_term_list = list(set([prompt.replace(\"This is \", \"\").replace(\"This photo is \", \"\").replace(\"This lesion is \", \"\").replace(\"skin has become \", \"\").lower()\n",
    "                                          for prompt in prompt_engineered_list]))\n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                prompt_ref = [\"This is dermatoscopy\", \"This is dermoscopy\"]\n",
    "                prompt_target=[[prompt_template.format(term) for term in concept_term_list] for prompt_template in prompt_template_list]\n",
    "                prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]] \n",
    "                \n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]] \n",
    "                \n",
    "            elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "                derm7ptconcept=concept_name[15:]\n",
    "                if derm7ptconcept==\"pigment network\":\n",
    "                    concept_term_list=[\"pigment network\", \"brown lines forming a grid-like reticular pattern\"]\n",
    "                    concept_term_list=[\"pigment network\", \"intersecting brown lines\"]\n",
    "                elif derm7ptconcept==\"typical pigment network\":\n",
    "                    concept_term_list=[\"typical pigment network\", \"regularly meshed pigment network\",]\n",
    "                elif derm7ptconcept==\"atypical pigment network\":\n",
    "#                     concept_term_list=[\"pigment network\", \"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                    #concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\", \"branched streaks\"]\n",
    "                    concept_term_list=[\"atypical pigment network\", \"irregularly meshed pigment network\"]\n",
    "                elif derm7ptconcept==\"regression structure\":\n",
    "                    concept_term_list=[\"regression structure\"]\n",
    "                elif derm7ptconcept==\"pigmentation\":\n",
    "#                     concept_term_list=[\"pigmented\", \"pigmented lesion\"]\n",
    "                    concept_term_list=[\"pigmented\", \"pigmented lesion\", \"colored lesion\"]    \n",
    "                elif derm7ptconcept==\"regular pigmentation\":\n",
    "                    concept_term_list=[\"regular pigmentation\", \"uniform and consistent coloration\"]\n",
    "                elif derm7ptconcept==\"irregular pigmentation\":\n",
    "                    concept_term_list=[\"irregular pigmentation\"]\n",
    "                elif derm7ptconcept==\"blue whitish veil\":\n",
    "                    concept_term_list=[\"blue whitish veil\", \"blue white veil\"]\n",
    "                elif derm7ptconcept==\"vascular structures\":\n",
    "                    concept_term_list=[\"vascular structures\"]\n",
    "                    concept_term_list=[\"vascular structures\", \"Hairpin vessels\", \"Comma vessels\", \"dotted vessels\", \"arborizing vessels\"]\n",
    "                elif derm7ptconcept==\"typical vascular structures\":\n",
    "                    concept_term_list=[\"typical vascular structures\"]\n",
    "                elif derm7ptconcept==\"atypical vascular structures\":\n",
    "                    concept_term_list=[\"atypical vascular structures\"]\n",
    "                elif derm7ptconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif derm7ptconcept==\"regular streaks\":\n",
    "                    concept_term_list=[\"regular streaks\", \"uniformly spaced linear patterns\"]\n",
    "                elif derm7ptconcept==\"irregular streaks\":\n",
    "                    concept_term_list=[\"irregular streaks\"]\n",
    "                elif derm7ptconcept==\"dots and globules\":\n",
    "                    #concept_term_list=[\"dots and globules\", \"tiny, pinpoint pigmented specks\", \"Small, darkly pigmented dots\"]\n",
    "                    concept_term_list=[\"tiny dots\", \"globules\", \"dot clusters\", \"globule clusters\"]\n",
    "                    concept_term_list=[\"dots and globules\", \"scattered globules\"]#, \"dots and globules clusters\"] 0.57\n",
    "                    concept_term_list=[\"black dots and globules\", \"brown dots and globules\", \"scattered globules\"] #0.\n",
    "                elif derm7ptconcept==\"regular dots and globules\":\n",
    "                    concept_term_list=[\"regular dots and globules\"]\n",
    "                elif derm7ptconcept==\"irregular dots and globules\":\n",
    "                    concept_term_list=[\"irregular dots and globules\"]\n",
    "                else:\n",
    "                    raise ValueError(derm7ptconcept)\n",
    "    \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]] \n",
    "                \n",
    "            elif concept_name.startswith(\"isicconcept_\"):\n",
    "                isicconcept=concept_name[12:]\n",
    "                if isicconcept==\"pigment_network\":\n",
    "                    concept_term_list=[\"pigment network\"]\n",
    "                elif isicconcept==\"negative_network\":\n",
    "                    concept_term_list=[\"negative network\"]\n",
    "                elif isicconcept==\"milia_like_cyst\":\n",
    "                    concept_term_list=[\"milia like cyst\"]\n",
    "                    concept_term_list=[\"seborrheic keratosis\"]\n",
    "                elif isicconcept==\"streaks\":\n",
    "                    concept_term_list=[\"streaks\", \"starburst\", \"linear patterns\", \"radially oriented linear projections\", \"regular, pigmented linear extensions\", \"irregular, pigmented linear extensions\"]\n",
    "                elif isicconcept==\"globules\":\n",
    "                    concept_term_list=[\"globules\"]\n",
    "                else:\n",
    "                    raise ValueError(isicconcept)                \n",
    "            \n",
    "                prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                prompt_target=[[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]]\n",
    "                prompt_ref = [[\"This is dermatoscopy\", \"This is dermoscopy\"]]                  \n",
    "                \n",
    "            elif concept_name.startswith(\"disease_\"):  \n",
    "                disease_name=concept_name[8:]\n",
    "                prompt_target=[[f\"This is dermatoscopy of {disease_name}\"],\n",
    "                               [f\"This is dermoscopy of {disease_name}\"]] \n",
    "                prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]\n",
    "                \n",
    "            else:\n",
    "                if concept_name==\"gel\":\n",
    "                    #concept_term_list=[\"water drop\", 'gel', \"fluid\"]\n",
    "                    prompt_target=[[\"This is dermatoscopy of water drop\", \"This is dermatoscopy of gel\", \"This is dermatoscopy of dermoscopy liquid\"],\n",
    "                                   [\"This is dermoscopy of water drop\", \"This is dermoscopy of gel\", \"This is dermoscopy of dermoscopy liquid\"],\n",
    "                                  ]\n",
    "                    prompt_target=[[\"This is dermatoscopy of gel\"],\n",
    "                                   [\"This is dermoscopy of gel\"],\n",
    "                                  ]                    \n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], \n",
    "                                  [\"This is dermoscopy\"]]\n",
    "                elif concept_name==\"dermoscope border\":\n",
    "                    concept_term_list=[\"dermoscope\"]\n",
    "                    prompt_target=[\"This is hole\"]\n",
    "                    prompt_target=[\"This is scope hole\", \"This is circle\", \"This is dermoscope\"]\n",
    "                    #prompt_target=[[\"This is dermatoscopy of dermoscope\", \"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_target=[[\"This is dermatoscopy of dermoscopy\"]]\n",
    "                    prompt_ref = [[\"This is dermatoscopy\"]]\n",
    "                    \n",
    "                else:\n",
    "                    concept_term_list=[concept_name]\n",
    "                    prompt_template_list=[\"This is dermatoscopy of {}\", \"This is dermoscopy of {}\"]\n",
    "                    prompt_target=[prompt_template.format(term) for prompt_template in prompt_template_list for term in concept_term_list]\n",
    "                    \n",
    "                    prompt_ref = [[\"This is dermatoscopy\"], [\"This is dermoscopy\"]]                    \n",
    "                \n",
    "        \n",
    "        #print(prompt_target, prompt_ref)\n",
    "        # target embedding\n",
    "        prompt_target_tokenized=[clip.tokenize(prompt_list, truncate=True) for prompt_list in prompt_target]\n",
    "        with torch.no_grad():\n",
    "            prompt_target_embedding = torch.stack([clip_model.model_step_with_text({\"text\": prompt_tokenized.to(model_device)})[\n",
    "                    \"text_features\"].detach().cpu() for prompt_tokenized in prompt_target_tokenized])\n",
    "        prompt_target_embedding_norm=prompt_target_embedding/prompt_target_embedding.norm(dim=2, keepdim=True)          \n",
    "\n",
    "        # reference embedding\n",
    "        prompt_ref_tokenized=[clip.tokenize(prompt_list, truncate=True) for prompt_list in prompt_ref]\n",
    "        with torch.no_grad():\n",
    "            prompt_ref_embedding = torch.stack([clip_model.model_step_with_text({\"text\": prompt_tokenized.to(model_device)})[\n",
    "                    \"text_features\"].detach().cpu() for prompt_tokenized in prompt_ref_tokenized])\n",
    "        prompt_ref_embedding_norm=prompt_ref_embedding/prompt_ref_embedding.norm(dim=2, keepdim=True)                \n",
    "\n",
    "        prompt_info[concept_name]={\"prompt_ref_embedding_norm\":prompt_ref_embedding_norm,\n",
    "                                   \"prompt_target_embedding_norm\":prompt_target_embedding_norm,\n",
    "                                  }\n",
    "        print(dataset_name, concept_name, \"\\n\" , prompt_target, prompt_ref)\n",
    "        print('-----------')\n",
    "        #print(prompt_target_embedding_norm)\n",
    "        #print(prompt_ref_embedding_norm)\n",
    "        del prompt_ref\n",
    "        del prompt_target\n",
    "    \n",
    "    return {\"prompt_info\": prompt_info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"prompt_info\"][\"skincon_Macule\"][\"prompt_target_embedding_norm\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8ec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    if (\"clinical_fd_clean\" in dataset_name) or (\"derm7pt\" in dataset_name):\n",
    "        variable_dict[dataset_name].update(\n",
    "            {\"prompt_info_vanilla\":get_concept_embedding(dataset_name, \n",
    "                          concept_list=variable_dict[dataset_name][\"concept_list\"],\n",
    "                                 clip_model=model_vanilla)[\"prompt_info\"]})            \n",
    "    variable_dict[dataset_name].update(\n",
    "        {\"prompt_info\":get_concept_embedding(dataset_name, \n",
    "                      concept_list=variable_dict[dataset_name][\"concept_list\"],\n",
    "                             clip_model=model)[\"prompt_info\"]})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [ \"proveai\"\n",
    "                    ]:\n",
    "    if (\"clinical_fd_clean\" in dataset_name) or (\"derm7pt\" in dataset_name):\n",
    "        variable_dict[dataset_name].update(\n",
    "            {\"prompt_info_vanilla\":get_concept_embedding(dataset_name, \n",
    "                          concept_list=variable_dict[dataset_name][\"concept_list\"],\n",
    "                                 clip_model=model_vanilla)[\"prompt_info\"]})            \n",
    "    variable_dict[dataset_name].update(\n",
    "        {\"prompt_info\":get_concept_embedding(dataset_name, \n",
    "                      concept_list=variable_dict[dataset_name][\"concept_list\"],\n",
    "                             clip_model=model)[\"prompt_info\"]})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similaity_score(image_features_norm, \n",
    "                              prompt_target_embedding_norm,\n",
    "                              prompt_ref_embedding_norm,\n",
    "                              temp=1,\n",
    "                              normalize=True):\n",
    "\n",
    "    target_similarity=prompt_target_embedding_norm.float()@image_features_norm.T.float()\n",
    "    ref_similarity=prompt_ref_embedding_norm.float()@image_features_norm.T.float()\n",
    "    \n",
    "    target_similarity_mean=target_similarity.mean(dim=[1]) # (template, terms, num_images) -> (template, num_images)\n",
    "    ref_similarity_mean=ref_similarity.mean(axis=1) # (template, 1, num_images) -> (template, num_images)\n",
    "         \n",
    "    if normalize:\n",
    "        similarity_score=scipy.special.softmax([target_similarity_mean.numpy()/temp, \n",
    "                            ref_similarity_mean.numpy()/temp], axis=0)[0,:].mean(axis=0)   \n",
    "        # (template, num_images), (template, num_images) -> (template, num_images) -> (1, num_images)\n",
    "    else:\n",
    "        similarity_score=target_similarity_mean.mean(axis=0)\n",
    "\n",
    "    \n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similaity_score_(image_features_norm, \n",
    "                              prompt_target_embedding_norm,\n",
    "                              prompt_ref_embedding_norm,\n",
    "                              temp=1/np.exp(4.5944),\n",
    "                              normalize=True):\n",
    "\n",
    "    target_similarity=prompt_target_embedding_norm.float()@image_features_norm.T.float() # (template, terms, num_features) @ (num_features, num_images) -> (template, terms, num_images) \n",
    "    ref_similarity=prompt_ref_embedding_norm.float()@image_features_norm.T.float() # (template, terms, num_features) @ (num_features, num_images) -> (template, terms, num_images) \n",
    "    \n",
    "    target_similarity_mean=target_similarity.mean(dim=[1]) # (template, terms, num_images) -> (template, num_images)\n",
    "    ref_similarity_mean=ref_similarity.mean(axis=1) # (template, 1, num_images) -> (template, num_images)\n",
    "         \n",
    "    if normalize:\n",
    "        similarity_score=scipy.special.softmax([target_similarity_mean.numpy()/temp, \n",
    "                            ref_similarity_mean.numpy()/temp], axis=0)[0,:].mean(axis=0)   \n",
    "        # (template, num_images), (template, num_images) -> (template, num_images) -> (1, num_images)\n",
    "    else:\n",
    "        similarity_score=target_similarity_mean.mean(axis=0)\n",
    "\n",
    "    \n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.net.model.logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909e6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df756489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa48057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from MONET.datamodules.components.base_dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8934c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.resnet50(weights=\"ResNet50_Weights.IMAGENET1K_V1\")\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "            # pass\n",
    "\n",
    "        head_in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.head = nn.Linear(head_in_features, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "def find_thres_best_f1(y_test, y_test_pred):\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_test_pred)\n",
    "    numerator = 2 * recall * precision\n",
    "    denom = recall + precision\n",
    "    f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "    max_f1 = np.max(f1_scores)\n",
    "    max_f1_thresh = thresholds[np.argmax(f1_scores)]    \n",
    "    return max_f1_thresh \n",
    "\n",
    "def train_classifier(train_dataloader, val_dataloader, test_dataloader, classifier_type=\"resnet\", verbose=True):\n",
    "    if classifier_type==\"resnet\":\n",
    "        classifier = Classifier(output_dim=1)\n",
    "    elif classifier_type==\"inception\":\n",
    "        classifier = Inception(output_dim=1)\n",
    "    classifier_device = \"cuda:3\"\n",
    "    classifier.to(classifier_device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2, verbose=True)\n",
    "    early_stopper = EarlyStopper(patience=5, min_delta=0)\n",
    "\n",
    "    train_auroc = AUROC(task=\"binary\")\n",
    "    val_auroc = AUROC(task=\"binary\")\n",
    "    for epoch in range(20):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        classifier.train()\n",
    "        if verbose:\n",
    "            pbar=tqdm.tqdm(train_dataloader)\n",
    "        else:\n",
    "            pbar=train_dataloader        \n",
    "        for batch in pbar:\n",
    "            image, label = batch[\"image\"].to(classifier_device), batch[\"label\"].to(classifier_device)\n",
    "            logits = classifier(image)\n",
    "            weight = torch.ones(label.shape[0], device=label.device)\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                input=logits[:, 0], target=(label == 1).float()\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            train_auroc.update(logits, (label == 1))\n",
    "\n",
    "        val_loss = 0\n",
    "        classifier.eval()\n",
    "        label_list=[]\n",
    "        logits_list=[]\n",
    "        with torch.no_grad():   \n",
    "            if verbose:\n",
    "                pbar=tqdm.tqdm(val_dataloader)\n",
    "            else:\n",
    "                pbar=val_dataloader             \n",
    "            for batch in pbar:\n",
    "                image, label = batch[\"image\"].to(classifier_device), batch[\"label\"].to(\n",
    "                    classifier_device\n",
    "                )\n",
    "                logits = classifier(image)\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    input=logits[:, 0], target=(label == 1).float()\n",
    "                )\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                val_auroc.update(logits, (label == 1))\n",
    "                logits_list.append(logits.detach().cpu().numpy())\n",
    "                label_list.append(label.detach().cpu().numpy())                \n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Train loss: {train_loss/len(train_dataloader.dataset):.3f} AUROC: {train_auroc.compute():.3f} Val loss: {val_loss/len(val_dataloader.dataset):.3f} AUROC: {val_auroc.compute():.3f}\"\n",
    "            )\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print(\"break\")\n",
    "            break\n",
    "        train_auroc.reset()\n",
    "        val_auroc.reset() \n",
    "        max_f1_thresh=find_thres_best_f1(y_test=np.hstack(label_list), y_test_pred=np.concatenate(logits_list)[:,0])\n",
    "        print(max_f1_thresh)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    test_auroc = AUROC(task=\"binary\")    \n",
    "    test_loss = 0\n",
    "    classifier.eval()\n",
    "    \n",
    "    logits_list=[]\n",
    "    label_list=[]\n",
    "    metadata_list=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if verbose:\n",
    "            pbar=tqdm.tqdm(test_dataloader)\n",
    "        else:\n",
    "            pbar=test_dataloader          \n",
    "        for batch in tqdm.tqdm(test_dataloader):\n",
    "            image, label = batch[\"image\"].to(classifier_device), batch[\"label\"].to(\n",
    "                classifier_device\n",
    "            )\n",
    "            logits = classifier(image)\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                input=logits[:, 0], target=(label == 1).float()\n",
    "            )\n",
    "            test_loss += loss.item() * image.size(0)\n",
    "            test_auroc.update(logits, (label == 1))\n",
    "            logits_list.append(logits.detach().cpu().numpy())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            metadata_list.append(batch[\"metadata\"])\n",
    "            \n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Test loss: {test_loss/len(test_dataloader.dataset):.3f} AUROC: {test_auroc.compute():.3f}\"\n",
    "        )   \n",
    "    return test_auroc.compute(), classifier, logits_list, label_list, metadata_list, max_f1_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5574f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdrcorrection(pvals, alpha=0.05, method='indep', is_sorted=False):\n",
    "    '''\n",
    "    pvalue correction for false discovery rate.\n",
    "\n",
    "    This covers Benjamini/Hochberg for independent or positively correlated and\n",
    "    Benjamini/Yekutieli for general or negatively correlated tests.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pvals : array_like, 1d\n",
    "        Set of p-values of the individual tests.\n",
    "    alpha : float, optional\n",
    "        Family-wise error rate. Defaults to ``0.05``.\n",
    "    method : {'i', 'indep', 'p', 'poscorr', 'n', 'negcorr'}, optional\n",
    "        Which method to use for FDR correction.\n",
    "        ``{'i', 'indep', 'p', 'poscorr'}`` all refer to ``fdr_bh``\n",
    "        (Benjamini/Hochberg for independent or positively\n",
    "        correlated tests). ``{'n', 'negcorr'}`` both refer to ``fdr_by``\n",
    "        (Benjamini/Yekutieli for general or negatively correlated tests).\n",
    "        Defaults to ``'indep'``.\n",
    "    is_sorted : bool, optional\n",
    "        If False (default), the p_values will be sorted, but the corrected\n",
    "        pvalues are in the original order. If True, then it assumed that the\n",
    "        pvalues are already sorted in ascending order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rejected : ndarray, bool\n",
    "        True if a hypothesis is rejected, False if not\n",
    "    pvalue-corrected : ndarray\n",
    "        pvalues adjusted for multiple hypothesis testing to limit FDR\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If there is prior information on the fraction of true hypothesis, then alpha\n",
    "    should be set to ``alpha * m/m_0`` where m is the number of tests,\n",
    "    given by the p-values, and m_0 is an estimate of the true hypothesis.\n",
    "    (see Benjamini, Krieger and Yekuteli)\n",
    "\n",
    "    The two-step method of Benjamini, Krieger and Yekutiel that estimates the number\n",
    "    of false hypotheses will be available (soon).\n",
    "\n",
    "    Both methods exposed via this function (Benjamini/Hochberg, Benjamini/Yekutieli)\n",
    "    are also available in the function ``multipletests``, as ``method=\"fdr_bh\"`` and\n",
    "    ``method=\"fdr_by\"``, respectively.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    multipletests\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def _ecdf(x):\n",
    "        '''no frills empirical cdf used in fdrcorrection\n",
    "        '''\n",
    "        nobs = len(x)\n",
    "        return np.arange(1,nobs+1)/float(nobs)    \n",
    "\n",
    "    pvals = np.asarray(pvals)\n",
    "    assert pvals.ndim == 1, \"pvals must be 1-dimensional, that is of shape (n,)\"\n",
    "\n",
    "    if not is_sorted:\n",
    "        pvals_sortind = np.argsort(pvals)\n",
    "        pvals_sorted = np.take(pvals, pvals_sortind)\n",
    "    else:\n",
    "        pvals_sorted = pvals  # alias\n",
    "\n",
    "    if method in ['i', 'indep', 'p', 'poscorr']:\n",
    "        ecdffactor = _ecdf(pvals_sorted)\n",
    "    elif method in ['n', 'negcorr']:\n",
    "        cm = np.sum(1./np.arange(1, len(pvals_sorted)+1))   #corrected this\n",
    "        ecdffactor = _ecdf(pvals_sorted) / cm\n",
    "##    elif method in ['n', 'negcorr']:\n",
    "##        cm = np.sum(np.arange(len(pvals)))\n",
    "##        ecdffactor = ecdf(pvals_sorted)/cm\n",
    "    else:\n",
    "        raise ValueError('only indep and negcorr implemented')\n",
    "    reject = pvals_sorted <= ecdffactor*alpha\n",
    "    if reject.any():\n",
    "        rejectmax = max(np.nonzero(reject)[0])\n",
    "        reject[:rejectmax] = True\n",
    "\n",
    "    pvals_corrected_raw = pvals_sorted / ecdffactor\n",
    "    pvals_corrected = np.minimum.accumulate(pvals_corrected_raw[::-1])[::-1]\n",
    "    del pvals_corrected_raw\n",
    "    pvals_corrected[pvals_corrected>1] = 1\n",
    "    if not is_sorted:\n",
    "        pvals_corrected_ = np.empty_like(pvals_corrected)\n",
    "        pvals_corrected_[pvals_sortind] = pvals_corrected\n",
    "        del pvals_corrected\n",
    "        reject_ = np.empty_like(reject)\n",
    "        reject_[pvals_sortind] = reject\n",
    "        return reject_, pvals_corrected_\n",
    "    else:\n",
    "        return reject, pvals_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb33ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import xlogy\n",
    "def log_loss(\n",
    "    y_true, y_pred, *, eps=\"auto\", normalize=True, sample_weight=None, labels=None\n",
    "):\n",
    "    \n",
    "    r\"\"\"Log loss, aka logistic loss or cross-entropy loss.\n",
    "\n",
    "    This is the loss function used in (multinomial) logistic regression\n",
    "    and extensions of it such as neural networks, defined as the negative\n",
    "    log-likelihood of a logistic model that returns ``y_pred`` probabilities\n",
    "    for its training data ``y_true``.\n",
    "    The log loss is only defined for two or more labels.\n",
    "    For a single sample with true label :math:`y \\in \\{0,1\\}` and\n",
    "    a probability estimate :math:`p = \\operatorname{Pr}(y = 1)`, the log\n",
    "    loss is:\n",
    "\n",
    "    .. math::\n",
    "        L_{\\log}(y, p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n",
    "\n",
    "    Read more in the :ref:`User Guide <log_loss>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like or label indicator matrix\n",
    "        Ground truth (correct) labels for n_samples samples.\n",
    "\n",
    "    y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)\n",
    "        Predicted probabilities, as returned by a classifier's\n",
    "        predict_proba method. If ``y_pred.shape = (n_samples,)``\n",
    "        the probabilities provided are assumed to be that of the\n",
    "        positive class. The labels in ``y_pred`` are assumed to be\n",
    "        ordered alphabetically, as done by\n",
    "        :class:`preprocessing.LabelBinarizer`.\n",
    "\n",
    "    eps : float or \"auto\", default=\"auto\"\n",
    "        Log loss is undefined for p=0 or p=1, so probabilities are\n",
    "        clipped to `max(eps, min(1 - eps, p))`. The default will depend on the\n",
    "        data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.\n",
    "\n",
    "        .. versionadded:: 1.2\n",
    "\n",
    "        .. versionchanged:: 1.2\n",
    "           The default value changed from `1e-15` to `\"auto\"` that is\n",
    "           equivalent to `np.finfo(y_pred.dtype).eps`.\n",
    "\n",
    "    normalize : bool, default=True\n",
    "        If true, return the mean loss per sample.\n",
    "        Otherwise, return the sum of the per-sample losses.\n",
    "\n",
    "    sample_weight : array-like of shape (n_samples,), default=None\n",
    "        Sample weights.\n",
    "\n",
    "    labels : array-like, default=None\n",
    "        If not provided, labels will be inferred from y_true. If ``labels``\n",
    "        is ``None`` and ``y_pred`` has shape (n_samples,) the labels are\n",
    "        assumed to be binary and are inferred from ``y_true``.\n",
    "\n",
    "        .. versionadded:: 0.18\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        Log loss, aka logistic loss or cross-entropy loss.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The logarithm used is the natural logarithm (base-e).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,\n",
    "    p. 209.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.metrics import log_loss\n",
    "    >>> log_loss([\"spam\", \"ham\", \"ham\", \"spam\"],\n",
    "    ...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])\n",
    "    0.21616...\n",
    "    \"\"\"\n",
    "    \n",
    "    def _weighted_sum(sample_score, sample_weight, normalize=False):\n",
    "        if normalize:\n",
    "            return np.average(sample_score, weights=sample_weight)\n",
    "        elif sample_weight is not None:\n",
    "            return np.dot(sample_score, sample_weight)\n",
    "        else:\n",
    "            return sample_score.sum()    \n",
    "    y_pred = sklearn.utils.check_array(\n",
    "        y_pred, ensure_2d=False, dtype=[np.float64, np.float32, np.float16]\n",
    "    )\n",
    "    eps = np.finfo(y_pred.dtype).eps if eps == \"auto\" else eps\n",
    "\n",
    "    sklearn.utils.check_consistent_length(y_pred, y_true, sample_weight)\n",
    "    lb = sklearn.preprocessing.LabelBinarizer()\n",
    "    if labels is not None:\n",
    "        lb.fit(labels)\n",
    "    else:\n",
    "        lb.fit(y_true)\n",
    "\n",
    "    if len(lb.classes_) == 1:\n",
    "        if labels is None:\n",
    "            raise ValueError(\n",
    "                \"y_true contains only one label ({0}). Please \"\n",
    "                \"provide the true labels explicitly through the \"\n",
    "                \"labels argument.\".format(lb.classes_[0])\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The labels array needs to contain at least two \"\n",
    "                \"labels for log_loss, \"\n",
    "                \"got {0}.\".format(lb.classes_)\n",
    "            )\n",
    "\n",
    "    transformed_labels = lb.transform(y_true)\n",
    "\n",
    "    if transformed_labels.shape[1] == 1:\n",
    "        transformed_labels = np.append(\n",
    "            1 - transformed_labels, transformed_labels, axis=1\n",
    "        )\n",
    "\n",
    "    # Clipping\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # If y_pred is of single dimension, assume y_true to be binary\n",
    "    # and then check.\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred[:, np.newaxis]\n",
    "    if y_pred.shape[1] == 1:\n",
    "        y_pred = np.append(1 - y_pred, y_pred, axis=1)\n",
    "\n",
    "    # Check if dimensions are consistent.\n",
    "    transformed_labels = sklearn.utils.check_array(transformed_labels)\n",
    "    if len(lb.classes_) != y_pred.shape[1]:\n",
    "        if labels is None:\n",
    "            raise ValueError(\n",
    "                \"y_true and y_pred contain different number of \"\n",
    "                \"classes {0}, {1}. Please provide the true \"\n",
    "                \"labels explicitly through the labels argument. \"\n",
    "                \"Classes found in \"\n",
    "                \"y_true: {2}\".format(\n",
    "                    transformed_labels.shape[1], y_pred.shape[1], lb.classes_\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The number of classes in labels is different \"\n",
    "                \"from that in y_pred. Classes found in \"\n",
    "                \"labels: {0}\".format(lb.classes_)\n",
    "            )\n",
    "\n",
    "    # Renormalize\n",
    "#     print(y_pred)\n",
    "    y_pred_sum = y_pred.sum(axis=1)\n",
    "    y_pred = y_pred / y_pred_sum[:, np.newaxis]\n",
    "#     print(y_pred)\n",
    "#     print(-xlogy(transformed_labels, y_pred))\n",
    "    loss = -xlogy(transformed_labels, y_pred).sum(axis=1)\n",
    "#     print(-xlogy(transformed_labels, y_pred))\n",
    "#     print(loss)\n",
    "    return loss\n",
    "#     return _weighted_sum(loss, sample_weight, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3ec3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a677ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(embeddings,\n",
    "                      prompt_info,\n",
    "                     idx):\n",
    "\n",
    "    concept_similarity_all=[]\n",
    "    for concept_name in prompt_info.keys():\n",
    "        concept_similarity=calculate_similaity_score(\n",
    "            image_features_norm=embeddings,\n",
    "            prompt_target_embedding_norm=prompt_info[concept_name][\"prompt_target_embedding_norm\"],\n",
    "            prompt_ref_embedding_norm=prompt_info[concept_name][\"prompt_ref_embedding_norm\"],\n",
    "            temp=1/np.exp(4.5944),\n",
    "            normalize=True)\n",
    "        concept_similarity_all.append(pd.Series(concept_similarity, \n",
    "                                                index=idx,\n",
    "                                               name=concept_name\n",
    "                                               )\n",
    "                                     )\n",
    "                                      \n",
    "#                                       {\"concept_name\":concept_name,\n",
    "#                                       \"concept_similarity\":,\n",
    "#                                       })\n",
    "    concept_similarity_all=pd.concat(concept_similarity_all, axis=1)\n",
    "    \n",
    "    return concept_similarity_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf630b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\", \"derm7pt_derm_nodup\",\n",
    "                     \"isic_nodup_nooverlap\", \"proveai\"\n",
    "                    ]:\n",
    "    if (\"clinical_fd_clean\" in dataset_name) or (\"derm7pt\" in dataset_name):\n",
    "        variable_dict[dataset_name].update(\n",
    "            {\"similarity_matrix_vanilla\": similarity_matrix(embeddings=variable_dict[dataset_name][\"image_features_vanilla_norm\"],\n",
    "                             prompt_info=variable_dict[dataset_name][\"prompt_info_vanilla\"],\n",
    "                            idx=variable_dict[dataset_name][\"metadata_all\"].index\n",
    "                     )})  \n",
    "    variable_dict[dataset_name].update(\n",
    "        {\"similarity_matrix\": similarity_matrix(embeddings=variable_dict[dataset_name][\"image_features_norm\"],\n",
    "                         prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                        idx=variable_dict[dataset_name][\"metadata_all\"].index\n",
    "                 )})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e8352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"similarity_matrix_vanilla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"similarity_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11136a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45512d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"image_features_vanilla_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"image_features_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"prompt_info_vanilla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7fd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"prompt_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c3462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac194c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_concept_name(dataset_name, concept_name):\n",
    "    if \"isic\" in dataset_name:\n",
    "        if concept_name.startswith(\"disease\"):\n",
    "            return False\n",
    "        elif concept_name.startswith(\"isicconcept_\"):\n",
    "            return False        \n",
    "        elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "            if 'typical' in concept_name:\n",
    "                return False                \n",
    "            elif 'regular' in concept_name:\n",
    "                return False\n",
    "            elif \"pigmentation\" in concept_name:\n",
    "                return False\n",
    "            else:\n",
    "                return True        \n",
    "        elif concept_name in [\"melanoma\", \"malignant\", \"finger\", \"red sticker\"]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        raise NotImplemented(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "from sklearn.model_selection import train_test_split\n",
    "from MONET.datamodules.components.base_dataset import BaseDataset\n",
    "\n",
    "def get_training_data_idx(dataloader, valid_idx, y_pos, subset_idx_train, subset_idx_test, n_px=None):\n",
    "    metadata_all_new = dataloader.dataset.metadata_all.copy()\n",
    "    metadata_all_new[\"label\"]=y_pos.astype(int)\n",
    "    \n",
    "    metadata_all_new_=metadata_all_new[valid_idx]\n",
    "    \n",
    "#     print(subset_idx_train)\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(np.unique(subset_idx_train), test_size=0.2, random_state=42)\n",
    "    \n",
    "    metadata_all_new_train=metadata_all_new_.loc[[i for i in subset_idx_train if i in train_idx]]\n",
    "    metadata_all_new_val=metadata_all_new_.loc[[i for i in subset_idx_train if i in val_idx]]\n",
    "    metadata_all_new_test=metadata_all_new_.loc[subset_idx_test]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"train:\", len(metadata_all_new_train))\n",
    "    print(\"val:\", len(metadata_all_new_val))\n",
    "    print(\"test:\", len(metadata_all_new_test))\n",
    "\n",
    "    if n_px is None:\n",
    "        n_px=dataloader.dataset.n_px\n",
    "    \n",
    "    data_train = BaseDataset(\n",
    "        image_path_or_binary_dict=dataloader.dataset.image_path_dict,\n",
    "        n_px=n_px,\n",
    "        norm_mean=dataloader.dataset.transforms_aftertensor.transforms[1].mean,\n",
    "        norm_std=dataloader.dataset.transforms_aftertensor.transforms[1].std,\n",
    "        augment=False,\n",
    "        metadata_all=metadata_all_new_train,\n",
    "        integrity_level=\"weak\",\n",
    "        return_label=[\"label\"],\n",
    "    )\n",
    "\n",
    "    data_val = BaseDataset(\n",
    "        image_path_or_binary_dict=dataloader.dataset.image_path_dict,\n",
    "        n_px=n_px,\n",
    "        norm_mean=dataloader.dataset.transforms_aftertensor.transforms[1].mean,\n",
    "        norm_std=dataloader.dataset.transforms_aftertensor.transforms[1].std,\n",
    "        augment=False,\n",
    "        metadata_all=metadata_all_new_val,\n",
    "        integrity_level=\"weak\",\n",
    "        return_label=[\"label\"],\n",
    "    )\n",
    "    \n",
    "    data_test = BaseDataset(\n",
    "        image_path_or_binary_dict=dataloader.dataset.image_path_dict,\n",
    "        n_px=n_px,\n",
    "        norm_mean=dataloader.dataset.transforms_aftertensor.transforms[1].mean,\n",
    "        norm_std=dataloader.dataset.transforms_aftertensor.transforms[1].std,\n",
    "        augment=False,\n",
    "        metadata_all=metadata_all_new_test,\n",
    "        integrity_level=\"weak\",\n",
    "        return_label=[\"label\"],\n",
    "    )    \n",
    "\n",
    "    from MONET.utils.loader import custom_collate\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=data_train,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,\n",
    "        shuffle=True,\n",
    "        collate_fn=custom_collate,\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=data_val,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate,\n",
    "    )   \n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=data_test,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate,\n",
    "    )       \n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c5939",
   "metadata": {},
   "source": [
    "# forced direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03584da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_bool_from_metadata(dataset_name, metadata_all, concept_name):\n",
    "    if \"derm7pt_derm\" in dataset_name:\n",
    "        if concept_name==\"derm7ptconcept_pigment network\":\n",
    "            valid_idx=(~metadata_all[\"pigment_network\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"pigment_network\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_typical pigment network\":\n",
    "            valid_idx=(~metadata_all[\"pigment_network\"].isnull()).values\n",
    "#                 valid_idx=(metadata_all[\"pigment_network\"].str.contains(\"typical\")).values\n",
    "            concept_bool=(metadata_all[\"pigment_network\"]==\"typical\")\n",
    "        elif concept_name==\"derm7ptconcept_atypical pigment network\":\n",
    "            valid_idx=(~metadata_all[\"pigment_network\"].isnull()).values\n",
    "#                 valid_idx=(metadata_all[\"pigment_network\"].str.contains(\"typical\")).values\n",
    "            concept_bool=(metadata_all[\"pigment_network\"]==\"atypical\")\n",
    "        elif concept_name==\"derm7ptconcept_regression structure\":\n",
    "            valid_idx=(~metadata_all[\"regression_structures\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"regression_structures\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_pigmentation\":\n",
    "            valid_idx=(~metadata_all[\"pigmentation\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"pigmentation\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_regular pigmentation\":\n",
    "            valid_idx=(~metadata_all[\"pigmentation\"].isnull()).values\n",
    "#                 valid_idx=(metadata_all[\"pigmentation\"].str.contains(\"regular\")).values\n",
    "            concept_bool=(metadata_all[\"pigmentation\"].str.contains(\" regular\"))\n",
    "        elif concept_name==\"derm7ptconcept_irregular pigmentation\":\n",
    "            valid_idx=(~metadata_all[\"pigmentation\"].isnull()).values\n",
    "#                 valid_idx=(metadata_all[\"pigmentation\"].str.contains(\"regular\")).values\n",
    "            concept_bool=(metadata_all[\"pigmentation\"].str.contains(\" irregular\"))\n",
    "        elif concept_name==\"derm7ptconcept_blue whitish veil\":\n",
    "            valid_idx=(~metadata_all[\"blue_whitish_veil\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"blue_whitish_veil\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_vascular structures\":\n",
    "            valid_idx=(~metadata_all[\"vascular_structures\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"vascular_structures\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_typical vascular structures\":\n",
    "            valid_idx=(~metadata_all[\"vascular_structures\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"vascular_structures\"].isin([\"within regression\", \"arborizing\", \"comma\", \"hairpin\", \"wreath\"]))\n",
    "        elif concept_name==\"derm7ptconcept_atypical vascular structures\":\n",
    "            valid_idx=(~metadata_all[\"vascular_structures\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"vascular_structures\"].isin([\"dotted\", \"linear irregular\"]))\n",
    "        elif concept_name==\"derm7ptconcept_streaks\":\n",
    "            #print(metadata_all[\"streaks\"].value_counts())\n",
    "            valid_idx=(~metadata_all[\"streaks\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"streaks\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_regular streaks\":\n",
    "            valid_idx=(~metadata_all[\"streaks\"].isnull()).values\n",
    "            #valid_idx=(metadata_all[\"streaks\"].str.contains(\"regular\")).values\n",
    "            concept_bool=(metadata_all[\"streaks\"]==\"regular\")\n",
    "        elif concept_name==\"derm7ptconcept_irregular streaks\":\n",
    "            valid_idx=(~metadata_all[\"streaks\"].isnull()).values\n",
    "            #valid_idx=(metadata_all[\"streaks\"].str.contains(\"regular\")).values\n",
    "            concept_bool=(metadata_all[\"streaks\"]==\"irregular\")\n",
    "        elif concept_name==\"derm7ptconcept_dots and globules\":\n",
    "            valid_idx=(~metadata_all[\"dots_and_globules\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"dots_and_globules\"]!=\"absent\")\n",
    "        elif concept_name==\"derm7ptconcept_regular dots and globules\":\n",
    "            valid_idx=(~metadata_all[\"dots_and_globules\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"dots_and_globules\"]==\"regular\")\n",
    "        elif concept_name==\"derm7ptconcept_irregular dots and globules\":\n",
    "            valid_idx=(~metadata_all[\"dots_and_globules\"].isnull()).values\n",
    "            concept_bool=(metadata_all[\"dots_and_globules\"]==\"irregular\")\n",
    "        else:\n",
    "            raise ValueError(concept_name)\n",
    "            \n",
    "        concept_bool_true=concept_bool\n",
    "        concept_bool_false=(~concept_bool)\n",
    "\n",
    "\n",
    "    elif \"isic\" in dataset_name:\n",
    "        if concept_name=='isicconcept_pigment_network':\n",
    "            label=(metadata_all[\"pigment_network\"])\n",
    "            valid_idx=(label!=-9).values\n",
    "            concept_bool=(label>(label[valid_idx&(label>0)].quantile(0.9))).values\n",
    "            concept_bool=(label>30)\n",
    "        elif concept_name=='isicconcept_negative_network':\n",
    "            label=(metadata_all[\"negative_network\"])\n",
    "            valid_idx=(label!=-9).values\n",
    "            concept_bool=(label>(label[valid_idx&(label>0)].quantile(0.9))).values    \n",
    "            concept_bool=(label>30)\n",
    "        elif concept_name=='isicconcept_milia_like_cyst':\n",
    "            label=(metadata_all[\"milia_like_cyst\"])\n",
    "            valid_idx=(label!=-9).values\n",
    "            concept_bool=(label>(label[valid_idx&(label>0)].quantile(0.9))).values    \n",
    "            concept_bool=(label>30)\n",
    "        elif concept_name=='isicconcept_streaks':\n",
    "            label=(metadata_all[\"streaks\"])\n",
    "            valid_idx=(label!=-9).values\n",
    "            concept_bool=(label>(label[valid_idx&(label>0)].quantile(0.9))).values    \n",
    "            concept_bool=(label>30)\n",
    "        elif concept_name=='isicconcept_globules':\n",
    "            label=(metadata_all[\"globules\"])\n",
    "            valid_idx=(label!=-9).values\n",
    "            concept_bool=(label>(label[valid_idx&(label>0)].quantile(0.9))).values\n",
    "            concept_bool=(label>30)\n",
    "        else:\n",
    "            raise ValueError(concept_name)            \n",
    "            \n",
    "    elif \"clinical_fd_clean\" in dataset_name:\n",
    "        if concept_name.startswith(\"skincon_\"):\n",
    "            concept_bool_true=(metadata_all[concept_name]==1)\n",
    "            concept_bool_false=(metadata_all[concept_name]==0)\n",
    "        else:\n",
    "            raise ValueError(concept_name)\n",
    "        \n",
    "      \n",
    "    return {\"concept_bool_true\": concept_bool_true,\n",
    "            \"concept_bool_false\": concept_bool_false,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forced_training(dataset_name, dataloader, concept_list, metadata_all, y_pos, random_seed_range=[]):\n",
    "    simulation_data_list=[]\n",
    "\n",
    "    for concept_name in concept_list:\n",
    "        if \"clinical_fd_clean\" in dataset_name:\n",
    "            concept_idx=(metadata_all[\"skincon_Do not consider this image\"]==0).values\n",
    "        elif \"derm7pt\" in dataset_name:\n",
    "            concept_idx=(~metadata_all[\"regression_structures\"].isnull()).values\n",
    "            \n",
    "            \n",
    "        if get_concept_bool_from_metadata(dataset_name, \n",
    "                        metadata_all[concept_idx], \n",
    "                        concept_name)[\"concept_bool_true\"].values.astype(bool).sum()<30:\n",
    "            print(concept_name, \"!!!!!!!!!!!!!!!!!!!!!!!! SKIPPED !!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            continue  \n",
    "\n",
    "    #     if concept_name!=\"skincon_Brown(Hyperpigmentation)\":\n",
    "    #         continue\n",
    "\n",
    "\n",
    "        num_train_pos=500\n",
    "        num_train_neg=500\n",
    "\n",
    "        num_test_pos=500\n",
    "        num_test_neg=500\n",
    "    #     for proportion in [1.0, 0.8, 0.2, 0.0]:\n",
    "        for proportion in [1]:\n",
    "            num_train_pos_with = int(num_train_pos*proportion)\n",
    "            num_train_pos_without = num_train_pos-num_train_pos_with\n",
    "\n",
    "            num_train_neg_with = int(num_train_neg*(1-proportion))\n",
    "            num_train_neg_without = num_train_neg-num_train_neg_with\n",
    "\n",
    "\n",
    "            num_test_pos_with = int(num_test_pos*(1-proportion))\n",
    "            num_test_pos_without = num_test_pos-num_test_pos_with\n",
    "\n",
    "            num_test_neg_with = int(num_test_neg*(proportion))\n",
    "            num_test_neg_without = num_test_neg-num_test_neg_with\n",
    "\n",
    "\n",
    "            for random_seed in random_seed_range:\n",
    "                subset_idx_train_, subset_idx_test_ = train_test_split(np.arange(len(concept_idx))[concept_idx], \n",
    "                                                                       test_size=0.4, \n",
    "                                                                       random_state=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "                metadata_all_train_=metadata_all.iloc[subset_idx_train_]\n",
    "                y_pos_train_=y_pos[subset_idx_train_]\n",
    "                metadata_all_train_=metadata_all_train_.copy()\n",
    "                metadata_all_train_[\"y_pos\"]=y_pos_train_\n",
    "                \n",
    "                \n",
    "                \n",
    "                concept_bool_train_true=get_concept_bool_from_metadata(dataset_name, \n",
    "                                                            metadata_all_train_, \n",
    "                                                            concept_name)[\"concept_bool_true\"]\n",
    "                concept_bool_train_false=get_concept_bool_from_metadata(dataset_name, \n",
    "                                                            metadata_all_train_, \n",
    "                                                            concept_name)[\"concept_bool_false\"]                        \n",
    "\n",
    "                print(len(metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==True)]),\n",
    "                      len(metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==True)]),\n",
    "                      len(metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==False)]),\n",
    "                      len(metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==False)]))\n",
    "                \n",
    "                if len(metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==True)])<30 or\\\n",
    "                len(metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==True)])<30 or\\\n",
    "                len(metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==False)])<30 or\\\n",
    "                len(metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==False)])<30:\n",
    "                    print(\"Train Not found\")\n",
    "                    continue\n",
    "                    \n",
    "                #\\continue\n",
    "\n",
    "                \n",
    "                train_idx_pos_with=metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==True)].sample(n=num_train_pos_with, replace=True, random_state=random_seed).index\n",
    "                train_idx_pos_without=metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==True)].sample(n=num_train_pos_without, replace=True, random_state=random_seed).index\n",
    "\n",
    "                train_idx_neg_with=metadata_all_train_[concept_bool_train_true&(metadata_all_train_[\"y_pos\"]==False)].sample(n=num_train_neg_with, replace=True, random_state=random_seed).index\n",
    "                train_idx_neg_without=metadata_all_train_[concept_bool_train_false&(metadata_all_train_[\"y_pos\"]==False)].sample(n=num_train_neg_without, replace=True, random_state=random_seed).index\n",
    "\n",
    "                train_idx=train_idx_pos_with.tolist()+train_idx_pos_without.tolist()+train_idx_neg_with.tolist()+train_idx_neg_without.tolist()\n",
    "                # train_idx=metadata_all_train_[(metadata_all_train_[concept_name]==1] ###\n",
    "                #train_idx=metadata_all_train_.index.tolist()\n",
    "                #print(metadata_all_train_.loc[train_idx][[concept_name,\"y_pos\"]])\n",
    "                metadata_all_train=metadata_all_train_.loc[train_idx]\n",
    "\n",
    "\n",
    "                metadata_all_test_=metadata_all.iloc[subset_idx_test_]\n",
    "                y_pos_test_=y_pos[subset_idx_test_]\n",
    "                metadata_all_test_=metadata_all_test_.copy()\n",
    "                metadata_all_test_[\"y_pos\"]=y_pos_test_\n",
    "                \n",
    "                concept_bool_test_true=get_concept_bool_from_metadata(dataset_name, \n",
    "                                                            metadata_all_test_, \n",
    "                                                            concept_name)[\"concept_bool_true\"]\n",
    "                concept_bool_test_false=get_concept_bool_from_metadata(dataset_name, \n",
    "                                                            metadata_all_test_, \n",
    "                                                            concept_name)[\"concept_bool_false\"]                    \n",
    "\n",
    "                if len(metadata_all_test_[concept_bool_test_true&(metadata_all_test_[\"y_pos\"]==True)])<30 or\\\n",
    "                len(metadata_all_test_[concept_bool_test_false&(metadata_all_test_[\"y_pos\"]==True)])<30 or\\\n",
    "                len(metadata_all_test_[concept_bool_test_true&(metadata_all_test_[\"y_pos\"]==False)])<30 or\\\n",
    "                len(metadata_all_test_[concept_bool_test_false&(metadata_all_test_[\"y_pos\"]==False)])<30:        \n",
    "                    print(\"Test Not found\")\n",
    "                    continue\n",
    "                #continue\n",
    "\n",
    "\n",
    "                test_idx_pos_with=metadata_all_test_[concept_bool_test_true&(metadata_all_test_[\"y_pos\"]==True)].sample(n=num_test_pos_with, replace=True, random_state=random_seed).index\n",
    "                test_idx_pos_without=metadata_all_test_[concept_bool_test_false&(metadata_all_test_[\"y_pos\"]==True)].sample(n=num_test_pos_without, replace=True, random_state=random_seed).index\n",
    "\n",
    "                test_idx_neg_with=metadata_all_test_[concept_bool_test_true&(metadata_all_test_[\"y_pos\"]==False)].sample(n=num_test_neg_with, replace=True, random_state=random_seed).index\n",
    "                test_idx_neg_without=metadata_all_test_[concept_bool_test_false&(metadata_all_test_[\"y_pos\"]==False)].sample(n=num_test_neg_without, replace=True, random_state=random_seed).index\n",
    "\n",
    "                test_idx=test_idx_pos_with.tolist()+test_idx_pos_without.tolist()+test_idx_neg_with.tolist()+test_idx_neg_without.tolist()\n",
    "\n",
    "\n",
    "                metadata_all_test=metadata_all_test_.loc[test_idx]\n",
    "                print(len(train_idx), len(test_idx))\n",
    "\n",
    "                train_dataloader, val_dataloader, test_dataloader=\\\n",
    "                get_training_data_idx(dataloader=dataloader, \n",
    "                                  valid_idx=concept_idx, \n",
    "                                  y_pos=y_pos, \n",
    "    #                               y_pos=variable_dict[dataset_name][\"dataloader\"].dataset.metadata_all[concept_name].fillna(0), \n",
    "                                  subset_idx_train=metadata_all_train.index, \n",
    "                                  #subset_idx_test=test_idx, \n",
    "                                  subset_idx_test=metadata_all_test.index,\n",
    "                                  n_px=None)            \n",
    "\n",
    "    #             print(len(train_dataloader))\n",
    "    #             print(len(val_dataloader))\n",
    "    #             print(len(test_dataloader))\n",
    "    #             subset_idx_train=\n",
    "\n",
    "                auc, x, logits_test, label_test, metadata_test, max_f1_thres =train_classifier(train_dataloader=train_dataloader, \n",
    "                                       val_dataloader=val_dataloader,\n",
    "                                       test_dataloader=test_dataloader, verbose=True)  \n",
    "\n",
    "                metadata_test=pd.concat(metadata_test)  \n",
    "                label_test=pd.Series(np.hstack(label_test), index=metadata_test.index)\n",
    "                logit_test=pd.Series(np.concatenate(logits_test)[:,0], index=metadata_test.index)\n",
    "\n",
    "                simulation_data_list.append({\"concept_name\": concept_name,\n",
    "                                             \"random_seed\": random_seed,\n",
    "                                             \"proportion\": proportion,\n",
    "                                             \"label_test\": label_test,\n",
    "                                             \"logit_test\": logit_test,\n",
    "                                             \"metadata_all_train\": metadata_all_train,\n",
    "                                             \"metadata_all_test\": metadata_all_test,\n",
    "                                             \"metadata_test\": metadata_test,\n",
    "                                             \"max_f1_thres\": max_f1_thres,\n",
    "                                            })\n",
    "    #             label_list=np.hstack(label_list)\n",
    "    #             logits_list=np.concatenate(logits_list)[:,0]\n",
    "    #             metadata_list=pd.concat(metadata_list)         \n",
    "\n",
    "    #         record_dict_list.append({\"concept_name\": concept_name})\n",
    "            print(concept_name)\n",
    "    return {\"model_auditing_simulation_data\": simulation_data_list}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645cb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"derm7pt_derm_nodup\"\n",
    "                    ]:\n",
    "    x=forced_training(dataset_name=dataset_name,\n",
    "                      dataloader=variable_dict[dataset_name][\"dataloader\"], \n",
    "                      concept_list=['derm7ptconcept_pigment network',\n",
    "                    'derm7ptconcept_regression structure',\n",
    "                    'derm7ptconcept_pigmentation',\n",
    "                    'derm7ptconcept_blue whitish veil',\n",
    "                    'derm7ptconcept_vascular structures',\n",
    "                    'derm7ptconcept_streaks',\n",
    "                    'derm7ptconcept_dots and globules'],\n",
    "                      metadata_all=variable_dict[dataset_name][\"metadata_all\"], \n",
    "                      y_pos=variable_dict[dataset_name][\"y_pos\"],\n",
    "                     random_seed_range=list(range(0,20))\n",
    "                     )\n",
    "#         variable_dict[dataset_name].update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa3c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"derm7pt_derm_nodup\"\n",
    "                    ]:\n",
    "    x=forced_training(dataset_name=dataset_name,\n",
    "                      dataloader=variable_dict[dataset_name][\"dataloader\"], \n",
    "                      concept_list=['derm7ptconcept_pigment network',\n",
    "                    'derm7ptconcept_regression structure',\n",
    "                    'derm7ptconcept_pigmentation',\n",
    "                    'derm7ptconcept_blue whitish veil',\n",
    "                    'derm7ptconcept_vascular structures',\n",
    "                    'derm7ptconcept_streaks',\n",
    "                    'derm7ptconcept_dots and globules'],\n",
    "                      metadata_all=variable_dict[dataset_name][\"metadata_all\"], \n",
    "                      y_pos=variable_dict[dataset_name][\"y_pos\"],\n",
    "                     random_seed_range=[0]\n",
    "                     )\n",
    "#         variable_dict[dataset_name].update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.936 0.37\n",
    "0.925 0.645\n",
    "0.934 0.590\n",
    "0.941 0.379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73972a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cc746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de959bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae28eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d40849",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"derm7pt_derm_nodup\"\n",
    "                    ]:\n",
    "    x=forced_training(dataset_name=dataset_name,\n",
    "                      dataloader=variable_dict[dataset_name][\"dataloader\"], \n",
    "                      concept_list=['derm7ptconcept_pigment network',\n",
    "                    'derm7ptconcept_regression structure',\n",
    "                    'derm7ptconcept_pigmentation',\n",
    "                    'derm7ptconcept_blue whitish veil',\n",
    "                    'derm7ptconcept_vascular structures',\n",
    "                    'derm7ptconcept_streaks',\n",
    "                    'derm7ptconcept_dots and globules'],\n",
    "                      metadata_all=variable_dict[dataset_name][\"metadata_all\"], \n",
    "                      y_pos=variable_dict[dataset_name][\"y_pos\"])\n",
    "#         variable_dict[dataset_name].update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595554e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca730d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\"\n",
    "                    ]:\n",
    "    x=forced_training(dataset_name=dataset_name,\n",
    "                      dataloader=variable_dict[dataset_name][\"dataloader\"], \n",
    "                      concept_list=skincon_cols, \n",
    "                      metadata_all=variable_dict[dataset_name][\"metadata_all\"], \n",
    "                      y_pos=variable_dict[dataset_name][\"y_pos\"])\n",
    "#         variable_dict[dataset_name].update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(variable_dict[\"derm7pt_derm_nodup\"][\"model_auditing_simulation_data\"])[\"concept_name\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97223919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pigment network, regression structure, pigment, streaks, vascular structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"model_auditing_simulation_data\"])[\"concept_name\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdeb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194843c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34234d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP / (TP+FP) * (TP+FN)/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109e4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf230d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427dba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"valid_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"metadata_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8353365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(variable_dict, \"logs/experiment_results/model_auditing_0827.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151209",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/experiment_results/ -trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict=torch.load(\"logs/experiment_results/model_auditing_0827.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(variable_dict[\"derm7pt_derm_nodup\"][\"model_auditing_simulation_data\"])[\"concept_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23dc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auditing_simulation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"evaluation_model_audit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f8de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ff29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(simulation_data_list, \"logs/experiment_results/model_audit_benchmark_0525.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation_data_list=torch.load(\"logs/experiment_results/model_audit_benchmark_0525.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data_list=torch.load(\"logs/experiment_results/model_audit_benchmark_0526.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(variable_dict, \"logs/experiment_results/model_audit_data_0526.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76138722",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict=torch.load(\"logs/experiment_results/model_audit_data_0526.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(simulation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_test\n",
    "\n",
    "# log_loss(y_pred=logit_test,\n",
    "#         y_true=label_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50830452",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25688725",
   "metadata": {},
   "source": [
    "current method+CLIP\n",
    "DOMINO+MONET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_info_copy=cluster_concept_test(similarity_info=concept_similarity_all,\n",
    "#                                    ground_truth=variable_dict[\"clinical_fd_clean_nodup\"][\"metadata_all\"][skincon_cols],\n",
    "#                                    clustering_features=concept_similarity_all,\n",
    "#                                    labels=label_test, logits=logit_test,\n",
    "#                                    threshold=0,\n",
    "#                                    score_threshold=0.8, accuracy_diff=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "def fisher_test_df(concept_list_bool_dict, y_pos):\n",
    "    res_df=[]\n",
    "    for concept_name, concept_bool in concept_list_bool_dict.items():\n",
    "#         print(column)\n",
    "#         print([[((data[column]==1)&(y_pos.loc[data.index]==True)).sum(), ((data[column]==0)&(y_pos.loc[data.index]==True)).sum()],\n",
    "#             [((data[column]==1)&(y_pos.loc[data.index]==False)).sum(), ((data[column]==0)&(y_pos.loc[data.index]==False)).sum()]])\n",
    "#         print(data.shape)\n",
    "#         print(((data[column]==1).shape,(y_pos.loc[data.index]==True).shape))\n",
    "\n",
    "        concept_bool_true=concept_bool[\"concept_bool_true\"]\n",
    "        concept_bool_false=concept_bool[\"concept_bool_false\"]\n",
    "\n",
    "        y_1_c_1=((y_pos==True)&(concept_bool_true)).sum()\n",
    "        y_1_c_0=((y_pos==True)&(concept_bool_false)).sum()\n",
    "        y_0_c_1=((y_pos==False)&(concept_bool_true)).sum()\n",
    "        y_0_c_0=((y_pos==False)&(concept_bool_false)).sum()\n",
    "    \n",
    "\n",
    "        res=fisher_exact(\n",
    "            [[y_1_c_1, y_1_c_0],\n",
    "            [y_0_c_1, y_0_c_0]])\n",
    "    \n",
    "#         rl_top=((data[column]==1)&(y_pos==True)).sum()/(((data[column]==1)).sum())\n",
    "#         rl_bottom=((data[column]==0)&(y_pos==True)).sum()/(((data[column]==0)).sum())\n",
    "        \n",
    "#         rl_top=((data[column]==1)&(y_pos==True)).sum()/(((y_pos==True)).sum())\n",
    "#         rl_bottom=((data[column]==1)&(y_pos==False)).sum()/(((y_pos==False)).sum())        \n",
    "#         print(res)\n",
    "        direction=(y_1_c_1-y_1_c_0)*(y_0_c_1-y_0_c_0)\n",
    "        \n",
    "        res_df.append({\"name\": concept_name,\n",
    "                       \"y=1,c=1\":y_1_c_1,\n",
    "                       \"y=1,c=0\":y_1_c_0,\n",
    "                       \"y=0,c=1\":y_0_c_1,\n",
    "                       \"y=0,c=0\":y_0_c_0,\n",
    "                       \"direction\":direction,\n",
    "                       \"direction1\":(y_1_c_1-y_1_c_0),\n",
    "                       \"direction2\":(y_0_c_1-y_0_c_0),                       \n",
    "#                        \"rl\": rl_top/ rl_bottom,\n",
    "                      \"pvalue\": res.pvalue,\n",
    "                       \"statistic\": res.statistic,\n",
    "                      })\n",
    "        \n",
    "#         print()\n",
    "    \n",
    "    res_df=pd.DataFrame(res_df).sort_values('statistic').set_index('name')\n",
    "    fdr_corrected=fdrcorrection(res_df[\"pvalue\"])\n",
    "    res_df[\"FDR_rejected\"]=fdr_corrected[0]\n",
    "    res_df[\"FDR_pvalue_adjusted\"]=fdr_corrected[1]    \n",
    "    res_df[\"bof_pvalue_adjusted\"]=res_df[\"pvalue\"]*len(res_df)\n",
    "    res_df[\"bof_pvalue_adjusted\"]=res_df[\"bof_pvalue_adjusted\"].map(lambda x:1 if x>1 else x)\n",
    "    #res_df[\"bof_rejected\"]=res_df[\"bof_pvalue_adjusted\"]<0.05\n",
    "    res_df[\"bof_rejected\"]=res_df[\"bof_pvalue_adjusted\"]<0.01\n",
    "    return res_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from scipy.stats import mode\n",
    "\n",
    "def cluster_concept_test_real(similarity_info, clustering_features, fixed_answer,\n",
    "                         labels, logits, threshold,\n",
    "                         metric_diff=0.5, metric_over=0,\n",
    "                         n_clusters=40, random_state=42, return_only_highperforming=True):\n",
    "    \n",
    "    torch.manual_seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)    \n",
    "    \n",
    "    record_list=[]\n",
    "    \n",
    "    per_label=False\n",
    "    \n",
    "    if per_label:\n",
    "        labels_unique=np.unique(labels)\n",
    "    else:\n",
    "        labels_unique=[None]\n",
    "        \n",
    "    for label in labels_unique:\n",
    "        if label is not None:\n",
    "            focus_idx=labels[labels==label].index\n",
    "\n",
    "            similarity_info_focus=similarity_info.loc[focus_idx].copy()\n",
    "            clustering_features_focus=clustering_features.loc[focus_idx].copy()\n",
    "            labels_focus=labels[labels==label].copy()\n",
    "            logits_focus=logits[labels==label].copy()\n",
    "        else:\n",
    "            focus_idx=labels[labels.astype(int)>-9].index\n",
    "\n",
    "            similarity_info_focus=similarity_info.loc[focus_idx].copy()\n",
    "            clustering_features_focus=clustering_features.loc[focus_idx].copy()\n",
    "            labels_focus=labels.copy()\n",
    "            logits_focus=logits.copy()            \n",
    "            \n",
    "            \n",
    "        assert (similarity_info_focus.index==clustering_features_focus.index).all()\n",
    "        assert (similarity_info_focus.index==labels_focus.index).all()\n",
    "        assert (similarity_info_focus.index==logits_focus.index).all()\n",
    "\n",
    "        if clustering_features_focus.shape[1]<50:\n",
    "            pca = PCA(n_components=10)\n",
    "        else:\n",
    "            pca = PCA(n_components=50)\n",
    "\n",
    "        clustering_features_focus_pc=pca.fit_transform(clustering_features_focus)\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=n_clusters//len(labels_unique), random_state=random_state, n_init=\"auto\").fit(clustering_features_focus_pc)\n",
    "        kmeans_dist=sklearn.metrics.pairwise_distances(kmeans.cluster_centers_)\n",
    "    \n",
    "        similarity_info_focus_copy=similarity_info_focus.copy()\n",
    "        similarity_info_focus_copy[\"kmeans_label\"]=kmeans.labels_\n",
    "        similarity_info_focus_copy[\"kmeans_dist\"]=((clustering_features_focus_pc-kmeans.cluster_centers_[kmeans.labels_])**2).sum(axis=1)\n",
    "        similarity_info_focus_copy[\"accuracy\"]=(labels_focus==(logits_focus>threshold))\n",
    "        similarity_info_focus_copy[\"loss\"]=-log_loss(y_true=labels_focus, y_pred=logits_focus.map(lambda x: 1/(1+np.exp(-x))), labels=[0,1])\n",
    "        similarity_info_focus_copy[\"label\"]=labels_focus\n",
    "        similarity_info_focus_copy[\"logit\"]=logits_focus\n",
    "        \n",
    "        similarity_info_focus_copy_group=similarity_info_focus_copy.groupby(\"kmeans_label\")[similarity_info.columns.tolist()].apply(lambda x: pd.Series([x[i].values for i in x.columns], index=x.columns))\n",
    "        similarity_info_focus_copy_group[\"count\"]=similarity_info_focus_copy.groupby(\"kmeans_label\").apply(len)\n",
    "        similarity_info_focus_copy_group[\"accuracy\"]=similarity_info_focus_copy.groupby(\"kmeans_label\")[\"accuracy\"].mean()\n",
    "        similarity_info_focus_copy_group[\"loss\"]=similarity_info_focus_copy.groupby(\"kmeans_label\")[\"loss\"].mean()\n",
    "        similarity_info_focus_copy_group[\"label_frequent\"]=similarity_info_focus_copy.groupby(\"kmeans_label\")[\"label\"].apply(lambda x: mode(x, keepdims=False).mode)\n",
    "\n",
    "        metric_use=\"accuracy\"\n",
    "\n",
    "        for count, (idx, row) in enumerate(similarity_info_focus_copy_group.sort_values(metric_use, ascending=True).iterrows()):\n",
    "            if return_only_highperforming:\n",
    "                if row[metric_use]>=similarity_info_focus_copy[metric_use].mean():\n",
    "                    continue\n",
    "            \n",
    "\n",
    "            sorted_idx=pd.Series(kmeans_dist[idx], index=sorted(np.unique(kmeans.labels_))).sort_values(ascending=True).index\n",
    "            sorted_idx=[i for i in sorted_idx if (similarity_info_focus_copy_group.loc[i][metric_use]>(similarity_info_focus_copy[metric_use].mean()+metric_diff)) and \\\n",
    "                        (similarity_info_focus_copy_group.loc[i][metric_use]>=(metric_over))\n",
    "                       ]\n",
    "            \n",
    "            similarity_info_focus_copy_group_diff_plus=similarity_info_focus_copy_group.copy().loc[[sorted_idx[0]]]\n",
    "#             print(similarity_info_focus_copy_group_diff_plus)\n",
    "            similarity_info_focus_copy_group_diff_plus[similarity_info.columns.tolist()]=similarity_info_focus_copy_group_diff_plus[similarity_info.columns.tolist()].apply(lambda x: pd.Series([(np.mean(row[i])-np.mean(x.loc[i])) for i in x.index], index=x.index), axis=1)\n",
    "    \n",
    "            x=pd.concat([\n",
    "                similarity_info_focus_copy_group_diff_plus[similarity_info.columns.tolist()].loc[sorted_idx[0]].rename('diff_magnitude'),\n",
    "                row[similarity_info.columns.tolist()].map(lambda x: np.mean(x)).rename(\"mean_value\")\n",
    "            ],\n",
    "                axis=1)\n",
    "#             print(x.sort_values(\"diff_magnitude\", ascending=False))    \n",
    "\n",
    "#             print(f\"cluster_idx {count} / \\\n",
    "# Target metric: {row[metric_use]:.3f} / \\\n",
    "# Ref metric: {similarity_info_focus_copy_group.loc[sorted_idx[0]][metric_use]:.3f}/ \\\n",
    "# Target concept: {np.mean(row['purple pen']):.3f}/ \\\n",
    "# Ref concept: {np.mean(similarity_info_focus_copy_group.loc[sorted_idx[0]]['purple pen']):.3f}/ \\\n",
    "# Mean metric:  {similarity_info_focus_copy[metric_use].mean():.3f}\\\n",
    "# \")\n",
    "#             print(np.mean(row['purple pen']),\n",
    "#                   np.mean(similarity_info_focus_copy_group.loc[sorted_idx[0]]['purple pen'])\n",
    "#                  ) \n",
    "            #sdsd\n",
    "                        \n",
    "            similarity_info_focus_copy_group_diff_minus=similarity_info_focus_copy_group.copy().loc[[sorted_idx[0]]]\n",
    "            similarity_info_focus_copy_group_diff_minus[similarity_info.columns.tolist()]=similarity_info_focus_copy_group_diff_minus[similarity_info.columns.tolist()].apply(lambda x: pd.Series([-(np.mean(row[i])-np.mean(x.loc[i])) for i in x.index], index=x.index), axis=1)            \n",
    "            #import ipdb\n",
    "            #ipdb.set_trace()\n",
    "            \n",
    "#             print('-------')\n",
    "#             print(x.sort_values('diff_magnitude', ascending=True).index==similarity_info_focus_copy_group_diff_minus[similarity_info.columns.tolist()].loc[sorted_idx[0]].sort_values(ascending=False).index.tolist())\n",
    "#             print(x.sort_values('diff_magnitude', ascending=True))\n",
    "#             print(idx, sorted_idx)\n",
    "            \n",
    "            \n",
    "            \n",
    "            record_list.append(\n",
    "                { \n",
    "#                  \"on_the_spot_plus_pred\": similarity_info_focus_copy_group_diff_plus[similarity_info.columns.tolist()].loc[sorted_idx[0]].sort_values(ascending=False).index.tolist(),\n",
    "#                  \"on_the_spot_minus_pred\": similarity_info_focus_copy_group_diff_minus[similarity_info.columns.tolist()].loc[sorted_idx[0]].sort_values(ascending=False).index.tolist(),\n",
    "                 \"on_the_spot_plus_pred\": x[(x[\"mean_value\"]>0.5)&(x[\"diff_magnitude\"]>0)].sort_values(\"diff_magnitude\", ascending=False).index.tolist(),\n",
    "                 \"on_the_spot_minus_pred\": x[(x[\"mean_value\"]>0.5)&(x[\"diff_magnitude\"]<0)].sort_values(\"diff_magnitude\", ascending=True).index.tolist(),                    \n",
    "                 \"statistics\": x,\n",
    "                 \"labels\": similarity_info_focus_copy[(similarity_info_focus_copy[\"kmeans_label\"]==idx)][[\"kmeans_dist\", metric_use]],\n",
    "                 \"labels_ref\": similarity_info_focus_copy[(similarity_info_focus_copy[\"kmeans_label\"]==sorted_idx[0])][[\"kmeans_dist\", metric_use]]                 \n",
    "                })\n",
    "#             print(record_list[-1][\"statistics\"].sort_values(\"diff_magnitude\", ascending=False).index==record_list[-1][\"on_the_spot_minus_pred\"]).all()\n",
    "    \n",
    "    return record_list, similarity_info_focus_copy_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list_temp, similarity_info_focus_copy_group_temp =\\\n",
    "\\\n",
    "cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_proveai, \n",
    "                          logits=logits_subset_proveai, \n",
    "                          threshold=threshold_select,\n",
    "                         metric_diff=0,\n",
    "                          metric_over=0,\n",
    "                         n_clusters=10, random_state=42, return_only_highperforming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f01976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5163c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c49b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list_temp, similarity_info_focus_copy_group_temp =\\\n",
    "\\\n",
    "cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_proveai, \n",
    "                          logits=logits_subset_proveai, \n",
    "                          threshold=threshold_select,\n",
    "                         metric_diff=0,\n",
    "                          metric_over=0.5,\n",
    "                         n_clusters=10, random_state=42, return_only_highperforming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd97d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e87205",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_info_focus_copy_group_temp.sort_values(\"accuracy\")[\n",
    "    [\"count\",\"accuracy\",\"loss\", \"label_frequent\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6500ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319cd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_info_focus_copy_group_diff_plus.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_info_focus_copy_group_diff_plus.iloc[0].loc[\"skincon_Vesicle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9c254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60e423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43941c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a670da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_model_audit(dataset_name,\n",
    "                         simulation_data_list,\n",
    "                         similarity_matrix,\n",
    "                         similarity_matrix_vanilla,\n",
    "                         efficientnet_feature,\n",
    "                         metadata_all,\n",
    "                         concept_list\n",
    "                        ):\n",
    "    \n",
    "    def get_ground_truth_on_the_spot(ground_truth, target_idx, reference_idx):\n",
    "        ground_truth_copy=ground_truth.copy()\n",
    "        \n",
    "        ground_truth_copy_target={concept_name: concept_bool[\"concept_bool_true\"].copy().loc[target_idx] for concept_name, concept_bool in ground_truth.items()}\n",
    "        ground_truth_copy_reference={concept_name: concept_bool[\"concept_bool_true\"].copy().loc[reference_idx] for concept_name, concept_bool in ground_truth.items()}\n",
    "    \n",
    "        ground_truth_copy_target=(pd.DataFrame(ground_truth_copy_target).mean(axis=0)>0.5).astype(int)\n",
    "        ground_truth_copy_reference=(pd.DataFrame(ground_truth_copy_reference).mean(axis=0)>0.5).astype(int)\n",
    "        ground_truth_copy_target_diff=ground_truth_copy_target-ground_truth_copy_reference\n",
    "        return {\"more_present\":ground_truth_copy_target_diff[ground_truth_copy_target_diff>0].index,\n",
    "                \"less_present\":ground_truth_copy_target_diff[ground_truth_copy_target_diff<0].index}\n",
    "                \n",
    "                \n",
    "    record_dict_all=[]\n",
    "    for simulation_count, simulation_data in enumerate(tqdm.tqdm(simulation_data_list)):\n",
    "#         if simulation_count not in [0,20,40,60,80]:\n",
    "#             continue\n",
    "        concept_name=simulation_data[\"concept_name\"]\n",
    "        label_test=simulation_data[\"label_test\"]\n",
    "        logit_test=simulation_data[\"logit_test\"]\n",
    "        metadata_train=simulation_data[\"metadata_all_train\"]        \n",
    "        metadata_test=simulation_data[\"metadata_all_test\"]                \n",
    "#         metadata_test=simulation_data[\"metadata_test\"]\n",
    "        max_f1_thres=simulation_data[\"max_f1_thres\"]\n",
    "        random_seed=simulation_data[\"random_seed\"]\n",
    "        \n",
    "        print(\"metadata_train\",metadata_train.shape)\n",
    "        print(\"metadata_test\",metadata_train.shape)\n",
    "        print(\"label_test\",label_test.shape)\n",
    "        print(\"logit_test\",logit_test.shape)\n",
    "    \n",
    "             \n",
    "        \n",
    "        fisher_pvals_train = fisher_test_df(concept_list_bool_dict={i:get_concept_bool_from_metadata(dataset_name, metadata_train, i) for i in concept_list}, \n",
    "                                           y_pos=metadata_train[\"y_pos\"])\n",
    "        \n",
    "        fisher_pvals_test = fisher_test_df(concept_list_bool_dict={i:get_concept_bool_from_metadata(dataset_name, metadata_test, i) for i in concept_list}, \n",
    "                                           y_pos=metadata_test[\"y_pos\"])        \n",
    "        \n",
    "#         print(fisher_pvals_train)\n",
    "#         print(fisher_pvals_test)\n",
    "        \n",
    "        test_less_represented=fisher_pvals_train[(fisher_pvals_train[\"direction\"]<0)&(fisher_pvals_train[\"statistic\"]>1)].index\\\n",
    "        .intersection(fisher_pvals_test[(fisher_pvals_test[\"direction\"]<0)&(fisher_pvals_test[\"statistic\"]<1)].index)\n",
    "        \n",
    "        test_more_represented=fisher_pvals_train[(fisher_pvals_train[\"direction\"]<0)&(fisher_pvals_train[\"statistic\"]<1)].index\\\n",
    "        .intersection(fisher_pvals_test[(fisher_pvals_test[\"direction\"]<0)&(fisher_pvals_test[\"statistic\"]>1)].index)\n",
    "        \n",
    "        test_more_represented_=fisher_pvals_train[(fisher_pvals_train[\"direction1\"]>0)&(fisher_pvals_train[\"direction2\"]<0)].index\\\n",
    "        .intersection(fisher_pvals_test[(fisher_pvals_test[\"direction1\"]<0)&(fisher_pvals_test[\"direction2\"]>0)].index)\n",
    "        \n",
    "        test_less_represented_=fisher_pvals_train[(fisher_pvals_train[\"direction1\"]<0)&(fisher_pvals_train[\"direction2\"]>0)].index\\\n",
    "        .intersection(fisher_pvals_test[(fisher_pvals_test[\"direction1\"]>0)&(fisher_pvals_test[\"direction2\"]<0)].index)        \n",
    "        \n",
    "        print(concept_name, \"Train-/Test+\", test_more_represented.tolist(), \"Train+/Test-\", test_less_represented.tolist())\n",
    "        print(\"Test\",concept_name, \"Train-/Test+\", test_more_represented_.tolist(), \"Train+/Test-\", test_less_represented_.tolist())\n",
    "                \n",
    "        fixed_answer=test_more_represented.tolist()+test_less_represented.tolist()\n",
    "\n",
    "        if len(concept_list)<47:\n",
    "            concept_name_test_list=concept_list+np.random.RandomState(random_seed).choice([i for i in skincon_cols if i not in ['skincon_Brown(Hyperpigmentation)','skincon_White(Hypopigmentation)','skincon_Blue', 'skincon_Pigmented']], size=48-len(concept_list), replace=False).tolist()\n",
    "        else:\n",
    "            concept_name_test_list=concept_list        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(similarity_matrix)\n",
    "#         print(similarity_matrix_vanilla)\n",
    "#         dsds\n",
    "        \n",
    "        test_result_MONET=cluster_concept_test_real(similarity_info=similarity_matrix[concept_name_test_list],\n",
    "                                                    clustering_features=pd.DataFrame(efficientnet_feature.numpy(),\n",
    "                                                                     index=metadata_all.index,\n",
    "                                                                    ),\n",
    "                                                    fixed_answer=fixed_answer,\n",
    "                                                    labels=label_test, logits=logit_test,\n",
    "                                                    threshold=max_f1_thres,\n",
    "        #                                            score_threshold=0.8, \n",
    "                                                    metric_diff=0,\n",
    "                                                    n_clusters=40)[0]\n",
    "        \n",
    "        test_result_vanilla=cluster_concept_test_real(similarity_info=similarity_matrix_vanilla[concept_name_test_list],\n",
    "                                                    clustering_features=pd.DataFrame(efficientnet_feature.numpy(),\n",
    "                                                                     index=metadata_all.index,\n",
    "                                                                    ),\n",
    "                                                    fixed_answer=fixed_answer,\n",
    "                                                    labels=label_test, logits=logit_test,\n",
    "                                                    threshold=max_f1_thres,\n",
    "        #                                            score_threshold=0.8, \n",
    "                                                    metric_diff=0,\n",
    "                                                    n_clusters=40)[0]\n",
    "        \n",
    "        \n",
    "        for model in [\"MONET\", \"CLIP\"]:\n",
    "            if model==\"MONET\":\n",
    "                test_result_list=test_result_MONET\n",
    "            elif model==\"CLIP\":\n",
    "                test_result_list=test_result_vanilla\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "            for test_result in test_result_list:\n",
    "#                 ground_truth_on_the_spot=get_ground_truth_on_the_spot(ground_truth=metadata_all[skincon_cols], \n",
    "#                                              target_idx=test_result[\"labels\"].index, \n",
    "#                                              reference_idx=test_result[\"labels_ref\"].index)\n",
    "                ground_truth_on_the_spot=get_ground_truth_on_the_spot(ground_truth={i:get_concept_bool_from_metadata(dataset_name, metadata_all, i) for i in concept_list}, \n",
    "                                             target_idx=test_result[\"labels\"].index, \n",
    "                                             reference_idx=test_result[\"labels_ref\"].index)                \n",
    "        \n",
    "#                 print(model, len(test_result_list), len(test_result[\"labels\"]))\n",
    "#                 print(test_result.keys(), len(concept_name_test_list),concept_name_test_list)\n",
    "                for i in range(1,5+1):\n",
    "                    if i>len(test_result[\"on_the_spot_plus_pred\"]):\n",
    "                        continue\n",
    "                    record_dict_all.append({\n",
    "                        \"model\": model,\n",
    "                        \"method\": \"on_the_spot_plus\",\n",
    "                        \"rank_n\": i,\n",
    "                        \"metric\": len(set(ground_truth_on_the_spot[\"more_present\"]).intersection(test_result[\"on_the_spot_plus_pred\"][:i]))!=0,\n",
    "                        \"answer_length\": len(set(ground_truth_on_the_spot[\"more_present\"])),\n",
    "                        \"random_performance\": 1-(math.perm(len(concept_name_test_list)-len(set(ground_truth_on_the_spot[\"more_present\"])), i) / math.perm(len(concept_name_test_list), i)),\n",
    "                        \"target_group_size\": len(test_result[\"labels\"]),\n",
    "                        \"random_seed\":random_seed,\n",
    "                    })\n",
    "\n",
    "                for i in range(1,5+1):\n",
    "                    if i>len(test_result[\"on_the_spot_minus_pred\"]):\n",
    "                        continue                 \n",
    "                    record_dict_all.append({\n",
    "                        \"model\": model,\n",
    "                        \"method\": \"on_the_spot_minus\",\n",
    "                        \"rank_n\": i,\n",
    "                        \"metric\": len(set(ground_truth_on_the_spot[\"less_present\"]).intersection(test_result[\"on_the_spot_minus_pred\"][:i]))!=0,\n",
    "                        \"answer_length\": len(set(ground_truth_on_the_spot[\"less_present\"])),\n",
    "                        \"target_group_size\": len(test_result[\"labels\"]),\n",
    "                        \"random_seed\":random_seed,\n",
    "                    })  \n",
    "                    \n",
    "#                 for i in range(1,5+1):\n",
    "#                     record_dict_all.append({\n",
    "#                         \"model\": model,\n",
    "#                         \"method\": \"on_the_spot_both\",\n",
    "#                         \"rank_n\": i,\n",
    "#                         \"metric\": len(set(ground_truth_on_the_spot[\"more_present\"]).intersection(test_result[\"on_the_spot_plus_pred\"][:i]))!=0 and len(set(ground_truth_on_the_spot[\"less_present\"]).intersection(test_result[\"on_the_spot_minus_pred\"][:i]))!=0,\n",
    "#                     })                      \n",
    "                    \n",
    "            for i in range(1,5+1):      \n",
    "                record_dict_all.append({\n",
    "                    \"model\": model,\n",
    "                    \"method\": \"fixed_answer_plus\",\n",
    "                    \"answer_length\": len(set(fixed_answer)),\n",
    "                    \"count\": len(test_result_list),\n",
    "                    \"rank_n\": i,\n",
    "                    \"metric\": len(set(fixed_answer).intersection([p for test_result in test_result_list for p in test_result[\"on_the_spot_plus_pred\"][:i]]))!=0,\n",
    "                    \"random_performance\": 1-(math.comb(len(concept_name_test_list)-len(set(fixed_answer)), i) / math.comb(len(concept_name_test_list), i))**len(test_result_list),\n",
    "                    \"random_seed\":random_seed,\n",
    "                })    \n",
    "                \n",
    "            for i in range(1,5+1):\n",
    "                record_dict_all.append({\n",
    "                    \"model\": model,\n",
    "                    \"method\": \"fixed_answer_minus\",\n",
    "                    \"answer_length\": len(set(fixed_answer)),\n",
    "                    \"count\": len(test_result_list),\n",
    "                    \"rank_n\": i,\n",
    "                    \"metric\": len(set(fixed_answer).intersection([p for test_result in test_result_list for p in test_result[\"on_the_spot_minus_pred\"][:i]]))!=0,\n",
    "                    \"random_seed\":random_seed,\n",
    "                })    \n",
    "        \n",
    "    return record_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657e1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"derm7pt_derm_nodup\"]:\n",
    "    x=evaluate_model_audit(dataset_name=dataset_name,\n",
    "                         simulation_data_list=variable_dict[dataset_name][\"model_auditing_simulation_data\"],\n",
    "                         similarity_matrix=variable_dict[dataset_name][\"similarity_matrix\"],\n",
    "                         similarity_matrix_vanilla=variable_dict[dataset_name][\"similarity_matrix_vanilla\"],\n",
    "                         efficientnet_feature=variable_dict[dataset_name][\"efficientnet_feature\"],\n",
    "                         metadata_all=variable_dict[dataset_name][\"metadata_all\"],\n",
    "                         concept_list=['derm7ptconcept_pigment network',\n",
    "                                        'derm7ptconcept_regression structure',\n",
    "                                        'derm7ptconcept_pigmentation',\n",
    "                                        'derm7ptconcept_blue whitish veil',\n",
    "                                        'derm7ptconcept_vascular structures',\n",
    "                                        'derm7ptconcept_streaks',\n",
    "                                        'derm7ptconcept_dots and globules'],\n",
    "                        )\n",
    "#     variable_dict[dataset_name].update(\n",
    "#         {\"evaluation_model_audit\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73433acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\"]:\n",
    "    x=evaluate_model_audit(dataset_name=dataset_name,\n",
    "                         simulation_data_list=variable_dict[dataset_name][\"model_auditing_simulation_data\"],\n",
    "                         similarity_matrix=variable_dict[dataset_name][\"similarity_matrix\"],\n",
    "                         similarity_matrix_vanilla=variable_dict[dataset_name][\"similarity_matrix_vanilla\"],\n",
    "                         efficientnet_feature=variable_dict[dataset_name][\"efficientnet_feature\"],\n",
    "                         metadata_all=variable_dict[dataset_name][\"metadata_all\"],\n",
    "                         concept_list=skincon_cols,\n",
    "                        )\n",
    "#     variable_dict[dataset_name].update(\n",
    "#         {\"evaluation_model_audit\": x})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cee5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4f778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"model_auditing_simulation_data\"][0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c4760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup_nooverlap\"]:\n",
    "    evaluate_model_audit(simulation_data_list,\n",
    "                         concept_list=variable_dict[dataset_name][\"concept_list\"],\n",
    "                         similarity_matrix=variable_dict[dataset_name][\"similarity_matrix\"],\n",
    "                         similarity_matrix_vanilla=variable_dict[dataset_name][\"similarity_matrix_vanilla\"],\n",
    "                         efficientnet_feature=variable_dict[dataset_name][\"efficientnet_feature\"],\n",
    "                         metadata_all=variable_dict[dataset_name][\"metadata_all\"],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c979f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"similarity_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"similarity_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9996dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"similarity_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49501f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"clinical_fd_clean_nodup_nooverlap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ebf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"efficientnet_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"].shape,\n",
    "variable_dict[dataset_name][\"similarity_matrix_vanilla\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981af36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d08cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"similarity_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a927d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a84fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b94023",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"concept_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa977511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3042eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_audit(simulation_data_list=simulation_data_list[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11657e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fd708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad243232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0088107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b306fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(math.comb(48-2, 1) / math.comb(48, 1))**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(math.comb(48-2, 2) / math.comb(48, 2))**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ca2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(math.comb(48-2, 4) / math.comb(48, 4))**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df[eval_result_df[\"method\"]==\"fixed_answer_plus\"].groupby([\"method\", \"rank_n\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd667e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(math.perm(48-len(set(ground_truth_on_the_spot[\"more_present\"])), i) / math.perm(48, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df[(eval_result_df[\"method\"]==\"fixed_answer_plus\")].groupby([\"rank_n\", \"method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9faffaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "474560b1",
   "metadata": {},
   "source": [
    "# generate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df.plot(x=\"random_performance\", y=\"random_performance_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db128ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"derm7pt_derm_nodup\"][\"evaluation_model_audit\"]\n",
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"evaluation_model_audit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36757a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_result_df[eval_result_df[\"method\"]==\"fixed_answer_minus\"][\"answer_length\"].hist()\n",
    "# eval_result_df[eval_result_df[\"method\"]==\"on_the_spot_minus\"][\"answer_length\"].hist()\n",
    "# eval_result=evaluate_model_audit(simulation_data_list=\n",
    "# [\n",
    "#     simulation_data_list[0],\n",
    "#     simulation_data_list[20],\n",
    "#     simulation_data_list[40],\n",
    "#     simulation_data_list[60],\n",
    "#     simulation_data_list[80],    \n",
    "\n",
    "# ])\n",
    "# eval_result=evaluate_model_audit(simulation_data_list=simulation_data_list)\n",
    "eval_result_df=pd.DataFrame(variable_dict[\"derm7pt_derm_nodup\"][\"evaluation_model_audit\"])\n",
    "# eval_result_df=pd.DataFrame(x)\n",
    "eval_result_df[\"metric_random_ratio\"]=eval_result_df[\"metric\"].astype(int)/eval_result_df[\"random_performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c41a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data_list[0][\"concept_name\"],\\\n",
    "simulation_data_list[20][\"concept_name\"],\\\n",
    "simulation_data_list[40][\"concept_name\"],\\\n",
    "simulation_data_list[60][\"concept_name\"],\\\n",
    "simulation_data_list[80][\"concept_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_dict[\"clinical_fd_clean_nodup\"][\"metadata_all\"][\n",
    "# (variable_dict[\"clinical_fd_clean_nodup\"][\"metadata_all\"][\"skincon_Crust\"]==0)\n",
    "# &(variable_dict[\"clinical_fd_clean_nodup\"][\"y_pos\"]==False)\n",
    "# ].iloc[5:]\n",
    "# variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset.getitem(\n",
    "# variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset.metadata_all.index.tolist().index(\n",
    "# \"7d2f3fa05f4f362299c1ed148e7fc719.jpg\")\n",
    "# )[\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfacbd",
   "metadata": {},
   "source": [
    "# one ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0590a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "# fig = plt.figure(constrained_layout=True, figsize=(15, 6))\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "subfigs = fig.subfigures(1, 1)\n",
    "\n",
    "axes = subfigs.subplots(1,1, gridspec_kw={\"wspace\":0.3})\n",
    "\n",
    "# axd={'fixed': axes[0], \"on_the_spot\": axes[1] }\n",
    "axd={'fixed': axes,}\n",
    "\n",
    "plot_key=\"fixed\"\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"], \n",
    "#             data=eval_result_df[(eval_result_df[\"method\"]==\"fixed_answer_plus\")&(eval_result_df[\"rank_n\"]<=3)],\n",
    "#            ax=axd[plot_key])\n",
    "\n",
    "eval_result_df_mean_fixed=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\"]).mean()\n",
    "print(eval_result_df_mean_fixed)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_fixed).reset_index(),\n",
    "    width=0.5,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "\n",
    "# plt.title(\"\\\n",
    "# ground-truth is defined based on distribution of train/test set\\\n",
    "# \\n(i.e., similar to the `red` confounder in the ISIC)\")\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_linewidth(1.5)\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=0.4, alpha=0.4)\n",
    "# axd[plot_key].yaxis.grid(True, which='minor', linewidth=0.2, alpha=0.4)\n",
    "\n",
    "axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='both', which='major', labelsize=16)\n",
    "axd[plot_key].tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "axd[plot_key].set_xlabel(\"Top-N\", fontsize=18)\n",
    "# axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\\n(across all underperforming clusters)\", fontsize=16)\n",
    "axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\", fontsize=18)\n",
    "\n",
    "for patch in axd[plot_key].patches :\n",
    "    patch.set_linewidth(1)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "\n",
    "\n",
    "    \n",
    "# leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5)\n",
    "axd[plot_key].get_legend().remove()\n",
    "axd[plot_key].text(x=-0.1, \n",
    "                   y=1.09, \n",
    "#                    y=1.03, \n",
    "                   transform=axd[plot_key].transAxes,\n",
    "                     s=\" B.\", fontsize=23, weight='bold')\n",
    "# leg.set_title(\"Model\", prop={\"size\":16})\n",
    "\n",
    "\n",
    "# axd[plot_key].set_title(\"Do the top N rec spurious correlation\", fontsize=16)\n",
    "axd[plot_key].set_title(\"Do the top-N concept explanations recover spurious correlations?\\n(across all low-performing clusters)\", \n",
    "                        fontsize=18)\n",
    "\n",
    "\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "# fig = plt.figure(constrained_layout=True, figsize=(15, 6))\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "subfigs = fig.subfigures(1, 1)\n",
    "\n",
    "axes = subfigs.subplots(1,2, gridspec_kw={\"wspace\":0.3})\n",
    "\n",
    "axd={'fixed': axes[0], \"on_the_spot\": axes[1] }\n",
    "\n",
    "plot_key=\"fixed\"\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"], \n",
    "#             data=eval_result_df[(eval_result_df[\"method\"]==\"fixed_answer_plus\")&(eval_result_df[\"rank_n\"]<=3)],\n",
    "#            ax=axd[plot_key])\n",
    "\n",
    "eval_result_df_mean_fixed=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\", \"random_seed\"]).mean()\n",
    "print(eval_result_df_mean_fixed)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_fixed).reset_index(),\n",
    "    width=0.7,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "# plt.title(\"\\\n",
    "# ground-truth is defined based on distribution of train/test set\\\n",
    "# \\n(i.e., similar to the `red` confounder in the ISIC)\")\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_linewidth(1.5)\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=0.4, alpha=0.4)\n",
    "# axd[plot_key].yaxis.grid(True, which='minor', linewidth=0.2, alpha=0.4)\n",
    "\n",
    "axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='both', which='major', labelsize=16)\n",
    "axd[plot_key].tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "axd[plot_key].set_xlabel(\"Top-N\", fontsize=18)\n",
    "# axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\\n(across all underperforming clusters)\", fontsize=16)\n",
    "axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\", fontsize=18)\n",
    "\n",
    "for patch in axd[plot_key].patches :\n",
    "    patch.set_linewidth(1)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "\n",
    "\n",
    "    \n",
    "# leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5)\n",
    "# axd[plot_key].get_legend().remove()\n",
    "leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5, ncols=2,\n",
    "                         loc='upper center', bbox_to_anchor=(0.487, -0.13, 0, 0), \n",
    "                        \n",
    "                        )\n",
    "leg.set_title(\"\", prop={\"size\":16})\n",
    "\n",
    "axd[plot_key].text(x=-0.2, \n",
    "                   y=1.09, \n",
    "#                    y=1.03, \n",
    "                   transform=axd[plot_key].transAxes,\n",
    "                     s=\" B.\", fontsize=23, weight='bold')\n",
    "# leg.set_title(\"Model\", prop={\"size\":16})\n",
    "\n",
    "\n",
    "# axd[plot_key].set_title(\"Do the top N rec spurious correlation\", fontsize=16)\n",
    "axd[plot_key].set_title(\"Do the top-N concept explanations recover spurious correlations?\\n(across all low-performing clusters)\", \n",
    "                        fontsize=18)\n",
    "\n",
    "plot_key=\"on_the_spot\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric_random_ratio\", hue=\"model\", \n",
    "# data=eval_result_df[\n",
    "#     (eval_result_df[\"method\"]==\"on_the_spot_plus\")\n",
    "#     &(eval_result_df[\"answer_length\"]!=0)\n",
    "#     &(eval_result_df[\"rank_n\"]<=3)], ax=axd[plot_key])\n",
    "\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_visible(False)\n",
    "    \n",
    "axd[plot_key].tick_params(left = False, right = False , labelleft = False ,\n",
    "            labelbottom = False, bottom = False)\n",
    "\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_derm7pt.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_derm7pt.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_derm7pt.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_derm7pt.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df_mean_fixed=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\"]).mean()\n",
    "print(eval_result_df_mean_fixed)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_fixed).reset_index(),\n",
    "    width=0.7,\n",
    "    ax=axd[plot_key]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0106879",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\", \"random_seed\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882af721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2560c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup_nooverlap\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_result_df[eval_result_df[\"method\"]==\"fixed_answer_minus\"][\"answer_length\"].hist()\n",
    "# eval_result_df[eval_result_df[\"method\"]==\"on_the_spot_minus\"][\"answer_length\"].hist()\n",
    "# eval_result=evaluate_model_audit(simulation_data_list=\n",
    "# [\n",
    "#     simulation_data_list[0],\n",
    "#     simulation_data_list[20],\n",
    "#     simulation_data_list[40],\n",
    "#     simulation_data_list[60],\n",
    "#     simulation_data_list[80],    \n",
    "\n",
    "# ])\n",
    "# eval_result=evaluate_model_audit(simulation_data_list=simulation_data_list)\n",
    "eval_result_df=pd.DataFrame(variable_dict[\"clinical_fd_clean_nodup_nooverlap\"][\"evaluation_model_audit\"])\n",
    "eval_result_df[\"metric_random_ratio\"]=eval_result_df[\"metric\"].astype(int)/eval_result_df[\"random_performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb25ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "# fig = plt.figure(constrained_layout=True, figsize=(15, 6))\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "subfigs = fig.subfigures(1, 1)\n",
    "\n",
    "axes = subfigs.subplots(1,2, gridspec_kw={\"wspace\":0.3})\n",
    "\n",
    "axd={'fixed': axes[0], \"on_the_spot\": axes[1] }\n",
    "\n",
    "plot_key=\"fixed\"\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"], \n",
    "#             data=eval_result_df[(eval_result_df[\"method\"]==\"fixed_answer_plus\")&(eval_result_df[\"rank_n\"]<=3)],\n",
    "#            ax=axd[plot_key])\n",
    "\n",
    "eval_result_df_mean_fixed=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\"]).mean()\n",
    "print(eval_result_df_mean_fixed)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_fixed).reset_index(),\n",
    "    width=0.7,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "\n",
    "# plt.title(\"\\\n",
    "# ground-truth is defined based on distribution of train/test set\\\n",
    "# \\n(i.e., similar to the `red` confounder in the ISIC)\")\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_linewidth(1.5)\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=0.4, alpha=0.4)\n",
    "# axd[plot_key].yaxis.grid(True, which='minor', linewidth=0.2, alpha=0.4)\n",
    "\n",
    "axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='both', which='major', labelsize=16)\n",
    "axd[plot_key].tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "axd[plot_key].set_xlabel(\"Top-N\", fontsize=18)\n",
    "# axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\\n(across all underperforming clusters)\", fontsize=16)\n",
    "axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\", fontsize=18)\n",
    "\n",
    "for patch in axd[plot_key].patches :\n",
    "    patch.set_linewidth(1)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "\n",
    "\n",
    "    \n",
    "# leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5)\n",
    "# axd[plot_key].get_legend().remove()\n",
    "leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5, ncols=2,\n",
    "                         loc='upper center', bbox_to_anchor=(0.487, -0.13, 0, 0), \n",
    "                        \n",
    "                        )\n",
    "leg.set_title(\"\", prop={\"size\":16})\n",
    "\n",
    "axd[plot_key].text(x=-0.2, \n",
    "                   y=1.09, \n",
    "#                    y=1.03, \n",
    "                   transform=axd[plot_key].transAxes,\n",
    "                     s=\" B.\", fontsize=23, weight='bold')\n",
    "# leg.set_title(\"Model\", prop={\"size\":16})\n",
    "\n",
    "\n",
    "# axd[plot_key].set_title(\"Do the top N rec spurious correlation\", fontsize=16)\n",
    "axd[plot_key].set_title(\"Do the top-N concept explanations recover spurious correlations?\\n(across all low-performing clusters)\", \n",
    "                        fontsize=18)\n",
    "\n",
    "plot_key=\"on_the_spot\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric_random_ratio\", hue=\"model\", \n",
    "# data=eval_result_df[\n",
    "#     (eval_result_df[\"method\"]==\"on_the_spot_plus\")\n",
    "#     &(eval_result_df[\"answer_length\"]!=0)\n",
    "#     &(eval_result_df[\"rank_n\"]<=3)], ax=axd[plot_key])\n",
    "\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_visible(False)\n",
    "    \n",
    "axd[plot_key].tick_params(left = False, right = False , labelleft = False ,\n",
    "            labelbottom = False, bottom = False)\n",
    "\n",
    "fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_skincon.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_skincon.jpg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_skincon.svg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"model_audit_benchmark_skincon.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8d8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55889c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf01464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a300f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3b13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4987426",
   "metadata": {},
   "source": [
    "# two ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ab607",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "# fig = plt.figure(constrained_layout=True, figsize=(15, 6))\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "subfigs = fig.subfigures(1, 1)\n",
    "\n",
    "axes = subfigs.subplots(1,2, gridspec_kw={\"wspace\":0.3})\n",
    "\n",
    "axd={'fixed': axes[0], \"on_the_spot\": axes[1] }\n",
    "\n",
    "plot_key=\"fixed\"\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"], \n",
    "#             data=eval_result_df[(eval_result_df[\"method\"]==\"fixed_answer_plus\")&(eval_result_df[\"rank_n\"]<=3)],\n",
    "#            ax=axd[plot_key])\n",
    "\n",
    "eval_result_df_mean_fixed=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"fixed_answer_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\"]).mean()\n",
    "print(eval_result_df_mean_fixed)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=\"metric\", hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_fixed).reset_index(),\n",
    "    width=0.7,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "\n",
    "# plt.title(\"\\\n",
    "# ground-truth is defined based on distribution of train/test set\\\n",
    "# \\n(i.e., similar to the `red` confounder in the ISIC)\")\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_linewidth(1.5)\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=0.4, alpha=0.4)\n",
    "# axd[plot_key].yaxis.grid(True, which='minor', linewidth=0.2, alpha=0.4)\n",
    "\n",
    "axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='both', which='major', labelsize=16)\n",
    "axd[plot_key].tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "axd[plot_key].set_xlabel(\"Top-N\", fontsize=18)\n",
    "# axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\\n(across all underperforming clusters)\", fontsize=16)\n",
    "axd[plot_key].set_ylabel(\"Freq. of recovering spurious corr.\", fontsize=18)\n",
    "\n",
    "for patch in axd[plot_key].patches :\n",
    "    patch.set_linewidth(1)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "\n",
    "\n",
    "    \n",
    "# leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5)\n",
    "axd[plot_key].get_legend().remove()\n",
    "axd[plot_key].text(x=-0.2, \n",
    "                   y=1.09, \n",
    "#                    y=1.03, \n",
    "                   transform=axd[plot_key].transAxes,\n",
    "                     s=\" B.\", fontsize=23, weight='bold')\n",
    "# leg.set_title(\"Model\", prop={\"size\":16})\n",
    "\n",
    "\n",
    "# axd[plot_key].set_title(\"Do the top N rec spurious correlation\", fontsize=16)\n",
    "axd[plot_key].set_title(\"Do the top-N concept explanations recover spurious correlations?\\n(across all low-performing clusters)\", \n",
    "                        fontsize=18)\n",
    "\n",
    "plot_key=\"on_the_spot\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.barplot(x=\"rank_n\", y=\"metric_random_ratio\", hue=\"model\", \n",
    "# data=eval_result_df[\n",
    "#     (eval_result_df[\"method\"]==\"on_the_spot_plus\")\n",
    "#     &(eval_result_df[\"answer_length\"]!=0)\n",
    "#     &(eval_result_df[\"rank_n\"]<=3)], ax=axd[plot_key])\n",
    "\n",
    "eval_result_df_mean_spot=eval_result_df[\n",
    "    (eval_result_df[\"method\"]==\"on_the_spot_plus\")\n",
    "    &(eval_result_df[\"answer_length\"]!=0)\n",
    "    &(eval_result_df[\"rank_n\"]<=3)].groupby([\"rank_n\", \"model\"]).mean()\n",
    "print(eval_result_df_mean_spot)\n",
    "sns.barplot(\n",
    "    x=\"rank_n\", y=0, hue=\"model\", hue_order=[\"MONET\", \"CLIP\"],\n",
    "    data=(eval_result_df_mean_spot[\"metric\"]/eval_result_df_mean_spot[\"random_performance\"]).reset_index(),\n",
    "    width=0.7,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axd[plot_key].spines[axis].set_linewidth(1.5)\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(1))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=0.4, alpha=0.4)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=0.2, alpha=0.4)\n",
    "\n",
    "axd[plot_key].tick_params(axis='both', which='major', labelsize=16)\n",
    "axd[plot_key].tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "axd[plot_key].set_xlabel(\"Top-N\", fontsize=18)\n",
    "# axd[plot_key].set_ylabel(\"Prob. of listing ground-truth concept\\ncompared to random (per cluster)\", fontsize=16)\n",
    "axd[plot_key].set_ylabel(\"Ratio of freq. of including ground truth\\nto that in random ordering\", fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "for patch in axd[plot_key].patches :\n",
    "    patch.set_linewidth(1)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "\n",
    "leg=axd[plot_key].legend(fontsize = 16, facecolor='white', framealpha=0.5, ncols=2,\n",
    "                         loc='upper center', bbox_to_anchor=(-0.2, -0.1, 0, 0)\n",
    "                        \n",
    "                        )\n",
    "leg.set_title(\"\", prop={\"size\":16})\n",
    "axd[plot_key].text(x=-0.19, \n",
    "                   y=1.09, \n",
    "#                    y=1.03, \n",
    "                   transform=axd[plot_key].transAxes,\n",
    "                     s=\"C.\", fontsize=23, weight='bold')\n",
    "# plt.tight_figure()\n",
    "# axd[plot_key].set_title(\"Ground-truth\", fontsize=16)\n",
    "axd[plot_key].set_title(\"Do the top-N concept explanations include ground truth\\ndefined per low-performing cluster?\", \n",
    "                        fontsize=18)\n",
    "\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"model_audit_main_benchmark.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1806cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_df_mean_spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fbcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n=3\n",
    "num_true=2\n",
    "1-(math.comb(48-num_true, top_n) / math.comb(48, top_n))**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_dict_isic=torch.load(\"logs/experiment_results/data_audit_new_0429.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c4c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19497325",
   "metadata": {},
   "source": [
    "# real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497f771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict_classifier=torch.load(\"logs/experiment_results/concept_annotation_data_auditing_0826.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict_classifier[\"isic_nodup_nooverlap\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ccbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e824b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dex(['51b3c4a7cc25da63c438edc9d2d5e749.jpg'], dtype='object'),\n",
    " Index(['b80678b6ff26b79f53e079c2b853af9a.jpg'], dtype='object'),\n",
    " Index(['e89438538c2e7c4fe86a1d6112fcd599.jpg'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f2e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_index(dataset_name, metadata_all, attribution):\n",
    "    if \"isic\" in dataset_name:\n",
    "        if attribution==\"all\":\n",
    "            #pd.Series([True], index=metadata_all)\n",
    "            subset_idx=np.array([True]*len(metadata_all))\n",
    "        else:\n",
    "            collection_65=(metadata_all[\"collection_65\"]==1).values\n",
    "            \n",
    "            if attribution==\"barcelona_all\":\n",
    "                subset_idx=((metadata_all[\"attribution\"]==\"Department of Dermatology, Hospital Clínic de Barcelona\")|(metadata_all[\"attribution\"]==\"Hospital Clínic de Barcelona\")).values\n",
    "            elif attribution==\"mskcc_all\":\n",
    "                subset_idx=((metadata_all[\"attribution\"]==\"MSKCC\")|(metadata_all[\"attribution\"]==\"Memorial Sloan Kettering Cancer Center\")).values\n",
    "            else:\n",
    "                subset_idx=(metadata_all[\"attribution\"]==attribution).values          \n",
    "                \n",
    "            subset_idx=subset_idx&collection_65\n",
    "        #for attribution in [None]+[\"barcelona\", \"vienna\", \"barcelona_all\"]:\n",
    "        #for attribution in [\"all\"]+list(metadata_all[\"attribution\"].unique())+[\"barcelona_all\", \"mskcc_all\"]:\n",
    "    elif \"clinical_fd_clean\" in dataset_name:\n",
    "        if attribution==\"all\":\n",
    "            subset_idx=np.array([True]*len(metadata_all))\n",
    "        else:\n",
    "            if attribution==\"dark\":\n",
    "                subset_idx=((metadata_all[\"fitzpatrick_scale\"].fillna(-9).astype(int).isin([5,6]))|\\\n",
    "                        (metadata_all[\"skin_tone\"].fillna(-9).astype(int).isin([56]))).values   \n",
    "            elif attribution==\"light\":\n",
    "                subset_idx=((metadata_all[\"fitzpatrick_scale\"].fillna(-9).astype(int).isin([1,2,3,4]))|\\\n",
    "                        (metadata_all[\"skin_tone\"].fillna(-9).astype(int).isin([12,34]))).values\n",
    "    return subset_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(dataset_name, idx):\n",
    "    if \"clinical_fd_clean_nodup\" in dataset_name:\n",
    "        if idx in [\"58b4bc079ca94e6e9377a42ca7564b40.jpg\",\n",
    "                   \"720cf31558966c82c118ab75b50632eb.jpg\",\n",
    "                   \"5f046cda32a3cc547205662e7be774f9.jpg\",\n",
    "                   \"d8bf377acc45a3beb0c6e81bf7ac1ff5.jpg\",\n",
    "                   \"109dc569333a2fa8490e098c95c6c3ca.jpg\",\n",
    "                   \"97445c91fd5215758e2c1a77c3fd1c12.jpg\",\n",
    "                   \"51b3c4a7cc25da63c438edc9d2d5e749.jpg\",\n",
    "                   \"b80678b6ff26b79f53e079c2b853af9a.jpg\",\n",
    "                   \"e89438538c2e7c4fe86a1d6112fcd599.jps\",\n",
    "                  ]:\n",
    "            return False\n",
    "        else:\n",
    "            return True            \n",
    "    elif \"isic\" in dataset_name:\n",
    "        if idx in ['ISIC_0053863',\n",
    "             'ISIC_0072697',\n",
    "             'ISIC_0062196',\n",
    "             'ISIC_0064559',\n",
    "             'ISIC_0062301',\n",
    "             'ISIC_0068895',\n",
    "             'ISIC_0070853',\n",
    "             'ISIC_0054985',\n",
    "             'ISIC_0059954',\n",
    "             'ISIC_0058819']:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(dataset_name, idx):\n",
    "    if \"clinical_fd_clean_nodup\" in dataset_name:\n",
    "        if idx in [\"58b4bc079ca94e6e9377a42ca7564b40.jpg\",\n",
    "         \"720cf31558966c82c118ab75b50632eb.jpg\",\n",
    "         \"5f046cda32a3cc547205662e7be774f9.jpg\",\n",
    "         \"d8bf377acc45a3beb0c6e81bf7ac1ff5.jpg\"]:\n",
    "            return False\n",
    "        else:\n",
    "            return True            \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e173093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_concept_name(dataset_name, concept_name):\n",
    "    if \"isic\" in dataset_name:\n",
    "        if concept_name.startswith(\"disease\"):\n",
    "            return False\n",
    "        elif concept_name.startswith(\"isicconcept_\"):\n",
    "            return False          \n",
    "        elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "            if 'typical' in concept_name:\n",
    "                return False                \n",
    "            elif 'regular' in concept_name:\n",
    "                return False\n",
    "            elif \"pigmentation\" in concept_name:\n",
    "                return False\n",
    "            else:\n",
    "                return True        \n",
    "        elif concept_name in [\"melanoma\", \"malignant\", \"finger\", \"red sticker\", \"blue sticker\"]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    if \"proveai\" in dataset_name:\n",
    "        if concept_name.startswith(\"disease\"):\n",
    "            return False\n",
    "        elif concept_name.startswith(\"isicconcept_\"):\n",
    "            return False          \n",
    "        elif concept_name.startswith(\"derm7ptconcept_\"):\n",
    "            if 'typical' in concept_name:\n",
    "                return False                \n",
    "            elif 'regular' in concept_name:\n",
    "                return False\n",
    "            elif \"pigmentation\" in concept_name:\n",
    "                return False\n",
    "            else:\n",
    "                return True        \n",
    "        elif concept_name in [\"melanoma\", \"malignant\", \"finger\", \"red sticker\", \"blue sticker\"]:\n",
    "            return False\n",
    "        else:\n",
    "            return True        \n",
    "        \n",
    "    elif \"clinical_fd_clean\" in dataset_name:\n",
    "        if concept_name.startswith(\"disease\"):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        raise NotImplementedError(dataset_name)\n",
    "\n",
    "def shorten_concept_name(concept_name, strict=True):\n",
    "    if concept_name.startswith(\"disease_\"):\n",
    "        short_name=concept_name.replace(\"disease_\", \"\")\n",
    "    elif concept_name==\"skincon_Erythema\":\n",
    "        short_name=\"Erythema\"\n",
    "    elif concept_name==\"skincon_Bulla\":\n",
    "        short_name=\"Bulla\"\n",
    "    elif concept_name==\"skincon_Lichenification\":\n",
    "        short_name=\"Lichenification\"\n",
    "    elif concept_name==\"skincon_Pustule\":\n",
    "        short_name=\"Pustule\"\n",
    "    elif concept_name==\"skincon_Ulcer\":\n",
    "        short_name=\"Ulcer\"\n",
    "    elif concept_name==\"skincon_Warty/Papillomatous\":\n",
    "        short_name=\"Warty\"\n",
    "    elif concept_name==\"skincon_White(Hypopigmentation)\":\n",
    "        short_name=\"Hypopigmentation\"\n",
    "    elif concept_name==\"skincon_Brown(Hyperpigmentation)\":\n",
    "        short_name=\"Hyperpigmentation\"\n",
    "    elif concept_name==\"skincon_Exophytic/Fungating\":\n",
    "        short_name=\"Fungating\"          \n",
    "    elif concept_name==\"purple pen\":\n",
    "        short_name=\"Purple pen\"\n",
    "    elif concept_name==\"nail\":\n",
    "        short_name=\"Nail\"  \n",
    "    elif concept_name==\"orange sticker\":\n",
    "        short_name=\"Orange sticker\"          \n",
    "    elif concept_name==\"hair\":\n",
    "        short_name=\"Hair\"          \n",
    "    elif concept_name==\"gel\":\n",
    "        short_name=\"Gel\"\n",
    "    elif concept_name==\"red\":\n",
    "        short_name=\"Red\"\n",
    "    elif concept_name==\"blue sticker\":\n",
    "        short_name=\"Blue sticker\"\n",
    "    elif concept_name==\"red sticker\":\n",
    "        short_name=\"Red sticker\"        \n",
    "    elif concept_name==\"dermoscope border\":\n",
    "        short_name=\"Dermoscopic border\"\n",
    "    elif concept_name==\"pinkish\":\n",
    "        short_name=\"Pink\"\n",
    "        \n",
    "    elif concept_name==\"derm7ptconcept_pigment network\":\n",
    "        short_name=\"Pigment network\"        \n",
    "    elif concept_name==\"derm7ptconcept_regression structure\":\n",
    "        short_name=\"Regression structure\"        \n",
    "    elif concept_name==\"derm7ptconcept_pigmentation\":\n",
    "        short_name=\"Pigmentation\"        \n",
    "    elif concept_name==\"derm7ptconcept_blue whitish veil\":\n",
    "        short_name=\"Blue whitish veil\"        \n",
    "    elif concept_name==\"derm7ptconcept_vascular structures\":\n",
    "        short_name=\"Vascular structures\"        \n",
    "    elif concept_name==\"derm7ptconcept_streaks\":\n",
    "        short_name=\"Streaks\"        \n",
    "    elif concept_name==\"derm7ptconcept_dots and globules\":\n",
    "        short_name=\"Dots and globules\"\n",
    "        \n",
    "    else:\n",
    "        if concept_name.startswith(\"skincon_\"):\n",
    "            short_name=concept_name[8:]\n",
    "        else:\n",
    "            if strict:\n",
    "                raise NotImplementedError(concept_name)\n",
    "            else:\n",
    "                short_name=concept_name\n",
    "            \n",
    "    return short_name\n",
    "\n",
    "def shorten_hospital_name(hospital_name):\n",
    "    if hospital_name==\"Hospital Clínic de Barcelona\":\n",
    "        short_name=\"Hospital Clínic de Barcelona\"\n",
    "    elif hospital_name==\"ViDIR Group, Department of Dermatology, Medical University of Vienna\":\n",
    "        short_name=\"Medical University of Vienna\"    \n",
    "    elif hospital_name==\"dark\":\n",
    "        short_name=\"Dark\"\n",
    "    elif hospital_name==\"light\":\n",
    "        short_name=\"Light\"            \n",
    "    return short_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cf389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode as sci_mode\n",
    "def plot_slice_figure(dataset_name,\n",
    "                      data_dict,\n",
    "                      prompt_info, \n",
    "                      row_per_slice=30, \n",
    "                      example_per_row=30, \n",
    "                      normalize=True, \n",
    "                      show_small_box=True, \n",
    "                      print_alphabet=True,\n",
    "                      print_legend_color=True,\n",
    "                      print_legend_color_idx=2,\n",
    "                      print_legend_number=True,\n",
    "                      task_type=\"malignancy\",\n",
    "                      fontsize=32,\n",
    "                      true_pred_count_fontsize=25,\n",
    "                      slice_title_fontsize=32,\n",
    "                      skip_section=0,\n",
    "                      figure_title=None, debug=False):\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    red_color=np.array([212,17,89]) #np.array((222,40,40))\n",
    "    green_color=np.array([26,133,255]) #np.array((40,200,40))\n",
    "    [31, 120, 180], [51, 160, 44]\n",
    "    # two_color=[np.array([90, 0, 220]), np.array([51, 160, 44])]\n",
    "    #two_color=[np.array([31, 120, 180]), np.array([51, 160, 44])]\n",
    "    two_color=[np.array([60, 50, 180]), np.array([51, 160, 44])]\n",
    "\n",
    "    \n",
    "    total_slices=(len([j for exp_name in data_dict.keys() for j in data_dict[exp_name][\"sample_list_list\"]]))\n",
    "    \n",
    "    fig = plt.figure(figsize=(3*(example_per_row), \n",
    "                              3*(row_per_slice)*total_slices+\\\n",
    "                              0.4*(len(data_dict)-1)+\\\n",
    "                              0.3*((total_slices-1)-(len(data_dict)-1))\n",
    "                             )\n",
    "                    )\n",
    "\n",
    "    box1 = gridspec.GridSpec(len(data_dict), 1,\n",
    "                             wspace=0.0,\n",
    "                             hspace=0.4)\n",
    "    \n",
    "    axd={}\n",
    "    for idx1, exp_name in enumerate(data_dict.keys()):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(data_dict[exp_name][\"sample_list_list\"]), 1,\n",
    "                        subplot_spec=box1[idx1], wspace=0.0, hspace=0.3)\n",
    "\n",
    "        for idx2, (slice_assignment) in enumerate(data_dict[exp_name][\"sample_list_list\"]):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(row_per_slice, example_per_row,\n",
    "                                                                    subplot_spec=box2[idx2], wspace=0, hspace=0.05)            \n",
    "#             if example_per_slice//10==1:\n",
    "#                 box3 = gridspec.GridSpecFromSubplotSpec(row_per_slice, example_per_row,\n",
    "#                                                         subplot_spec=box2[idx2], wspace=0, hspace=0.05)\n",
    "#             else:\n",
    "#                 box3 = gridspec.GridSpecFromSubplotSpec(row_per_slice, example_per_row,\n",
    "#                                                         subplot_spec=box2[idx2], wspace=0.05, hspace=0.15)\n",
    "            for rank_num in range(row_per_slice*example_per_row):\n",
    "                ax=plt.Subplot(fig, box3[rank_num])\n",
    "                fig.add_subplot(ax)\n",
    "\n",
    "                plot_key=(idx1, idx2, rank_num)\n",
    "                axd[plot_key]=ax   \n",
    "                \n",
    "    #dsdsd           \n",
    "    for idx1, exp_name in enumerate(data_dict.keys()):\n",
    "        \n",
    "        targets=data_dict[exp_name][\"targets\"]\n",
    "        preds=data_dict[exp_name][\"preds\"]\n",
    "        main_title=data_dict[exp_name][\"main_title\"]   \n",
    "                \n",
    "        \n",
    "        \n",
    "        for idx2, (sample_list) in enumerate(data_dict[exp_name][\"sample_list_list\"]):\n",
    "            print('--------------------------------------------------')\n",
    "            for rank_num in range(row_per_slice*example_per_row):\n",
    "                plot_key=(idx1, idx2, rank_num)\n",
    "                axd[plot_key].set_xticks([])\n",
    "                axd[plot_key].set_yticks([])   \n",
    "                \n",
    "                if rank_num==0 and idx2==1:\n",
    "                    \n",
    "                    axd[plot_key].text(x=0.0, \n",
    "                                         #y=1.1, \n",
    "                                         y=1.1, \n",
    "                                         transform=axd[plot_key].transAxes,\n",
    "                                         s=main_title[1], \n",
    "                                         fontsize=slice_title_fontsize)    \n",
    "#                                            , weight='bold')     \n",
    "\n",
    "                if rank_num==example_per_row-1:\n",
    "                    \n",
    "                    label_str=f\"True Malignant: {targets.loc[sample_list].sum()} Neg={(1-targets.loc[sample_list]).sum()}\"\n",
    "                    predicted_str=f\" Pred +={(preds.loc[sample_list]==1).sum()} Neg={(preds.loc[sample_list]==0).sum()}\"                    \n",
    "                    \n",
    "#                     title= f\"Malignant: {targets[slice_mask].sum()} → {(preds[slice_mask]==1).sum()}   Benign: {(1-targets[slice_mask]).sum()} → {(prob[slice_mask]<0.5).sum()}\"\n",
    "                    title= f\"True: {targets.loc[sample_list].sum()} / {(1-targets.loc[sample_list]).sum()} → Pred: {(preds.loc[sample_list]==1).sum()} / {(preds.loc[sample_list]==0).sum()} \"\n",
    "                    targets.loc[sample_list].sum()\n",
    "                    print(title)\n",
    "                    axd[plot_key].text(x=1.0, y=1.1, transform=axd[plot_key].transAxes,\n",
    "                                         s=title, fontsize=true_pred_count_fontsize, color=\"black\",\n",
    "                                       horizontalalignment=\"right\",\n",
    "\n",
    "#                                       bbox=dict(facecolor='white', edgecolor='red')\n",
    "                                      )   \n",
    "                    \n",
    "                #if print_legend_number and idx1==len(data_dict)-1 and idx2==len(data_dict[exp_name][\"sample_list_list\"])-1 and rank_num==example_per_row-1:\n",
    "                if print_legend_number and idx1==len(data_dict)-1 and idx2==len(data_dict[exp_name][\"sample_list_list\"])-1 and rank_num==row_per_slice*example_per_row-1:\n",
    "                    if task_type==\"malignancy\":\n",
    "                        title= f\"True: # Malignant / # Benign → Pred: # Malignant / # Benign\"\n",
    "                    elif task_type==\"melanoma\":\n",
    "                        title= f\"True: # Melanoma / # Non-melanoma → Pred: # Melanoma / # Non-melanoma\"\n",
    "                    else:\n",
    "                        raise ValueError(task_type)\n",
    "                    targets.loc[sample_list].sum()\n",
    "                    axd[plot_key].text(x=1.0, y=-0.25, transform=axd[plot_key].transAxes,\n",
    "                                         s=title, fontsize=true_pred_count_fontsize-2, color=\"black\",\n",
    "                                       horizontalalignment=\"right\",\n",
    "\n",
    "#                                       bbox=dict(facecolor='white', edgecolor='red')\n",
    "                                      )  \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if print_legend_color and idx1==len(data_dict)-1 and idx2==len(data_dict[exp_name][\"sample_list_list\"])-1 and rank_num==print_legend_color_idx:\n",
    "\n",
    "                    legend_elements = [Line2D([0], [0], marker='o', color=(1,1,1,1), \n",
    "                                              markerfacecolor=np.array((200,40,40))/256, \n",
    "                                              markeredgecolor=np.array((0,0,0))/256, \n",
    "                                              markersize=30, \n",
    "                                              label=\"Maligant\"),\n",
    "                                       Line2D([0], [0], marker='X', color=(1,1,1,1), \n",
    "                                              markerfacecolor=np.array((40,200,40))/256, \n",
    "                                              markeredgecolor=np.array((0,0,0))/256, \n",
    "                                              markersize=30, label=\"Benign\"),]\n",
    "\n",
    "                    if task_type==\"malignancy\":\n",
    "                        legend_elements = [Line2D([0], [0], marker='s', color=(1,1,1,1), \n",
    "                                                  markerfacecolor=red_color/256, \n",
    "                                                  markeredgecolor=np.array((0,0,0))/256, \n",
    "                                                  markersize=30, \n",
    "                                                  label=\"Maligant\"),\n",
    "                                           Line2D([0], [0], marker='s', color=(1,1,1,1), \n",
    "                                                  markerfacecolor=green_color/256, \n",
    "                                                  markeredgecolor=np.array((0,0,0))/256, \n",
    "                                                  markersize=30, label=\"Benign   (Upper left: True, Lower right: Pred)\"),]                                \n",
    "                    elif task_type==\"melanoma\":\n",
    "                        legend_elements = [Line2D([0], [0], marker='s', color=(1,1,1,1), \n",
    "                                                  markerfacecolor=red_color/256, \n",
    "                                                  markeredgecolor=np.array((0,0,0))/256, \n",
    "                                                  markersize=30, \n",
    "                                                  label=\"Melanoma\"),\n",
    "                                           Line2D([0], [0], marker='s', color=(1,1,1,1), \n",
    "                                                  markerfacecolor=green_color/256, \n",
    "                                                  markeredgecolor=np.array((0,0,0))/256, \n",
    "                                                  markersize=30, label=\"Non-melanoma   (Upper left: True, Lower right: Pred)\"),]\n",
    "                    else:\n",
    "                        raise ValueError(task_type)                    \n",
    "                    \n",
    "\n",
    "\n",
    "                    axd[plot_key].legend(handles=legend_elements, \n",
    "                                        ncol=2, \n",
    "                                        handlelength=3,\n",
    "                                        handletextpad=-0.1, \n",
    "                                        columnspacing=1.5,\n",
    "                                        fontsize=true_pred_count_fontsize-2,\n",
    "                                        loc='lower center', \n",
    "                                        bbox_to_anchor=(1, -0.45))  \n",
    "                    \n",
    "#                     axd[plot_key].legend(handles=legend_elements, \n",
    "#                                         ncol=2, \n",
    "#                                         handlelength=3,\n",
    "#                                         handletextpad=-0.1, \n",
    "#                                         columnspacing=1.5,\n",
    "#                                         fontsize=23,\n",
    "#                                         loc='lower center', \n",
    "#                                         bbox_to_anchor=(0, -0.45))                   \n",
    "            \n",
    "            \n",
    "            image_idx_list=variable_dict[dataset_name][\"metadata_all\"].index.get_indexer(sample_list)\n",
    "        \n",
    "            count=0\n",
    "            rank_num=0\n",
    "            while rank_num<min(row_per_slice*example_per_row, len(image_idx_list)):\n",
    "                if check_image(dataset_name, variable_dict[dataset_name][\"metadata_all\"].index[image_idx_list[count]]):\n",
    "#                 if check_image(dataset_name, image_idx_list[count]):\n",
    "                    pass\n",
    "                else:\n",
    "                    count+=1\n",
    "                    continue\n",
    "                    \n",
    "                plot_key=(idx1, idx2, rank_num)\n",
    "                \n",
    "                item=variable_dict[dataset_name][\"dataloader\"].dataset.getitem(image_idx_list[count])\n",
    "                image=item[\"image\"]\n",
    "                axd[plot_key].imshow(image.resize((300, 300)))\n",
    "                \n",
    "                if debug:\n",
    "                    axd[plot_key].set_title(item[\"metadata\"].name)\n",
    "                \n",
    "                if show_small_box:\n",
    "\n",
    "                    if pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index).loc[item[\"metadata\"].name]==True:\n",
    "#                     if item[\"metadata\"][\"benign_malignant_bool\"]==True:\n",
    "                        axd[plot_key].scatter(x=[0.905], y=[0.905], s=650, \n",
    "                                       linewidths=1.5,\n",
    "                                       edgecolor=np.array((0,0,0, 120))/256,\n",
    "                                       #edgecolor=np.array((255,255,0, 120))/256,\n",
    "                                       color=red_color/256,\n",
    "                                       marker=\"s\",\n",
    "                                       transform=axd[plot_key].transAxes)     \n",
    "\n",
    "                    elif pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index).loc[item[\"metadata\"].name]==False:\n",
    "#                     elif item[\"metadata\"][\"benign_malignant_bool\"]==False:\n",
    "                        axd[plot_key].scatter(x=[0.905], y=[0.905], s=650, \n",
    "                                   linewidths=1.5,\n",
    "                                   #edgecolor=np.array((0,0,0, 120))/256,\n",
    "                                   edgecolor=np.array((0,0,0, 120))/256,\n",
    "                                   color=green_color/256,\n",
    "                                   marker=\"s\",\n",
    "                                   transform=axd[plot_key].transAxes)                 \n",
    "\n",
    "                    x1=0.82\n",
    "                    x2=0.99\n",
    "                    if preds.loc[item[\"metadata\"].name]==1:\n",
    "                        axd[plot_key].fill([x1, x2, x2, x1], [x1, x2, x1, x1], \n",
    "                                           color=red_color/256,\n",
    "                                          transform=axd[plot_key].transAxes\n",
    "                                          )    \n",
    "                    else:\n",
    "                        axd[plot_key].fill([x1, x2, x2, x1], [x1, x2, x1, x1], \n",
    "                                           color=green_color/256,\n",
    "                                          transform=axd[plot_key].transAxes\n",
    "                                          )\n",
    "    #                     axd[plot_key].scatter(x=[0.99], y=[0.99], s=700, \n",
    "    #                                    linewidths=1.3,\n",
    "    # #                                    edgecolor=np.array((0,0,0, 120))/256,\n",
    "    #                                    color=np.array((40,200,40))/256,\n",
    "    #                                         #color=np.array((100,40,40))/256,\n",
    "    #                                    marker=6,\n",
    "    #                                    transform=axd[plot_key].transAxes)                         \n",
    "                else:\n",
    "                    axd[plot_key].set_title(item[\"metadata\"].name, fontsize=10)\n",
    "\n",
    "                axd[plot_key].set_xticks([])\n",
    "                axd[plot_key].set_yticks([])  \n",
    "                      \n",
    "\n",
    "                if rank_num==0:   \n",
    "                    #shorten_concept_name(concept_name)\n",
    "\n",
    "                    #axd[plot_key].set_ylabel(shorten_concept_name(concept_name), fontsize=30, zorder=-10)\n",
    "                    #axd[plot_key].set_ylabel(str(idx1), fontsize=30, zorder=-10)\n",
    "                    pass\n",
    "\n",
    "                if rank_num==100:\n",
    "                    diff_dict_df=pd.DataFrame(diff_dict)\n",
    "                    #print(diff_dict_df[\"concept_name\"])\n",
    "                    diff_dict_df=diff_dict_df[diff_dict_df[\"concept_name\"].map(lambda x: check_concept_name(\"isic\", x))]\n",
    "                    \n",
    "#                     print(diff_dict_df.sort_values(\"diff_score\", ascending=False).iloc[:][\"concept_name\"])\n",
    "                    #title=f\"{int(slice_mask.sum()):d} {(targets[slice_mask]==((prob[slice_mask]>0.5).astype(int))).mean():.2f} \"\n",
    "                    #title=', '.join(diff_dict_df.sort_values(\"diff_score\", ascending=False).iloc[:5][\"concept_name\"].map(shorten_concept_name).tolist())\n",
    "\n",
    "#                     concept_str=diff_dict_df.sort_values(\"diff_score\", ascending=False).iloc[:5][\"concept_name\"]\n",
    "                    concept_str=diff_dict_df.sort_values(\"concept_presence_score\", ascending=False).iloc[:5][\"concept_name\"]\n",
    "#                     concept_str=diff_dict_df.sort_values(\"slice_score\", ascending=False).iloc[:5][\"concept_name\"]\n",
    "                    concept_str=concept_str.map(shorten_concept_name)\n",
    "                    concept_str=\", \".join(concept_str.str.replace(\"skincon_\",\"\"))\n",
    "                    concept_str=concept_str\n",
    "                    \n",
    "                    print(concept_str)\n",
    "#                     print(diff_dict_df.sort_values(\"diff_score\", ascending=False).iloc[:20])\n",
    "                    print(diff_dict_df.sort_values(\"concept_presence_score\", ascending=False).iloc[:20])                    \n",
    "#                     print(diff_dict_df.sort_values(\"concept_presence_score\", ascending=False).iloc[:20])                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    #title+= / Predicted Pos={(prob[slice_mask]>0.5).sum()} Neg={(prob[slice_mask]<0.5).sum()}\"\n",
    "                                      \n",
    "                    title= concept_str\n",
    "                        \n",
    "                    targets.loc[sample_list].sum()\n",
    "                    axd[plot_key].text(x=-0., y=1.1, transform=axd[plot_key].transAxes,\n",
    "                                         s=title, fontsize=true_pred_count_fontsize, color=\"black\",\n",
    "                                      \n",
    "#                                       bbox=dict(facecolor='white', edgecolor='red')\n",
    "                                      )   \n",
    "                     \n",
    "                    \n",
    "                    pass\n",
    "                   \n",
    "                    \n",
    "#                       axd[plot_key].text(x=-0.3, y=1.05, transform=axd[plot_key].transAxes,\n",
    "#                                          s=[\"A\", \"B\", \"C\", \"D\", \"E\"][idx1], fontsize=35, weight='bold')\n",
    "\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    axd[plot_key].spines[axis].set_linewidth(1)      \n",
    "#                 print('idx~~~~', idx1)\n",
    "                if rank_num==0 and idx1==0 and idx2==0 and figure_title is not None:\n",
    "                    print(figure_title)\n",
    "                    axd[plot_key].text(x=-0.33, \n",
    "                                         #y=1.1, \n",
    "                                         y=1.4,\n",
    "                                         transform=axd[plot_key].transAxes,\n",
    "                                         s=figure_title[0], \n",
    "                                         fontsize=35, weight='bold')  \n",
    "                    axd[plot_key].text(x=0.01, \n",
    "                                         #y=1.1, \n",
    "                                         y=1.4, \n",
    "                                         transform=axd[plot_key].transAxes,\n",
    "                                         s=figure_title[1],\n",
    "                                         fontsize=fontsize)        \n",
    "                    \n",
    "                if rank_num==0 and idx2==0:\n",
    "                    if print_alphabet and skip_section+idx1<26:\n",
    "                        axd[plot_key].text(x=-0.3, \n",
    "                                             #y=1.1, \n",
    "                                             y=1.1, \n",
    "                                             transform=axd[plot_key].transAxes,\n",
    "                                             s=[\"A.\", \"B.\", \"C.\", \"D.\", \"E.\", \"F.\", \"G.\", \"H.\", \"I.\", \"J.\", \n",
    "                                                \"K.\", \"L.\", \"M.\", \"N.\", \"O.\", \"P.\", \"Q.\", \"R.\", \"S.\", \"T.\", \n",
    "                                                \"U.\", \"V.\", \"W.\", \"X.\", \"Y.\", \"Z.\"][skip_section+idx1], \n",
    "                                             fontsize=slice_title_fontsize+3, weight='bold')  \n",
    "                        axd[plot_key].text(x=0.05, \n",
    "                                             #y=1.1, \n",
    "                                             y=1.1, \n",
    "                                             transform=axd[plot_key].transAxes,\n",
    "                                             s=main_title[0], \n",
    "                                             fontsize=fontsize)\n",
    "                    else:\n",
    "#                         axd[plot_key].text(x=-0.3, \n",
    "#                                              #y=1.1, \n",
    "#                                              y=1.4, \n",
    "#                                              transform=axd[plot_key].transAxes,\n",
    "#                                              s=[\"A.\", \"B.\", \"C.\", \"D.\", \"E.\"][skip_section+idx1], \n",
    "#                                              fontsize=35, weight='bold')  \n",
    "                        axd[plot_key].text(x=0.0, \n",
    "                                             #y=1.1, \n",
    "                                             y=1.1, \n",
    "                                             transform=axd[plot_key].transAxes,\n",
    "                                             s=main_title[0], \n",
    "                                             fontsize=slice_title_fontsize)\n",
    "    \n",
    "    \n",
    "                     \n",
    "                    \n",
    "  \n",
    "                \n",
    "                   \n",
    "                    \n",
    "                rank_num+=1\n",
    "                count+=1                      \n",
    "            \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256bf05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"dataloader\"].dataset.getitem(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[\"labels\"].shape for i in test_result_list_from1_to2_concept_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset(image_features_norm, metadata_all, \n",
    "                  logits, labels, subset_idx):\n",
    "    \n",
    "    image_features_norm_subset=image_features_norm[metadata_all.index.get_indexer(metadata_all[subset_idx].index)]    \n",
    "    \n",
    "    logits_subset=logits.iloc[logits.index.get_indexer(metadata_all[subset_idx].index)]\n",
    "    \n",
    "    label_subset=labels.iloc[labels.index.get_indexer(metadata_all[subset_idx].index)]\n",
    "    \n",
    "    return image_features_norm_subset, logits_subset, label_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da099338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2d196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d44892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388c595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8847c22",
   "metadata": {},
   "source": [
    "# run ISIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3774929",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_dict={\n",
    "    \"isic_nodup_nooverlap\": [\"ViDIR Group, Department of Dermatology, Medical University of Vienna\", \"Hospital Clínic de Barcelona\"],\n",
    "    \"clinical_fd_clean_nodup_nooverlap\": [\"light\", \"dark\"],\n",
    "}\n",
    "\n",
    "dataset_name=\"isic_nodup_nooverlap\"\n",
    "\n",
    "hospital_1,hospital_2=attribution_dict[dataset_name]\n",
    "n_clusters_param=n_clusters_param_dict[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea897639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c513c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1_thres_isic={}\n",
    "\n",
    "classifier_val_idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_1}\"][1].dataset.metadata_all.index\n",
    "y_test=variable_dict_classifier[dataset_name][\"classifier_dataloader_all\"].dataset.metadata_all[\"label\"].loc[classifier_val_idx]\n",
    "y_test_predicted_probas=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"logits_with_index\"].loc[classifier_val_idx]\n",
    "# y_test_predicted_probas=y_test_predicted_probas.map(lambda x: 1/(1 + np.exp(-x)))\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_test_predicted_probas)\n",
    "numerator = 2 * recall * precision\n",
    "denom = recall + precision\n",
    "f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "max_f1 = np.max(f1_scores)\n",
    "max_f1_thresh = thresholds[np.argmax(f1_scores)]\n",
    "max_f1_thres_isic[hospital_1]=max_f1_thresh\n",
    "print(max_f1_thresh)\n",
    "\n",
    "classifier_val_idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_2}\"][1].dataset.metadata_all.index\n",
    "y_test=variable_dict_classifier[dataset_name][\"classifier_dataloader_all\"].dataset.metadata_all[\"label\"].loc[classifier_val_idx]\n",
    "y_test_predicted_probas=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"logits_with_index\"].loc[classifier_val_idx]\n",
    "# y_test_predicted_probas=y_test_predicted_probas.map(lambda x: 1/(1 + np.exp(-x)))\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_test_predicted_probas)\n",
    "numerator = 2 * recall * precision\n",
    "denom = recall + precision\n",
    "f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "max_f1 = np.max(f1_scores)\n",
    "max_f1_thresh = thresholds[np.argmax(f1_scores)]\n",
    "max_f1_thres_isic[hospital_2]=max_f1_thresh\n",
    "\n",
    "print(max_f1_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_auc(metadata_all, \n",
    "                       logits, \n",
    "                       idx):\n",
    "    #print(logits.shape, idx, metadata_all.shape)\n",
    "    pd.Series(logits, index=metadata_all.index)\n",
    "#     return sklearn.metrics.roc_auc_score(y_true=metadata_all[\"label\"].loc[idx].values.astype(int),\n",
    "#                              y_score=logits.loc[idx].values)\n",
    "    return sklearn.metrics.roc_auc_score(y_true=metadata_all[\"label\"].loc[idx].values.astype(int),\n",
    "                             y_score=pd.Series(logits, index=metadata_all.index).loc[idx].values)\n",
    "\n",
    "print(calculate_test_auc(metadata_all=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"metadata\"],\n",
    "                  logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"logits\"],\n",
    "                   idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_2}\"][1].dataset.metadata_all.index))\n",
    "\n",
    "print(calculate_test_auc(metadata_all=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"metadata\"],\n",
    "                  logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"logits\"],\n",
    "                   idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_1}\"][1].dataset.metadata_all.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_auc(metadata_all, \n",
    "                       logits, \n",
    "                       idx):\n",
    "    #print(logits.shape, idx, metadata_all.shape)\n",
    "    pd.Series(logits, index=metadata_all.index)\n",
    "#     return sklearn.metrics.roc_auc_score(y_true=metadata_all[\"label\"].loc[idx].values.astype(int),\n",
    "#                              y_score=logits.loc[idx].values)\n",
    "    return sklearn.metrics.roc_auc_score(y_true=metadata_all[\"label\"].loc[idx].values.astype(int),\n",
    "                             y_score=pd.Series(logits, index=metadata_all.index).loc[idx].values)\n",
    "\n",
    "print(calculate_test_auc(metadata_all=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"metadata\"],\n",
    "                  logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"logits\"],\n",
    "                   idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_1}\"][1].dataset.metadata_all.index))\n",
    "\n",
    "print(calculate_test_auc(metadata_all=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"metadata\"],\n",
    "                  logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"logits\"],\n",
    "                   idx=variable_dict_classifier[dataset_name][f\"classifier_dataloader_{hospital_2}\"][1].dataset.metadata_all.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733b8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc5eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01126802",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe023c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_true=y_test, y_score=y_test_predicted_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6862a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_norm_subset_from1_to2, logits_subset_from1_to2, label_subset_from1_to2 = \\\n",
    "select_subset(image_features_norm=variable_dict_classifier[dataset_name][\"image_features_norm\"],\n",
    "             metadata_all=variable_dict_classifier[dataset_name][\"metadata_all\"],\n",
    "             logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_1}_eval\"][\"logits_with_index\"],\n",
    "             labels=variable_dict_classifier[dataset_name][\"classifier_dataloader_all\"].dataset.metadata_all[\"label\"],\n",
    "             subset_idx=get_subset_index(dataset_name=dataset_name, \n",
    "                                         metadata_all=variable_dict_classifier[dataset_name][\"metadata_all\"], \n",
    "                                         attribution=hospital_2)&(variable_dict_classifier[dataset_name][\"valid_idx\"])) \n",
    "\n",
    "test_result_list_from1_to2_concept_only=cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_from1_to2, \n",
    "                          logits=logits_subset_from1_to2, \n",
    "                          threshold=max_f1_thres_isic[hospital_1],\n",
    "                         metric_diff=0,\n",
    "                         n_clusters=40, random_state=42)\n",
    "\n",
    "# test_result_list_from1_to2_with_disease=cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "#                                                      , \n",
    "#                           clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "#                                                              index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "#                                                             ), \n",
    "#                           fixed_answer=[\"red\"],\n",
    "#                          labels=label_subset_from1_to2, \n",
    "#                           logits=logits_subset_from1_to2, \n",
    "#                           threshold=max_f1_thres_isic[hospital_1],\n",
    "#                          metric_diff=0.1,\n",
    "#                          n_clusters=80, random_state=42)\n",
    "\n",
    "print(len(label_subset_from1_to2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40543195",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "for test_result in test_result_list_from1_to2_concept_only:\n",
    "    # print(test_result[\"statistics\"].sort_values(\"diff_magnitude\", ascending=False))\n",
    "    concept_name_list_plus=test_result[\"on_the_spot_plus_pred\"][:5]\n",
    "    sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "test_result[\"labels\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index\n",
    "#     sampe_list_plus=test_result[\"labels\"].sort_values(\"kmeans_dist\").index\n",
    "#     test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "#                                   test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    sub_title_plus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_plus])\n",
    "    print(concept_name_list_plus)\n",
    "    \n",
    "    concept_name_list_minus=test_result[\"on_the_spot_minus_pred\"][:3]\n",
    "    concept_name_list_minus=test_result[\"statistics\"][(test_result[\"statistics\"][\"diff_magnitude\"]<0)&(test_result[\"statistics\"][\"mean_value\"]>0.3)].sort_values(\"diff_magnitude\", ascending=True).iloc[:5].index.tolist()\n",
    "    sub_title_minus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_minus])  \n",
    "    \n",
    "\n",
    "    \n",
    "    if count<5:\n",
    "        data_dict_main[count]={\n",
    "            \"targets\": label_subset_from1_to2.astype(int),\n",
    "            \"preds\": (logits_subset_from1_to2>max_f1_thres_isic[hospital_1]).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }  \n",
    "    if count<15:\n",
    "        data_dict_supple[count]={\n",
    "            \"targets\": label_subset_from1_to2.astype(int),\n",
    "            \"preds\": (logits_subset_from1_to2>max_f1_thres_isic[hospital_1]).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }          \n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ccee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"959,ISIC_0061234,ISIC_0053863,ISIC_0072697,,\\n\\\n",
    "961,ISIC_0058303,ISIC_0062196,,,\\n\\\n",
    "962,ISIC_0062827,ISIC_0064559,ISIC_0062301,,\\n\\\n",
    "963,ISIC_0070137,ISIC_0068895,,,\\n\\\n",
    "964,ISIC_0065605,ISIC_0070853,ISIC_0054985,ISIC_0059954,\\n\\\n",
    "965,ISIC_0061470,ISIC_0058819,,,\"\n",
    "x_=[[j for j in i.split(',')[1:] if j!=\"\"] for i in x.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[j for i in x_ for j in i[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[13].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp():\n",
    "    targets=data_dict_supple[0]['targets']\n",
    "    preds=data_dict_supple[0]['preds']\n",
    "    sample_list=data_dict_supple[0][\"sample_list_list\"][0]\n",
    "    print(sample_list)\n",
    "#     sdd\n",
    "    \n",
    "    label_str=f\"True Malignant: {targets.loc[sample_list].sum()} Neg={(1-targets.loc[sample_list]).sum()}\"\n",
    "    print(label_str)\n",
    "    predicted_str=f\" Pred +={(preds.loc[sample_list]==1).sum()} Neg={(preds.loc[sample_list]==0).sum()}\"                    \n",
    "    print(predicted_str)\n",
    "    \n",
    "temp()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_dict_supple[0]['targets'].loc[data_dict_supple[0][\"sample_list_list\"][0]]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4980966",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_figure??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362589b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c193c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0]['targets'].loc[data_dict_supple[0][\"sample_list_list\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88998c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "                    label_str=f\"True Malignant: {targets.loc[sample_list].sum()} Neg={(1-targets.loc[sample_list]).sum()}\"\n",
    "                    predicted_str=f\" Pred +={(preds.loc[sample_list]==1).sum()} Neg={(preds.loc[sample_list]==0).sum()}\"                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0]['preds'].loc[data_dict_supple[0][\"sample_list_list\"][0]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1dcbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0]['preds'].loc[\n",
    "    data_dict_supple[0]['targets'].loc[data_dict_supple[0][\"sample_list_list\"][0]]\\\n",
    "    [data_dict_supple[0]['targets'].loc[data_dict_supple[0][\"sample_list_list\"][0]]==0].index\n",
    "].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd74a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a55b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "183+115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad25b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[7]['targets'].loc[data_dict_supple[7][\"sample_list_list\"][0]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08549fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[7]['preds'].loc[data_dict_supple[7][\"sample_list_list\"][0]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[7]['preds'].loc[\n",
    "    data_dict_supple[7]['targets'].loc[data_dict_supple[13][\"sample_list_list\"][0]]\\\n",
    "    [data_dict_supple[7]['targets'].loc[data_dict_supple[13][\"sample_list_list\"][0]]==1].index\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13016445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dict_supple[13]['preds'].loc[data_dict_supple[13][\"sample_list_list\"][0]].loc[\n",
    "    data_dict_supple[13]['targets'].loc[data_dict_supple[13][\"sample_list_list\"][0]].index\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[13]['preds'].loc[data_dict_supple[13][\"sample_list_list\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264637e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[13][\"sample_list_list\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f40e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=10,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=True,\n",
    "                  print_legend_number=True,\n",
    "                  print_legend_color=True,\n",
    "                  figure_title=None, debug=False)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from1_to2_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f26b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_from1_to2_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93749f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_main,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=5,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=False,\n",
    "                  print_legend_number=False,\n",
    "                  print_legend_color=False,\n",
    "                      slice_title_fontsize=27,\n",
    "                  figure_title=(\"D. \", \"Trained at Med U. Vienna / Tested at Hosp. Barcelona \"))\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from1_to2_main.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from1_to2_main.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_norm_subset_from2_to1, logits_subset_from2_to1, label_subset_from2_to1 = \\\n",
    "select_subset(image_features_norm=variable_dict_classifier[dataset_name][\"image_features_norm\"],\n",
    "             metadata_all=variable_dict_classifier[dataset_name][\"metadata_all\"],\n",
    "             logits=variable_dict_classifier[dataset_name][f\"classifier_model_{hospital_2}_eval\"][\"logits_with_index\"],\n",
    "             labels=variable_dict_classifier[dataset_name][\"classifier_dataloader_all\"].dataset.metadata_all[\"label\"],\n",
    "             subset_idx=get_subset_index(dataset_name=dataset_name, \n",
    "                                         metadata_all=variable_dict_classifier[dataset_name][\"metadata_all\"], \n",
    "                                         attribution=hospital_1)&(variable_dict_classifier[dataset_name][\"valid_idx\"])) \n",
    "\n",
    "test_result_list_from2_to1_concept_only=cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_from2_to1, \n",
    "                          logits=logits_subset_from2_to1, \n",
    "                          threshold=max_f1_thres_isic[hospital_2],\n",
    "                         metric_diff=0,\n",
    "                         n_clusters=40, random_state=42)\n",
    "\n",
    "# test_result_list_from2_to1_with_disease=cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "#                                                      , \n",
    "#                           clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "#                                                              index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "#                                                             ), \n",
    "#                           fixed_answer=[\"red\"],\n",
    "#                          labels=label_subset_from2_to1, \n",
    "#                           logits=logits_subset_from2_to1, \n",
    "#                           threshold=max_f1_thres_isic[hospital_2],\n",
    "#                          metric_diff=0.1,\n",
    "#                          n_clusters=80, random_state=42)\n",
    "print(len(label_subset_from2_to1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "for test_result in test_result_list_from2_to1_concept_only:\n",
    "    print(test_result[\"statistics\"].sort_values(\"diff_magnitude\", ascending=False))\n",
    "    concept_name_list_plus=test_result[\"on_the_spot_plus_pred\"][:5]\n",
    "    sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "test_result[\"labels\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index\n",
    "#     sampe_list_plus=test_result[\"labels\"].sort_values(\"kmeans_dist\").index\n",
    "#     test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "#                                   test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    sub_title_plus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_plus])\n",
    "    \n",
    "    concept_name_list_minus=test_result[\"on_the_spot_minus_pred\"][:3]\n",
    "    concept_name_list_minus=test_result[\"statistics\"][(test_result[\"statistics\"][\"diff_magnitude\"]<0)&(test_result[\"statistics\"][\"mean_value\"]>0.3)].sort_values(\"diff_magnitude\", ascending=True).iloc[:5].index.tolist()\n",
    "    sub_title_minus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_minus])  \n",
    "    \n",
    "\n",
    "    \n",
    "    if count<5:\n",
    "        data_dict_main[count]={\n",
    "            \"targets\": label_subset_from2_to1.astype(int),\n",
    "            \"preds\": (logits_subset_from2_to1>max_f1_thres_isic[hospital_2]).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }  \n",
    "    if count<15:\n",
    "        data_dict_supple[count]={\n",
    "            \"targets\": label_subset_from2_to1.astype(int),\n",
    "            \"preds\": (logits_subset_from2_to1>max_f1_thres_isic[hospital_2]).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }          \n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a88b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=10,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=True,\n",
    "                  print_legend_number=True,\n",
    "                  print_legend_color=True,\n",
    "                  figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c00275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_main,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=5,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=False,\n",
    "                  print_legend_number=False,\n",
    "                  print_legend_color=False,\n",
    "                  slice_title_fontsize=27,\n",
    "                  figure_title=(\"E. \", \"Trained at Hosp. Barcelona / Tested at Med U. Vienna\"))\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_main.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_main.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3729c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trained at Med U. Vienna / Tested at Hosp. Barcelona\n",
    "Trained on light skin / Tested on dark skin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict={\"a\":data_dict_main[0]},\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=10,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=False,\n",
    "                  print_legend_number=False,\n",
    "                  print_legend_color=True,\n",
    "                  print_legend_color_idx=4,\n",
    "                  figure_title=(\"E. \", \"Trained at Med U. Vienna / Tested at Hosp. Barcelona \"))\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_main_legend.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_main_legend.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38a684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337ed22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67a61fbe",
   "metadata": {},
   "source": [
    "# run proveai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d70a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"proveai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true=pd.read_csv(\"data/proveai/isic_upd_rev.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_true=prove_logits_true[\"truth\"],\n",
    "                             y_score=prove_logits_true[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46089911",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_true=prove_logits_true[\"truth\"],\n",
    "                                      y_pred=prove_logits_true[\"scores\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[\"scores\"][prove_logits_true[\"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd66aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e36cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[\"scores\"][prove_logits_true[\"prediction\"]==1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[\"scores\"][prove_logits_true[\"prediction\"]==0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=prove_logits_true[\"truth\"]\n",
    "y_pred=prove_logits_true[\"prediction\"]\n",
    "y_score=prove_logits_true[\"scores\"]\n",
    "# 0.001\n",
    "\n",
    "tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))\n",
    "print(\"accuracy\", (y_true==y_pred).mean())\n",
    "print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                             y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eeb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=prove_logits_true[\"truth\"]\n",
    "y_pred=prove_logits_true[\"scores\"]>0.00097\n",
    "y_score=prove_logits_true[\"scores\"]\n",
    "# 0.001\n",
    "\n",
    "tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))\n",
    "print(\"accuracy\", (y_true==y_pred).mean())\n",
    "print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                             y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=prove_logits_true[\"truth\"]\n",
    "y_pred=prove_logits_true[\"scores\"]>0.0085\n",
    "y_score=prove_logits_true[\"scores\"]\n",
    "\n",
    "tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))\n",
    "print(\"accuracy\", (y_true==y_pred).mean())\n",
    "print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                             y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=prove_logits_true[\"truth\"]\n",
    "y_pred=prove_logits_true[\"scores\"]>0.5\n",
    "y_score=prove_logits_true[\"scores\"]\n",
    "\n",
    "tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))\n",
    "print(\"accuracy\", (y_true==y_pred).mean())\n",
    "print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                             y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42898512",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(prove_logits_true[\"truth\"], \n",
    "                                                                       prove_logits_true[\"scores\"])\n",
    "numerator = 2 * recall * precision\n",
    "denom = recall + precision\n",
    "f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "max_f1 = np.max(f1_scores)\n",
    "max_f1_thresh = thresholds[np.argmax(f1_scores)]\n",
    "max_f1_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=prove_logits_true[\"truth\"]\n",
    "y_pred=prove_logits_true[\"scores\"]>0.0865900212694926\n",
    "y_score=prove_logits_true[\"scores\"]\n",
    "\n",
    "tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))\n",
    "print(\"accuracy\", (y_true==y_pred).mean())\n",
    "print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                             y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf21300",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91908688",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[\"truth\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    y_true=prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[test_result[\"labels\"].index]\n",
    "    y_pred=(prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index])>0.00103\n",
    "    y_score=prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index]\n",
    "\n",
    "    if (y_true==y_pred).all():\n",
    "        continue\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85495d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    y_true=prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[test_result[\"labels\"].index]\n",
    "    y_pred=(prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index])>0.1906984259977523\n",
    "    y_score=prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index]\n",
    "\n",
    "    if (y_true==y_pred).all():\n",
    "        continue\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    y_true=prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[test_result[\"labels\"].index]\n",
    "    y_pred=(prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index])>0.05\n",
    "    y_score=prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index]\n",
    "\n",
    "    if (y_true==y_pred).all():\n",
    "        continue\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ff8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d40a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042253ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d854b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"labels\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780afb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6832f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ae3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3070b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp =\\\n",
    "(sklearn.metrics.confusion_matrix(y_true=prove_logits_true[\"truth\"],\n",
    "y_pred=prove_logits_true[\"target\"]>0.0085).ravel())\n",
    "print(\"sensitivity\", tp / (tp+fn))\n",
    "print(\"specificity\", tn / (tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics \n",
    "\n",
    "confusion_matrix(y_true, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity\n",
    "print(sklearn.metrics.recall_score(y_true=prove_logits_true[\"truth\"],\n",
    "    y_pred=prove_logits_true[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity\n",
    "print(sklearn.metrics.recall_score(y_true=prove_logits_true[\"truth\"],\n",
    "    y_pred=prove_logits_true[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbe936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57933a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity= recall = TP / (TP+FN)\n",
    "specificity= TN / (TN+FP)\n",
    "precision= TP / (TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52635ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_concept_test_real??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_subset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ebe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"proveai\"\n",
    "threshold_select=0.00097\n",
    "#threshold_select=0.5\n",
    "# threshold_select=0.0865900212694926\n",
    "# threshold_select=0.5\n",
    "\n",
    "# image_features_norm_subset_proveai, logits_subset_proveai, label_subset_proveai = \\\n",
    "# variable_dict[dataset_name][\"image_features_norm\"], \\\n",
    "# prove_logits_true.set_index(\"image_name\").loc[variable_dict[dataset_name][\"metadata_all\"].index][\"scores\"],\\\n",
    "# variable_dict[dataset_name][\"y_pos\"]\n",
    "\n",
    "image_features_norm_subset_proveai, logits_subset_proveai, label_subset_proveai = \\\n",
    "select_subset(image_features_norm=variable_dict[dataset_name][\"image_features_norm\"],\n",
    "             metadata_all=variable_dict[dataset_name][\"metadata_all\"],\n",
    "             logits=prove_logits_true.set_index(\"image_name\").loc[variable_dict[dataset_name][\"metadata_all\"].index][\"scores\"],\n",
    "             labels=pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index),\n",
    "             subset_idx=pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index)==0)\n",
    "\n",
    "\n",
    "\n",
    "test_result_list_proveai_concept_only, similarity_info_focus_copy_group_proveai_concept_only = cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_proveai, \n",
    "                          logits=logits_subset_proveai, \n",
    "                          threshold=threshold_select,\n",
    "                         metric_diff=0,\n",
    "                         metric_over=0.5,\n",
    "                         n_clusters=10, random_state=42)\n",
    "\n",
    "test_result_list_proveai_concept_only_, similarity_info_focus_copy_group_proveai_concept_only_ = cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "[variable_dict[dataset_name][\"similarity_matrix\"].columns[variable_dict[dataset_name][\"similarity_matrix\"].columns.map(lambda x: check_concept_name(dataset_name, x))]]\n",
    "                                                     , \n",
    "                          clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "                                                             index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "                                                            ), \n",
    "                          fixed_answer=[\"red\"],\n",
    "                         labels=label_subset_proveai, \n",
    "                          logits=logits_subset_proveai, \n",
    "                          threshold=threshold_select,\n",
    "                         metric_diff=0,\n",
    "                         metric_over=0.5,                                                                                                                           \n",
    "                         n_clusters=10, random_state=42, return_only_highperforming=False)\n",
    "\n",
    "# test_result_list_proveai_with_disease=cluster_concept_test_real(similarity_info=variable_dict[dataset_name][\"similarity_matrix\"]\n",
    "#                                                      , \n",
    "#                           clustering_features=pd.DataFrame(variable_dict[dataset_name][\"efficientnet_feature\"].numpy(),\n",
    "#                                                              index=variable_dict[dataset_name][\"metadata_all\"].index,\n",
    "#                                                             ), \n",
    "#                           fixed_answer=[\"red\"],\n",
    "#                          labels=label_subset_proveai, \n",
    "#                           logits=logits_subset_proveai, \n",
    "#                           threshold=max_f1_thres_isic[hospital_2],\n",
    "#                          metric_diff=0.1,\n",
    "#                          n_clusters=80, random_state=42)\n",
    "print(len(label_subset_proveai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_concept_name??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_result_list_proveai_concept_only_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_result_list_proveai_concept_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3be1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "((logits_subset_proveai>threshold_select)==(label_subset_proveai==1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d85f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "((prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index])>0.00103).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prove_logits_true[\"truth\"]).sum(),\\\n",
    "(prove_logits_true[\"prediction\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prove_logits_true[\"truth\"]==1)[(prove_logits_true[\"prediction\"])==0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prove_logits_true[\"truth\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_result_list_proveai_concept_only_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b47426",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prove_logits_true.set_index(\"image_name\")[\"truth\"]==\\\n",
    " (prove_logits_true.set_index(\"image_name\")[\"target\"]>threshold_select))\\\n",
    ".mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d71b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_result_list_proveai_concept_only_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only_[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ae896",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_the_spot_minus_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only_[0][\"on_the_spot_minus_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only_[1][\"on_the_spot_minus_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42952b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only_[0][\"labels_ref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only_[1][\"labels_ref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ccb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e15e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list=[]\n",
    "for test_result in test_result_list_proveai_concept_only_:\n",
    "    y_true=prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[test_result[\"labels\"].index]\n",
    "    y_pred=(prove_logits_true.set_index(\"image_name\")[\"scores\"].loc[test_result[\"labels\"].index])>threshold_select\n",
    "    y_score=prove_logits_true.set_index(\"image_name\")[\"scores\"].loc[test_result[\"labels\"].index]\n",
    "\n",
    "    if (y_true==y_pred).all():\n",
    "        continue\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0,1]).ravel())\n",
    "    \n",
    "    \n",
    "    record_dict_list.append({\n",
    "        \"M->M\": tp,\n",
    "        \"M->B\": fn,\n",
    "        \"B->M\": fp,\n",
    "        \"B->B\": tn,\n",
    "        \"sensitivity\": tp / (tp+fn),\n",
    "        \"specificity\": tn / (tn+fp),\n",
    "        \"accuracy\":  (y_true==y_pred).mean(),\n",
    "    })\n",
    "    \n",
    "    #print(f\"{tp},{fn}/{tn},{fp} -> {tp},{fp}/{tn},{fn}\")\n",
    "    print(\"M -> M\", tp)\n",
    "    print(\"M -> B\", fn)\n",
    "    print(\"B -> M\", fp)\n",
    "    print(\"B -> B\", tn)\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c60dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50040905",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==1)].shape#.set_index(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62353342",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==0)].shape#.set_index(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32446eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==0)][\"image_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab99d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(variable_dict[dataset_name][\"similarity_matrix\"].loc[\n",
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==1)][\"image_name\"].values\n",
    "].mean(axis=0)-\\\n",
    "variable_dict[dataset_name][\"similarity_matrix\"].loc[\n",
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==0)][\"image_name\"].values\n",
    "].mean(axis=0)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"].loc[\n",
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==1)][\"image_name\"].values\n",
    "][\"purple pen\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4960716",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"].loc[\n",
    "prove_logits_true[(prove_logits_true[\"truth\"]==0)&(prove_logits_true[\"prediction\"]==0)][\"image_name\"].values\n",
    "][\"purple pen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5dee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"labels_ref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90460953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "           \n",
    "           \n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07570bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name_list_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be280c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "test_result[\"labels\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32351676",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"statistics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"labels\"].shape, test_result[\"labels_ref\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb842ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sampe_list_minus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_minus].sum(axis=1).loc[test_result[\"labels_ref\"].index].rename(\"concept\"),\n",
    "test_result[\"labels_ref\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bae74",
   "metadata": {},
   "source": [
    "# just 5 and with concept ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4738146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    print(test_result[\"statistics\"].sort_values(\"diff_magnitude\", ascending=False))\n",
    "    \n",
    "    # get positive concept\n",
    "    concept_name_list_plus=test_result[\"on_the_spot_plus_pred\"][:5]\n",
    "    \n",
    "    # get image list\n",
    "    sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "    test_result[\"labels\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index   \n",
    "#     sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "# test_result[\"labels\"]], axis=1).sort_values([\"concept\"], ascending=[False]).index    \n",
    "    \n",
    "    # get title\n",
    "#     sampe_list_plus=test_result[\"labels\"].sort_values(\"kmeans_dist\").index\n",
    "#     test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "#                                   test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    sub_title_plus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_plus])\n",
    "    \n",
    "    # get negative concept\n",
    "    concept_name_list_minus=test_result[\"on_the_spot_minus_pred\"][:5]\n",
    "    \n",
    "    # get image list\n",
    "    sampe_list_minus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_minus].sum(axis=1).loc[test_result[\"labels_ref\"].index].rename(\"concept\"),\n",
    "    test_result[\"labels_ref\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[False, False]).index    \n",
    "#     sampe_list_minus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_minus].sum(axis=1).loc[test_result[\"labels_ref\"].index].rename(\"concept\"),\n",
    "# test_result[\"labels_ref\"]], axis=1).sort_values([\"concept\"], ascending=[False]).index        \n",
    "    # concept_name_list_minus=test_result[\"statistics\"][(test_result[\"statistics\"][\"diff_magnitude\"]<0)&(test_result[\"statistics\"][\"mean_value\"]>0.3)].sort_values(\"diff_magnitude\", ascending=True).iloc[:5].index.tolist()\n",
    "    \n",
    "    # get title\n",
    "    sub_title_minus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_minus])  \n",
    "    \n",
    "    if count<5:\n",
    "        data_dict_main[count]={\n",
    "            \"targets\": label_subset_proveai.astype(int),\n",
    "            \"preds\": (logits_subset_proveai>threshold_select).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus, \n",
    "                sampe_list_minus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }  \n",
    "    if count<20:\n",
    "        data_dict_supple[count]={\n",
    "            \"targets\": label_subset_proveai.astype(int),\n",
    "            \"preds\": (logits_subset_proveai>threshold_select).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus,\n",
    "                sampe_list_minus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }          \n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_dict in data_dict_supple.values():\n",
    "    y_true=data_dict[\"targets\"].loc[data_dict[\"sample_list_list\"][0]]\n",
    "    y_pred=data_dict[\"preds\"].loc[data_dict[\"sample_list_list\"][0]]\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0,1]).ravel())\n",
    "    print(tn, fp, fn, tp)\n",
    "    print((y_true==1).sum(),\"/\", (y_true==0).sum(), \"->\", (y_pred==1).sum(),\"/\", (y_pred==0).sum())\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99156a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=5,\n",
    "                      row_per_slice=1,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=10,\n",
    "                      row_per_slice=2,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test_conceptordered.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test_conceptordered.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19fd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac94c40",
   "metadata": {},
   "source": [
    "# just 5 and without concept ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    print(test_result[\"statistics\"].sort_values(\"diff_magnitude\", ascending=False))\n",
    "    \n",
    "    # get positive concept\n",
    "    concept_name_list_plus=test_result[\"on_the_spot_plus_pred\"][:5]\n",
    "    \n",
    "    # get image list\n",
    "    # sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "    # test_result[\"labels\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[True, False]).index   \n",
    "    sampe_list_plus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_plus].sum(axis=1).loc[test_result[\"labels\"].index].rename(\"concept\"),\n",
    "test_result[\"labels\"]], axis=1).sort_values([\"accuracy\"], ascending=[True]).index    \n",
    "    \n",
    "    # get title\n",
    "#     sampe_list_plus=test_result[\"labels\"].sort_values(\"kmeans_dist\").index\n",
    "#     test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "#                                   test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    sub_title_plus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_plus])\n",
    "    \n",
    "    # get negative concept\n",
    "    concept_name_list_minus=test_result[\"on_the_spot_minus_pred\"][:5]\n",
    "    \n",
    "    # get image list\n",
    "    # sampe_list_minus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_minus].sum(axis=1).loc[test_result[\"labels_ref\"].index].rename(\"concept\"),\n",
    "    # test_result[\"labels_ref\"]], axis=1).sort_values([\"accuracy\", \"concept\"], ascending=[False, False]).index    \n",
    "    sampe_list_minus=pd.concat([variable_dict[dataset_name][\"similarity_matrix\"][concept_name_list_minus].sum(axis=1).loc[test_result[\"labels_ref\"].index].rename(\"concept\"),\n",
    "test_result[\"labels_ref\"]], axis=1).sort_values([\"accuracy\"], ascending=[False]).index        \n",
    "    # concept_name_list_minus=test_result[\"statistics\"][(test_result[\"statistics\"][\"diff_magnitude\"]<0)&(test_result[\"statistics\"][\"mean_value\"]>0.3)].sort_values(\"diff_magnitude\", ascending=True).iloc[:5].index.tolist()\n",
    "    \n",
    "    # get title\n",
    "    sub_title_minus=\", \".join([shorten_concept_name(i, strict=False) for i in concept_name_list_minus])  \n",
    "    \n",
    "    if count<5:\n",
    "        data_dict_main[count]={\n",
    "            \"targets\": label_subset_proveai.astype(int),\n",
    "            \"preds\": (logits_subset_proveai>threshold_select).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus, \n",
    "                sampe_list_minus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }  \n",
    "    if count<20:\n",
    "        data_dict_supple[count]={\n",
    "            \"targets\": label_subset_proveai.astype(int),\n",
    "            \"preds\": (logits_subset_proveai>threshold_select).astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "            \"sample_list_list\":[\n",
    "                sampe_list_plus,\n",
    "                sampe_list_minus\n",
    "            ],           \n",
    "            \"main_title\": [sub_title_plus, sub_title_minus],\n",
    "        #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "        }          \n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441df106",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=5,\n",
    "                      row_per_slice=1,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=10,\n",
    "                      row_per_slice=2,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d91514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac58e8a",
   "metadata": {},
   "source": [
    "# purple pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"][\"purple pen\"].sort_values(ascending=False).index[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdb577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"][\"purple pen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b01374",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_subset_proveai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_subset_proveai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(logits_subset_proveai>threshold_select).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-335/508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6811880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_subset_proveai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440746ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "    \n",
    "    return {\n",
    "        \"sensitivity\": tp / (tp+fn),\n",
    "        \"specificity\": tn / (tn+fp),\n",
    "        \"auroc\": sklearn.metrics.roc_auc_score(y_true=y_true, y_score=y_score),\n",
    "        \"accuracy\": (y_true==y_pred).mean()   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5323ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c791e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ad2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name=\"skincon_Poikiloderma\"\n",
    "top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[:100]\n",
    "bottom_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=True).index[:100]\n",
    "below_top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e92740",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[top_idx]\n",
    "num_bottom=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[below_top_idx].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([\n",
    "    [num_top.sum(), (1-num_top).sum()],\n",
    "    [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "], alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([\n",
    "    [num_top.sum(), (1-num_top).sum()],\n",
    "    [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "], alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_top.sum()/ (1-num_top).sum())/(num_bottom.sum()/(1-num_bottom).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([\n",
    "    [num_top.sum(), (1-num_top).sum()],\n",
    "    [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "], alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da79c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([\n",
    "    [num_top.sum(), (1-num_top).sum()],\n",
    "    [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "], alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name=\"skincon_Poikiloderma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[:100]\n",
    "bottom_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=True).index[:100]\n",
    "below_top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:]\n",
    "\n",
    "\n",
    "\n",
    "num_top=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[top_idx]\n",
    "num_bottom=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[below_top_idx]\n",
    "\n",
    "\n",
    "num_test=fisher_exact([\n",
    "        [num_top.sum(), (1-num_top).sum()],\n",
    "        [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "    ], alternative='greater')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159dd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([\n",
    "    [num_top.sum(), num_bottom.sum()],\n",
    "    [(1-num_top).sum(), (1-num_bottom).sum()]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61642438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    [num_top.sum(), num_bottom.sum()],\n",
    "    [(1-num_top).sum(), (1-num_bottom).sum()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    [num_top.sum(), (1-num_top).sum()],\n",
    "    [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_top=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[top_idx]\n",
    "    num_bottom=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[below_top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp=[]\n",
    "\n",
    "idx_benign=pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index)[\n",
    "    pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index)==0\n",
    "].index\n",
    "\n",
    "idx_all=variable_dict[dataset_name][\"metadata_all\"].index\n",
    "\n",
    "idx_select=idx_benign\n",
    "\n",
    "for concept_name in variable_dict[dataset_name][\"similarity_matrix\"].columns:\n",
    "\n",
    "    top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[:100]\n",
    "    bottom_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=True).index[:100]\n",
    "    below_top_idx=variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:]\n",
    "\n",
    "    \n",
    "    \n",
    "    num_top=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[top_idx]\n",
    "    num_bottom=(prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int).loc[below_top_idx]\n",
    "    \n",
    "    \n",
    "    num_test=fisher_exact([\n",
    "            [num_top.sum(), (1-num_top).sum()],\n",
    "            [num_bottom.sum(), (1-num_bottom).sum()]\n",
    "        ], alternative='greater')    \n",
    "    \n",
    "    correct_top=((prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int)==prove_logits_true.set_index(\"image_name\")[\"truth\"]).astype(int).loc[top_idx]\n",
    "    correct_bottom=((prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).astype(int)==prove_logits_true.set_index(\"image_name\")[\"truth\"]).astype(int).loc[below_top_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    record_dict_list_temp.append(\n",
    "        {\n",
    "            \"concept_name\": concept_name,\n",
    "            \"prop_top\": (1-num_top.mean()),\n",
    "            \"prop_bottom\": 1-num_bottom.mean(),\n",
    "            \"prop_diff\": -num_top.mean()+num_bottom.mean(),\n",
    "            \"num_test_statistic\": num_test.statistic,\n",
    "            \"num_test_pval\": num_test.pvalue,\n",
    "            \"accuracy_top\": correct_top.mean(),\n",
    "            \"accuracy_bottom\": correct_bottom.mean(),\n",
    "            \"accuracy_diff\": correct_top.mean()-correct_bottom.mean(),\n",
    "        }\n",
    "\n",
    "    )\n",
    "    #label_subset_proveai.astype(int),\"preds\": (logits_subset_proveai>threshold_select).astype(int),    \n",
    "#     print(concept_name, (logits_subset_proveai>threshold_select).astype(int).loc[top_idx].sum(),\n",
    "#           (logits_subset_proveai>threshold_select).astype(int).loc[bottom_idx].sum(),\n",
    "#           (logits_subset_proveai>threshold_select).astype(int).loc[top_idx].sum()-(logits_subset_proveai>threshold_select).astype(int).loc[bottom_idx].sum()\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a590dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df=pd.DataFrame(record_dict_list_temp)\n",
    "record_dict_list_temp_df[record_dict_list_temp_df[\"concept_name\"].map(lambda x: check_concept_name('proveai', x))]\\\n",
    ".sort_values(\"prop_diff\", ascending=True)\\\n",
    ".rename(columns={\"prop_top\": \"specificity_top100\",\n",
    "                 \"prop_bottom\": \"specificity_rest\",\n",
    "                 \"prop_diff\": \"specificity_diff\",\n",
    "                 \"num_test_statistic\": \"odd ratio\",\n",
    "                 \"num_test_pval\": \"fisher_pval\",\n",
    "                })\\\n",
    "[['concept_name', 'specificity_top100', 'specificity_rest',\n",
    "       'specificity_diff', 'odd ratio', 'fisher_pval']]\\\n",
    ".iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1336cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df=pd.DataFrame(record_dict_list_temp)\n",
    "\n",
    "record_dict_list_temp_df=record_dict_list_temp_df[record_dict_list_temp_df[\"concept_name\"].map(lambda x: check_concept_name('proveai', x))]\n",
    "\n",
    "multiple_testing_correction=multitest.multipletests(\n",
    "pvals=record_dict_list_temp_df[\"num_test_pval\"].values,\n",
    "method=\"bonferroni\"\n",
    ")\n",
    "record_dict_list_temp_df[\"reject\"]=multiple_testing_correction[0]\n",
    "record_dict_list_temp_df[\"num_test_pval\"]=multiple_testing_correction[1]\n",
    "record_dict_list_temp_df[\"alphacSidak\"]=multiple_testing_correction[2]\n",
    "record_dict_list_temp_df[\"alphacBonf\"]=multiple_testing_correction[3]\n",
    "\n",
    "\n",
    "record_dict_list_temp_df_latex=record_dict_list_temp_df.copy()\n",
    "record_dict_list_temp_df_latex[\"concept_name\"]=record_dict_list_temp_df_latex[\"concept_name\"].map(shorten_concept_name)\n",
    "\n",
    "record_dict_list_temp_df_latex[\"num_test_pval\"]=record_dict_list_temp_df_latex[\"num_test_pval\"].map(lambda x: f\"{x:.3e}\")\n",
    "record_dict_list_temp_df_latex[\"prop_top\"]=record_dict_list_temp_df_latex[\"prop_top\"]\n",
    "record_dict_list_temp_df_latex[\"prop_bottom\"]=record_dict_list_temp_df_latex[\"prop_bottom\"]\n",
    "record_dict_list_temp_df_latex[[\"prop_top\",\n",
    "                          \"prop_bottom\",\n",
    "                          \"num_test_statistic\"\n",
    "                         ]]=record_dict_list_temp_df_latex[[\"prop_top\",\n",
    "                          \"prop_bottom\",\n",
    "                          \"num_test_statistic\"\n",
    "                         ]].round(3)\n",
    "# float_format_func=lambda x: f\"{x:.3e}\".replace(\"e\", \"\\\\times\")\n",
    "# record_dict_list_temp_df_latex[\"concept_name\"].map(shorten_concept_name)\n",
    "table_latex=record_dict_list_temp_df_latex.sort_values(\"prop_diff\", ascending=True)\\\n",
    ".rename(columns={\"prop_top\": \"specificity_top100\",\n",
    "                 \"prop_bottom\": \"specificity_rest\",\n",
    "                 \"prop_diff\": \"specificity_diff\",\n",
    "                 \"num_test_statistic\": \"odd ratio\",\n",
    "                 \"num_test_pval\": \"fisher_pval\",\n",
    "                })\\\n",
    "[['concept_name', 'specificity_top100', \"specificity_rest\", \"odd ratio\", 'fisher_pval']].to_latex(index=False,\n",
    "# formatters={\"fisher_pval\": float_format_func}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df_latex.sort_values(\"prop_diff\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6dfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_latex)#.replace(\"e-\",\" \\\\times 10^{-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df_latex.sort_values(\"prop_diff\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b963ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.05/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce8e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitest.multipletests(\n",
    "pvals=record_dict_list_temp_df[\"num_test_pval\"].values,\n",
    "method=\"bonferroni\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bfa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df_latex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3345123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitest.multipletests(\n",
    "pvals=record_dict_list_temp_df[\"num_test_pval\"].values,\n",
    "method=\"bonferroni\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df[\"num_test_pval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d4c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_temp_df=pd.DataFrame(record_dict_list_temp)\n",
    "record_dict_list_temp_df[record_dict_list_temp_df[\"concept_name\"].map(lambda x: check_concept_name('proveai', x))]\\\n",
    ".sort_values(\"accuracy_diff\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_dict_list_temp).sort_values(\"num_diff\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_concept_name(concept_name, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "#shorten_concept_name(i, strict=False)\n",
    "    \n",
    "idx_select=idx_benign\n",
    "\n",
    "# concept_name=\"skincon_Poikiloderma\"\n",
    "concept_name=\"pinkish\"\n",
    "\n",
    "if False:\n",
    "    data_test={\n",
    "        \"targets\": prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[idx_select].astype(int),\n",
    "        \"preds\": (prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).loc[idx_select].astype(int),\n",
    "    #         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "    # #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "    #                             ],\n",
    "        \"sample_list_list\":[\n",
    "            variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[:100], \n",
    "    #         np.random.RandomState(seed=42).choice(\n",
    "    #         variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:],\n",
    "    #         100, replace=False)        \n",
    "            variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[-100:]\n",
    "\n",
    "        ],           \n",
    "        \"main_title\": [\"The top 100 images for \"+shorten_concept_name(concept_name, strict=False), \n",
    "                       \"The bottom 100 images for \"+shorten_concept_name(concept_name, strict=False), \n",
    "                      # \"100 sampled images that are not included in top 100\"\n",
    "                      ],\n",
    "    #     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "    }  \n",
    "    count+=1    \n",
    "\n",
    "data_test={\n",
    "    \"targets\": prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[idx_select].astype(int),\n",
    "    \"preds\": (prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).loc[idx_select].astype(int),\n",
    "#         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "# #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "#                             ],\n",
    "    \"sample_list_list\":[\n",
    "        variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[:100], \n",
    "#         np.random.RandomState(seed=42).choice(\n",
    "#         variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:],\n",
    "#         100, replace=False)        \n",
    "\n",
    "    ],           \n",
    "    \"main_title\": [\"The top 100 images for \"+shorten_concept_name(concept_name, strict=False), \n",
    "                  # \"100 sampled images that are not included in top 100\"\n",
    "                  ],\n",
    "#     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "}  \n",
    "data_dict_main[count]=data_test\n",
    "data_dict_supple[count]=data_test \n",
    "\n",
    "count+=1\n",
    "\n",
    "data_test={\n",
    "    \"targets\": prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[idx_select].astype(int),\n",
    "    \"preds\": (prove_logits_true.set_index(\"image_name\")[\"scores\"]>threshold_select).loc[idx_select].astype(int),\n",
    "#         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "# #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "#                             ],\n",
    "    \"sample_list_list\":[\n",
    "#         np.random.RandomState(seed=42).choice(\n",
    "#         variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[100:],\n",
    "#         100, replace=False)        \n",
    "        variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=False).index[-100:]\n",
    "\n",
    "    ],           \n",
    "    \"main_title\": [\"The bottom 100 images for \"+shorten_concept_name(concept_name, strict=False), \n",
    "                  # \"100 sampled images that are not included in top 100\"\n",
    "                  ],\n",
    "#     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "}  \n",
    "\n",
    "data_dict_main[count]=data_test\n",
    "data_dict_supple[count]=data_test       \n",
    "\n",
    "count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_concept_name(concept_name, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f02cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"].loc[\"ISIC_6410859\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"][\"copyright_license\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"metadata_all\"].loc[list(data_dict_supple[i][\"sample_list_list\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97592a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_dict_supple:\n",
    "    print()\n",
    "    sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317e526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e18832",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=10,\n",
    "                      row_per_slice=10,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      print_legend_color_idx=2+90,\n",
    "                      task_type=\"melanoma\",\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_top_bottom_{concept_name}.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_top_bottom_{concept_name}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ccada",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_top_bottom_{concept_name}.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_top_bottom_{concept_name}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82375b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_figure??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870e249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "skincon_Atrophy\n",
    "skincon_Poikiloderma\n",
    "pinkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1770b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_subset_proveai.astype(int).loc[top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd022be",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].sort_values(ascending=True).index[:99]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in variable_dict[dataset_name][\"similarity_matrix\"].columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.choice(variable_dict[dataset_name][\"similarity_matrix\"][concept_name].loc[idx_select].index,\n",
    "                size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_logits_true.set_index(\"image_name\").loc[idx_select][\"prediction\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a1086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres=variable_dict[dataset_name][\"similarity_matrix\"].quantile(0.5, axis=0)\n",
    "data_dict_main={}\n",
    "data_dict_supple={}\n",
    "count=0\n",
    "    \n",
    "    \n",
    "idx_select=pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index)[\n",
    "    pd.Series(variable_dict[dataset_name][\"y_pos\"], index=variable_dict[dataset_name][\"metadata_all\"].index)==0   \n",
    "].index    \n",
    "\n",
    "data_test={\n",
    "    \"targets\": label_subset_proveai.astype(int),\n",
    "    \"preds\": (logits_subset_proveai>threshold_select).astype(int),\n",
    "#         \"sample_list_list\": [test_result[\"labels\"].sort_values(\"kmeans_dist\").index,\n",
    "# #                              test_result[\"labels_ref\"].sort_values(\"kmeans_dist\").index\n",
    "#                             ],\n",
    "    \"sample_list_list\":[\n",
    "        logits_subset_proveai[(logits_subset_proveai>threshold_select)].index[:100], \n",
    "        logits_subset_proveai[(logits_subset_proveai<=threshold_select)].index[:100]\n",
    "    ],           \n",
    "    \"main_title\": [\"wrong\", \"correct\"],\n",
    "#     \"slice_assignment_list\": [slice_assignment_from1_to2[:,slice_idx] for slice_idx in [3]],\n",
    "}  \n",
    "\n",
    "data_dict_main[count]=data_test\n",
    "data_dict_supple[count]=data_test       \n",
    "\n",
    "count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                      prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                      example_per_row=10,\n",
    "                      row_per_slice=10,\n",
    "                      normalize=True, \n",
    "                      show_small_box=True,\n",
    "                      skip_section=0,\n",
    "                      print_alphabet=True,\n",
    "                      print_legend_number=True,\n",
    "                      print_legend_color=True,\n",
    "                      true_pred_count_fontsize=16,\n",
    "                      fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                      figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test_sorted_wrong_correct.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/f\"model_audit_ADAE_test_sorted_wrong_correct.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_title_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skincon_Poikiloderma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2abc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87c184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4d040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27387bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c274dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a149941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0befff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cafb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce4911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_info_focus_copy_group_proveai_concept_only.sort_values(\"accuracy\")\\\n",
    "[[\"count\", \"accuracy\", \"loss\", \"label_frequent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4489944",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_idx 0 / metric: 0.047619047619047616 / 0.37662337662337664/ mean metric: 0.3405511811023622\n",
    "cluster_idx 1 / metric: 0.1388888888888889 / 0.37662337662337664/ mean metric: 0.3405511811023622\n",
    "cluster_idx 2 / metric: 0.21212121212121213 / 0.6140350877192983/ mean metric: 0.3405511811023622\n",
    "cluster_idx 3 / metric: 0.2682926829268293 / 0.3488372093023256/ mean metric: 0.3405511811023622\n",
    "cluster_idx 0 / metric: 0.047619047619047616 / 0.37662337662337664/ mean metric: 0.3405511811023622\n",
    "cluster_idx 1 / metric: 0.1388888888888889 / 0.37662337662337664/ mean metric: 0.3405511811023622\n",
    "cluster_idx 2 / metric: 0.21212121212121213 / 0.6140350877192983/ mean metric: 0.3405511811023622\n",
    "cluster_idx 3 / metric: 0.2682926829268293 / 0.3488372093023256/ mean metric: 0.3405511811023622\n",
    "cluster_idx 4 / metric: 0.3488372093023256 / 0.3488372093023256/ mean metric: 0.3405511811023622\n",
    "cluster_idx 5 / metric: 0.3684210526315789 / 0.3684210526315789/ mean metric: 0.3405511811023622\n",
    "cluster_idx 6 / metric: 0.37662337662337664 / 0.37662337662337664/ mean metric: 0.3405511811023622\n",
    "cluster_idx 7 / metric: 0.3793103448275862 / 0.3793103448275862/ mean metric: 0.3405511811023622\n",
    "cluster_idx 8 / metric: 0.4230769230769231 / 0.4230769230769231/ mean metric: 0.3405511811023622\n",
    "cluster_idx 9 / metric: 0.6140350877192983 / 0.6140350877192983/ mean metric: 0.3405511811023622\n",
    "508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a647d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b63d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278f0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa829dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50737107",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_idx 0 / metric: 0.047619047619047616 /  mean metric: 0.3405511811023622\n",
    "cluster_idx 1 / metric: 0.1388888888888889 /  mean metric: 0.3405511811023622\n",
    "cluster_idx 2 / metric: 0.21212121212121213 /  mean metric: 0.3405511811023622\n",
    "cluster_idx 3 / metric: 0.2682926829268293 /  mean metric: 0.3405511811023622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a152c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa09308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c70ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53551d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8be09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d883000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a066d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"temp.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d326ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f31ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_supple,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=5,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=True,\n",
    "                  print_legend_number=True,\n",
    "                  print_legend_color=True,\n",
    "                    true_pred_count_fontsize=16,\n",
    "                    fontsize=16,\n",
    "                      slice_title_fontsize=16,\n",
    "                  figure_title=None)\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_supple.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c228ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a1ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f268a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780823d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4ed63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6faf673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d5fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce823550",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_figure??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a92294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0][\"targets\"].sum(),data_dict_supple[0][\"preds\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0][\"targets\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[1][\"targets\"].sum(),data_dict_supple[1][\"preds\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e13270",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[2][\"targets\"].sum(),data_dict_supple[2][\"preds\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5195ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[2][\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_supple[0][\"preds\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a729cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_list_proveai_concept_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cf7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_result in test_result_list_proveai_concept_only:\n",
    "    y_true=prove_logits_true.set_index(\"image_name\")[\"truth\"].loc[test_result[\"labels\"].index]\n",
    "    y_pred=(prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index])>0.05\n",
    "    #y_pred=(prove_logits_true.set_index(\"image_name\")[\"prediction\"].loc[test_result[\"labels\"].index])\n",
    "    y_score=prove_logits_true.set_index(\"image_name\")[\"target\"].loc[test_result[\"labels\"].index]\n",
    "\n",
    "    if (y_true==y_pred).all():\n",
    "        continue\n",
    "    \n",
    "    tn, fp, fn, tp = (sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel())\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"sensitivity\", tp / (tp+fn)) # tp / P\n",
    "    print(\"specificity\", tn / (tn+fp)) # tn / N\n",
    "    if y_true.all() or (~y_true).all():\n",
    "        pass\n",
    "    else:\n",
    "        print(\"auroc\", sklearn.metrics.roc_auc_score(y_true=y_true,\n",
    "                                     y_score=y_score))  \n",
    "    print(\"accuracy\", (y_true==y_pred).mean())    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d207e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_slice_figure(dataset_name=dataset_name,\n",
    "                      data_dict=data_dict_main,\n",
    "                  prompt_info=variable_dict[dataset_name][\"prompt_info\"],\n",
    "                  example_per_row=5,\n",
    "                  row_per_slice=1,\n",
    "                  normalize=True, \n",
    "                  show_small_box=True,\n",
    "                  skip_section=0,\n",
    "                  print_alphabet=False,\n",
    "                  print_legend_number=False,\n",
    "                  print_legend_color=False,\n",
    "                  slice_title_fontsize=27,\n",
    "                  figure_title=(\"E. \", \"Trained at Hosp. Barcelona / Tested at Med U. Vienna\"))\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_main.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"model_audit_from2_to1_main.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0563c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3bb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f29742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a0c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
