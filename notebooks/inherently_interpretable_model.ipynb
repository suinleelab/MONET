{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f3b372",
   "metadata": {},
   "source": [
    "# set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(os.path.abspath(\"inherently_interpretable_model.ipynb\"), pythonpath=True)\n",
    "import os\n",
    "\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60ebd7",
   "metadata": {},
   "source": [
    "# set python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(root / \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61656244",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import norm, pearsonr\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import clip\n",
    "from MONET.datamodules.multiplex_datamodule import MultiplexDatamodule\n",
    "from MONET.utils.loader import custom_collate_per_key, dataloader_apply_func\n",
    "from MONET.utils.static import (\n",
    "    concept_to_prompt,\n",
    "    fitzpatrick17k_disease_label,\n",
    "    fitzpatrick17k_ninelabel,\n",
    "    fitzpatrick17k_threelabel,\n",
    "    skincon_cols,\n",
    ")\n",
    "from MONET.utils.text_processing import generate_prompt_token_from_concept\n",
    "from MONET.utils.io import load_pkl\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_to_exppath(wandb, log_path=\"/gscratch/cse/chanwkim/MONET_log/train/runs\"):\n",
    "    log_path = Path(log_path)\n",
    "    for experiment in os.listdir(log_path):\n",
    "        if os.path.exists(log_path / experiment / \"wandb\"):\n",
    "            filenames = os.listdir(log_path / experiment / \"wandb\")\n",
    "            filename = [filename for filename in filenames if filename.startswith(\"run\")][0][-8:]\n",
    "            if filename == wandb:\n",
    "                return log_path / experiment\n",
    "    raise RuntimeError(\"not found\")\n",
    "\n",
    "\n",
    "# exppath = wandb_to_exppath(\n",
    "#     wandb=\"15eh81uv\", log_path=\"/projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs\"\n",
    "# )\n",
    "# print([exppath / \"checkpoints\" / ckpt for ckpt in os.listdir(exppath / \"checkpoints/\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db480f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed8eb5",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zt0n2xd0\"\n",
    "model_device = \"cuda:7\"\n",
    "\n",
    "cfg_model = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"contrastive.yaml\")\n",
    "cfg_model.net.model_name_or_path = \"ViT-L/14\"\n",
    "cfg_model.net.device = model_device\n",
    "cfg_model\n",
    "\n",
    "model = hydra.utils.instantiate(cfg_model)\n",
    "model.to(model_device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_dir = {\n",
    "    \"zt0n2xd0\": \"/projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs/2023-01-17_20-58-15/checkpoints/last.ckpt\",\n",
    "}\n",
    "\n",
    "if model_name != \"ViT-L/14\":\n",
    "    model_path = model_path_dir[model_name]\n",
    "    loaded = torch.load(model_path, map_location=model_device)\n",
    "    model.load_state_dict(loaded[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zt0n2xd0\"\n",
    "model_device = \"cuda:7\"\n",
    "\n",
    "cfg_model = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"contrastive.yaml\")\n",
    "cfg_model.net.model_name_or_path = \"ViT-L/14\"\n",
    "cfg_model.net.device = model_device\n",
    "cfg_model\n",
    "\n",
    "model_vanilla = hydra.utils.instantiate(cfg_model)\n",
    "model_vanilla.to(model_device)\n",
    "model_vanilla.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "# cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "cfg_dm.dataset_name_test = \"fitzpatrick17k_skincon=all\"\n",
    "# cfg_dm.dataset_name_test = \"fitzpatrick17k=all\"\n",
    "\n",
    "# cfg_dm.dataset_name_train =\n",
    "\n",
    "cfg_dm.split_seed = 42\n",
    "cfg_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85962af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cfg_dm.dataset_name_test = \"fitzpatrick17k_clean_threelabel_nodup=all\"\n",
    "dm = hydra.utils.instantiate(cfg_dm)\n",
    "dm.setup()\n",
    "# train_dataloader = dm.train_dataloader()\n",
    "test_dataloader_f17k = dm.test_dataloader()\n",
    "\n",
    "cfg_dm.dataset_name_test = \"fitzpatrick17k_threelabel=all\"\n",
    "dm = hydra.utils.instantiate(cfg_dm)\n",
    "dm.setup()\n",
    "# train_dataloader = dm.train_dataloader()\n",
    "test_dataloader_f17k_all = dm.test_dataloader()\n",
    "\n",
    "cfg_dm.dataset_name_test = \"ddi=all\"\n",
    "dm = hydra.utils.instantiate(cfg_dm)\n",
    "dm.setup()\n",
    "# train_dataloader = dm.train_dataloader()\n",
    "test_dataloader_ddi = dm.test_dataloader()\n",
    "\n",
    "cfg_dm.dataset_name_test = \"fitzpatrick17k_skincon=all\"\n",
    "dm = hydra.utils.instantiate(cfg_dm)\n",
    "dm.setup()\n",
    "# train_dataloader = dm.train_dataloader()\n",
    "test_dataloader_f17k_skincon = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74561b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_func(batch):\n",
    "    with torch.no_grad():\n",
    "        batch[\"image\"] = batch[\"image\"].to(model_device)\n",
    "        image_features = model.model_step_with_image(batch)[\"image_features\"]\n",
    "    # print(batch[\"metadata\"])\n",
    "    return {\n",
    "#         \"image\":  batch[\"image\"],\n",
    "        \"image_features\": image_features.detach().cpu(),\n",
    "        \"metadata\": batch[\"metadata\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Featurizing and saving...\")\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_f17k,\n",
    "    func=batch_func,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_f17k = loader_applied[\"metadata\"]\n",
    "image_features_f17k = loader_applied[\"image_features\"].cpu()\n",
    "\n",
    "\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_f17k_all,\n",
    "    func=batch_func,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_f17k_all = loader_applied[\"metadata\"]\n",
    "image_features_f17k_all = loader_applied[\"image_features\"].cpu()\n",
    "\n",
    "\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_ddi,\n",
    "    func=batch_func,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_ddi = loader_applied[\"metadata\"]\n",
    "image_features_ddi = loader_applied[\"image_features\"].cpu()\n",
    "\n",
    "\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_f17k_skincon,\n",
    "    func=batch_func,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_f17k_skincon = loader_applied[\"metadata\"]\n",
    "image_features_f17k_skincon = loader_applied[\"image_features\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_func_vanilla_clip(batch):\n",
    "    with torch.no_grad():\n",
    "        batch[\"image\"] = batch[\"image\"].to(model_device)\n",
    "        image_features = model_vanilla.model_step_with_image(batch)[\"image_features\"]\n",
    "    # print(batch[\"metadata\"])\n",
    "    return {\n",
    "#         \"image\":  batch[\"image\"],\n",
    "        \"image_features\": image_features.detach().cpu(),\n",
    "        \"metadata\": batch[\"metadata\"],\n",
    "    }\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_f17k,\n",
    "    func=batch_func_vanilla_clip,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_f17k_vanilla = loader_applied[\"metadata\"]\n",
    "image_features_f17k_vanilla = loader_applied[\"image_features\"].cpu()\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_f17k_all,\n",
    "    func=batch_func_vanilla_clip,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_f17k_all_vanilla = loader_applied[\"metadata\"]\n",
    "image_features_f17k_all_vanilla = loader_applied[\"image_features\"].cpu()\n",
    "# images_all_f17k = loader_applied[\"images\"]\n",
    "\n",
    "loader_applied = dataloader_apply_func(\n",
    "    dataloader=test_dataloader_ddi,\n",
    "    func=batch_func_vanilla_clip,\n",
    "    collate_fn=custom_collate_per_key,\n",
    ")\n",
    "metadata_all_ddi_vanilla = loader_applied[\"metadata\"]\n",
    "image_features_ddi_vanilla = loader_applied[\"image_features\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_map = {\n",
    "    \"acral-melanotic-macule\": \"melanoma look-alike\",\n",
    "    \"atypical-spindle-cell-nevus-of-reed\": \"melanoma look-alike\",\n",
    "    \"benign-keratosis\": \"melanoma look-alike\",\n",
    "    \"blue-nevus\": \"melanoma look-alike\",\n",
    "    \"dermatofibroma\": \"melanoma look-alike\",\n",
    "    \"dysplastic-nevus\": \"melanoma look-alike\",\n",
    "    \"epidermal-nevus\": \"melanoma look-alike\",\n",
    "    \"hyperpigmentation\": \"melanoma look-alike\",\n",
    "    \"keloid\": \"melanoma look-alike\",\n",
    "    \"inverted-follicular-keratosis\": \"melanoma look-alike\",\n",
    "    \"melanocytic-nevi\": \"melanoma look-alike\",\n",
    "    \"melanoma\": \"melanoma\",\n",
    "    \"melanoma-acral-lentiginous\": \"melanoma\",\n",
    "    \"melanoma-in-situ\": \"melanoma\",\n",
    "    \"nevus-lipomatosus-superficialis\": \"melanoma look-alike\",\n",
    "    \"nodular-melanoma-(nm)\": \"melanoma\",\n",
    "    \"pigmented-spindle-cell-nevus-of-reed\": \"melanoma look-alike\",\n",
    "    \"seborrheic-keratosis\": \"melanoma look-alike\",\n",
    "    \"seborrheic-keratosis-irritated\": \"melanoma look-alike\",\n",
    "    \"solar-lentigo\": \"melanoma look-alike\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd09e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"index\" not in metadata_all_ddi:\n",
    "    metadata_all_ddi = metadata_all_ddi.reset_index()\n",
    "#     metadata_all_ddi = metadata_all_ddi[(metadata_all_ddi[\"skincon_Do not consider this image\"]!=1).values]\n",
    "if \"index\" not in metadata_all_f17k:\n",
    "    metadata_all_f17k = metadata_all_f17k.reset_index()\n",
    "#     metadata_all_f17k = metadata_all_f17k[(metadata_all_f17k[\"skincon_Do not consider this image\"]!=1).values]\n",
    "if \"index\" not in metadata_all_f17k_all:\n",
    "    metadata_all_f17k_all = metadata_all_f17k_all.reset_index()\n",
    "#     metadata_all_f17k_all = metadata_all_f17k_all[(metadata_all_f17k_all[\"skincon_Do not consider this image\"]!=1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_all_f17k_filtered = metadata_all_f17k.query(\n",
    "#     \"nine_partition_label == 'malignant melanoma'\"\n",
    "#     \" | nine_partition_label == 'benign melanocyte'\"\n",
    "#     \" | label == 'seborrheic keratosis'\"\n",
    "#     \" | label == 'dermatofibroma'\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter f17k and ddi datasets to melanoma and melanoma look alikes\n",
    "metadata_all_f17k_filtered = metadata_all_f17k.query(\n",
    "    \"nine_partition_label == 'malignant melanoma'\"\n",
    "    \" | nine_partition_label == 'benign melanocyte'\"\n",
    "    \" | label == 'seborrheic keratosis'\"\n",
    "    \" | label == 'dermatofibroma'\"\n",
    ")\n",
    "\n",
    "image_features_f17k_filtered = image_features_f17k[metadata_all_f17k_filtered.index]\n",
    "image_features_f17k_filtered_vanilla = image_features_f17k_vanilla[metadata_all_f17k_filtered.index]\n",
    "print(image_features_f17k_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_all_f17k_all_filtered = metadata_all_f17k_all.query(\n",
    "    \"nine_partition_label == 'malignant melanoma'\"\n",
    "    \" | nine_partition_label == 'benign melanocyte'\"\n",
    "    \" | label == 'seborrheic keratosis'\"\n",
    "    \" | label == 'dermatofibroma'\"\n",
    ")\n",
    "image_features_f17k_all_filtered = image_features_f17k_all[metadata_all_f17k_all_filtered.index]\n",
    "image_features_f17k_all_filtered_vanilla = image_features_f17k_all_vanilla[metadata_all_f17k_all_filtered.index]\n",
    "print(image_features_f17k_all_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_kws = set(ddi_map.keys())\n",
    "metadata_all_ddi_filtered = metadata_all_ddi.query(\"disease in @mimic_kws\")\n",
    "image_features_ddi_filtered = image_features_ddi[metadata_all_ddi_filtered.index]\n",
    "image_features_ddi_filtered_vanilla = image_features_ddi_vanilla[metadata_all_ddi_filtered.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_all_melanoma = torch.cat((image_features_f17k_filtered, image_features_ddi_filtered))\n",
    "image_features_all_malignancy = torch.cat((image_features_f17k, image_features_ddi))\n",
    "image_features_all_f17all_melanoma = torch.cat((image_features_f17k_all_filtered, image_features_ddi_filtered))\n",
    "image_features_all_f17all_malignancy = torch.cat((image_features_f17k_all, image_features_ddi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_all_melanoma_vanilla = torch.cat((image_features_f17k_filtered_vanilla, image_features_ddi_filtered_vanilla))\n",
    "image_features_all_malignancy_vanilla = torch.cat((image_features_f17k_vanilla, image_features_ddi_vanilla))\n",
    "image_features_all_f17all_melanoma_vanilla = torch.cat((image_features_f17k_all_filtered_vanilla, image_features_ddi_filtered_vanilla))\n",
    "image_features_all_f17all_malignancy_vanilla = torch.cat((image_features_f17k_all_vanilla, image_features_ddi_vanilla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4777ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d0420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_features_all = image_features_f17k\n",
    "y_f17k_melanoma = list(\n",
    "    map(\n",
    "        lambda x: int(x),\n",
    "        list(metadata_all_f17k_filtered[\"nine_partition_label\"] == \"malignant melanoma\"),\n",
    "    )\n",
    ")\n",
    "y_f17k_all_melanoma = list(\n",
    "    map(\n",
    "        lambda x: int(x),\n",
    "        list(metadata_all_f17k_all_filtered[\"nine_partition_label\"] == \"malignant melanoma\"),\n",
    "    )\n",
    ")\n",
    "y_f17k_malignancy = list(\n",
    "    map(\n",
    "        lambda x: int(x),\n",
    "        list(metadata_all_f17k[\"three_partition_label\"] == \"malignant\"),\n",
    "    )\n",
    ")\n",
    "y_f17k_all_malignancy = list(\n",
    "    map(\n",
    "        lambda x: int(x),\n",
    "        list(metadata_all_f17k_all[\"three_partition_label\"] == \"malignant\"),\n",
    "    )\n",
    ")\n",
    "#y_ddi_melanoma = list(map(lambda x: int(x), metadata_all_ddi_filtered[\"disease\"] == \"melanoma\"))\n",
    "y_ddi_melanoma = list(map(lambda x: int(x), metadata_all_ddi_filtered[\"disease\"].map(lambda x: ddi_map[x]) == \"melanoma\"))\n",
    "y_ddi_malignancy = list(map(lambda x: int(x), metadata_all_ddi[\"malignant\"]))\n",
    "\n",
    "y_melanoma = y_f17k_melanoma + y_ddi_melanoma\n",
    "y_melanoma_all = y_f17k_all_melanoma + y_ddi_melanoma\n",
    "y_malignancy = y_f17k_malignancy + y_ddi_malignancy\n",
    "y_malignancy_all = y_f17k_all_malignancy + y_ddi_malignancy\n",
    "\n",
    "metadata_all_melanoma=pd.concat([metadata_all_f17k_filtered, metadata_all_ddi_filtered], axis=0)\n",
    "metadata_all_melanoma_all=pd.concat([metadata_all_f17k_all_filtered, metadata_all_ddi_filtered], axis=0)\n",
    "metadata_all_malignancy=pd.concat([metadata_all_f17k, metadata_all_ddi], axis=0)\n",
    "metadata_all_malignancy_all=pd.concat([metadata_all_f17k_all, metadata_all_ddi], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fc499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2041d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_f17k_melanoma).sum(), (1-np.array(y_f17k_melanoma)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f2a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324f8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff51e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array(y_f17k_melanoma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_melanoma).sum(), (1-np.array(y_melanoma)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc296bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_all_melanoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_using_manual_labels(xtrain,\n",
    "                             xtest,\n",
    "                             ytrain,\n",
    "                             ytest, \n",
    "                             alpha=0.001):\n",
    "\n",
    "    clf_manual_labels = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)\n",
    "    clf_manual_labels.fit(xtrain, ytrain)\n",
    "    y_pred = clf_manual_labels.predict(xtest)\n",
    "    auc = roc_auc_score(ytest, clf_manual_labels.predict_proba(xtest)[:, 1])\n",
    "    #print(f\"AUC on test set:{auc}\")\n",
    "    return auc, clf_manual_labels, clf_manual_labels.predict_proba(xtest)[:, 1]\n",
    "    # accuracy_scores_f17k_test_set.append(auc)\n",
    "\n",
    "\n",
    "#auc, clf_manual_labels = train_using_manual_labels(test_dataloader_skincon, skincon_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(image_features, text_features_dict):\n",
    "    image_features_norm = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "    similarity_dict = {}\n",
    "    for key, text_features in text_features_dict.items():\n",
    "\n",
    "        text_features_norm = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "        similarity = image_features_norm.float() @ text_features_norm.T.float()\n",
    "\n",
    "        if similarity.shape[1] > 1:\n",
    "            similarity_per_prompt = similarity.softmax(\n",
    "                dim=0\n",
    "            )  # (batch_size, num_prompts) -> (batch_size, num_prompts)\n",
    "            similarity_ensemble = similarity_per_prompt.mean(\n",
    "                dim=1\n",
    "            ).numpy()  # (batch_size, num_prompts) -> (batch_size)\n",
    "        else:\n",
    "            # (batch_size, 1)\n",
    "            similarity_ensemble = similarity[:, 0].numpy()\n",
    "\n",
    "        assert len(similarity_ensemble.shape) == 1\n",
    "\n",
    "        similarity_dict[key] = similarity_ensemble\n",
    "\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53230681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def tune_best_temp_for_concepts(model, image_features, y, concept_list, train_idx, test_idx, alpha=0.001):\n",
    "    image_features_all_norm = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "    x_dict = OrderedDict()\n",
    "\n",
    "    for j, concept in enumerate(concept_list):\n",
    "        similarity_list = []\n",
    "        for concept_value in concept_dict[concept]:\n",
    "            prompt = f\"This is photo of {concept_value}\"\n",
    "            # print(prompt)\n",
    "            with torch.no_grad():\n",
    "                output = model.model_step_with_text(\n",
    "                    {\"text\": clip.tokenize(prompt).to(model_device)}\n",
    "                )\n",
    "                similarity_train = get_similarity_score(\n",
    "                    image_features=image_features_all_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "                #print(similarity_train)\n",
    "\n",
    "            similarity_list.append(similarity_train)\n",
    "        similarity_list = np.array(similarity_list)\n",
    "\n",
    "        similarity_list = similarity_list.T\n",
    "\n",
    "        x_dict[concept] = similarity_list\n",
    "        # x[:,j]=sim_prob_list[:,0]\n",
    "        \n",
    "    best_temp_dict = {}\n",
    "    \n",
    "#     for concept in concept_list:\n",
    "    best_auc = 0\n",
    "    best_temperature = None\n",
    "    best_clf = None\n",
    "    for temperature in [5, 2, 1, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]:\n",
    "\n",
    "        x_softmax = np.array(\n",
    "                [softmax(x_dict[concept] / temperature, axis=1)[:, 0] for concept in x_dict.keys()]\n",
    "        ).T\n",
    "            \n",
    "        clf = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)  # , eta0=1e-1)\n",
    "        \n",
    "        xtrain=x_softmax[train_idx]\n",
    "        xtest=x_softmax[test_idx]\n",
    "        \n",
    "        ytrain=np.array(y)[train_idx]\n",
    "        ytest=np.array(y)[test_idx]\n",
    "        \n",
    "        clf.fit(xtrain, ytrain)\n",
    "\n",
    "        auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:, 1])\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_temperature = temperature\n",
    "            best_clf = clf\n",
    "        #print(temperature, auc)\n",
    "        #print(f\"Concept:{concept}: Best auc={best_auc:.3f}: Temp={best_temperature:.3f}\")\n",
    "    \n",
    "        best_temp_dict[concept] = best_temperature\n",
    "    return best_auc, best_temperature, best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_best_temp_softmax(model, image_features_train, image_features_test, ytrain, ytest, concept_list, temp, num_ref_concepts=5, use_template_as_reference=True, alpha=0.001):\n",
    "    image_features_train_norm = image_features_train / image_features_train.norm(dim=1, keepdim=True)\n",
    "    image_features_test_norm = image_features_test / image_features_test.norm(dim=1, keepdim=True)\n",
    "#     print(concept_list)\n",
    "\n",
    "    x_dict_train = {}\n",
    "    x_dict_test = {}\n",
    "\n",
    "\n",
    "    for j, concept in enumerate(concept_list):\n",
    "        similarity_list_train = []\n",
    "        similarity_list_test = []\n",
    "        \n",
    "        if use_template_as_reference:\n",
    "            concept_sampled=concept_dict[concept][:1]+np.random.choice(a=concept_dict[concept][1:], size=min(num_ref_concepts, len(concept_dict[concept][1:])), replace=False).tolist()\n",
    "            prompt_list=[f\"This is photo of {concept_value}\" for concept_value in concept_sampled]\n",
    "        else:\n",
    "            prompt_list=[f\"This is photo of {concept_dict[concept][0]}\", f\"This is photo\"]\n",
    "            \n",
    "        for prompt in prompt_list:\n",
    "            with torch.no_grad():\n",
    "                output = model.model_step_with_text(\n",
    "                    {\"text\": clip.tokenize(prompt).to(model_device)}\n",
    "                )\n",
    "                similarity_train = get_similarity_score(\n",
    "                    image_features=image_features_train_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "                similarity_test = get_similarity_score(\n",
    "                    image_features=image_features_test_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "            similarity_list_train.append(similarity_train)\n",
    "            similarity_list_test.append(similarity_test)\n",
    "\n",
    "            \n",
    "            \n",
    "        similarity_list_train = np.array(similarity_list_train).T\n",
    "        similarity_list_test = np.array(similarity_list_test).T\n",
    "\n",
    "\n",
    "#         similarity_list = similarity_list.T\n",
    "#         x_dict[concept] = np.array([similarity_list[:, 0], np.mean(similarity_list[:, 1:], axis=1)]).T\n",
    "        x_dict_train[concept] = similarity_list_train\n",
    "        x_dict_test[concept] = similarity_list_test\n",
    "#         print(x_dict[concept].shape)\n",
    "        # x[:,j]=sim_prob_list[:,0]\n",
    "    #print([(x_dict_train[concept] / 0.02)[:, :] for concept in x_dict_train.keys()])\n",
    "    if num_ref_concepts>0:\n",
    "        x_softmax_train = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T\n",
    "\n",
    "        x_softmax_test = np.array(\n",
    "            [softmax(x_dict_test[concept] / temp, axis=1)[:, 0] for concept in x_dict_test.keys()]\n",
    "        ).T\n",
    "    else:\n",
    "        #print('ehere')\n",
    "        x_softmax_train = np.array(\n",
    "            [(x_dict_train[concept]/temp )[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T\n",
    "\n",
    "        x_softmax_test = np.array(\n",
    "            [(x_dict_test[concept]/temp )[:, 0] for concept in x_dict_test.keys()]\n",
    "        ).T        \n",
    "        \n",
    "\n",
    "#     xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "#         x_softmax, y, random_state=8, test_size=0.2, shuffle=True\n",
    "#     )\n",
    "\n",
    "    clf = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)  # , eta0=1e-1)\n",
    "    clf.fit(x_softmax_train, ytrain)\n",
    "\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(x_softmax_test)[:, 1])\n",
    "    return clf, auc, clf.predict_proba(x_softmax_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_with_best_temp_softmax(model, image_features_train, image_features_test, ytrain, ytest, concept_list, temp, num_ref_concepts=5, use_template_as_reference=True, alpha=0.001):\n",
    "    image_features_train_norm = image_features_train / image_features_train.norm(dim=1, keepdim=True)\n",
    "    image_features_test_norm = image_features_test / image_features_test.norm(dim=1, keepdim=True)\n",
    "#     print(concept_list)\n",
    "\n",
    "    x_dict_train = {}\n",
    "    x_dict_test = {}\n",
    "\n",
    "\n",
    "    for j, concept in enumerate(concept_list):\n",
    "        similarity_list_train = []\n",
    "        similarity_list_test = []\n",
    "        \n",
    "        if use_template_as_reference:\n",
    "            concept_sampled=concept_dict[concept][:1]+np.random.choice(a=concept_dict[concept][1:], size=min(num_ref_concepts, len(concept_dict[concept][1:])), replace=False).tolist()\n",
    "            prompt_list=[f\"This is photo of {concept_value}\" for concept_value in concept_sampled]\n",
    "        else:\n",
    "            prompt_list=[f\"This is photo of {concept_dict[concept][0]}\", f\"This is photo\"]\n",
    "            \n",
    "        for prompt in prompt_list:\n",
    "            print(\"prompt:\", prompt)\n",
    "            with torch.no_grad():\n",
    "                output = model.model_step_with_text(\n",
    "                    {\"text\": clip.tokenize(prompt).to(model_device)}\n",
    "                )\n",
    "                similarity_train = get_similarity_score(\n",
    "                    image_features=image_features_train_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "                similarity_test = get_similarity_score(\n",
    "                    image_features=image_features_test_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "            similarity_list_train.append(similarity_train)\n",
    "            similarity_list_test.append(similarity_test)\n",
    "\n",
    "            \n",
    "            \n",
    "        similarity_list_train = np.array(similarity_list_train).T\n",
    "        similarity_list_test = np.array(similarity_list_test).T\n",
    "\n",
    "\n",
    "#         similarity_list = similarity_list.T\n",
    "#         x_dict[concept] = np.array([similarity_list[:, 0], np.mean(similarity_list[:, 1:], axis=1)]).T\n",
    "        x_dict_train[concept] = similarity_list_train\n",
    "        x_dict_test[concept] = similarity_list_test\n",
    "#         print(x_dict[concept].shape)\n",
    "        # x[:,j]=sim_prob_list[:,0]\n",
    "    #print([(x_dict_train[concept] / 0.02)[:, :] for concept in x_dict_train.keys()])\n",
    "    \n",
    "    x_softmax_train = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    \n",
    "    x_softmax_test = np.array(\n",
    "        [softmax(x_dict_test[concept] / temp, axis=1)[:, 0] for concept in x_dict_test.keys()]\n",
    "    ).T    \n",
    "    clf = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)  # , eta0=1e-1)\n",
    "    clf.fit(x_softmax_train, ytrain)\n",
    "    \n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf.predict_proba(x_softmax_test)[:, 1])        \n",
    "    print(list(zip(concept_list,clf.coef_[0,:])), clf.intercept_)\n",
    "    print(auc)    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    clf_to1 = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)  # , eta0=1e-1)\n",
    "    clf_to1.fit(x_softmax_train/x_softmax_train.max(axis=0, keepdims=True), ytrain)\n",
    "    \n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf_to1.predict_proba(x_softmax_test/x_softmax_train.max(axis=0, keepdims=True))[:, 1])        \n",
    "    print(list(zip(concept_list,clf_to1.coef_[0,:])), clf_to1.intercept_)\n",
    "    print(auc)   \n",
    "    \n",
    "    \n",
    "    clf_std = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=alpha)  # , eta0=1e-1)\n",
    "    clf_std.fit(x_softmax_train/x_softmax_train.std(axis=0, keepdims=True), ytrain)\n",
    "    \n",
    "    print((x_softmax_train/x_softmax_train.std(axis=0, keepdims=True)).max(axis=0))\n",
    "\n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf_std.predict_proba(x_softmax_test/x_softmax_train.std(axis=0, keepdims=True))[:, 1])        \n",
    "    \n",
    "    print(list(zip(concept_list,clf_std.coef_[0,:])), clf_std.intercept_)\n",
    "    print(auc)       \n",
    "          \n",
    "    \n",
    "    x_softmax_train_temp = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T    \n",
    "    \n",
    "    x_softmax_train_notemp = np.array(\n",
    "            [softmax(x_dict_train[concept] / 1, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T \n",
    "    \n",
    "    x_softmax_train_max1 = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    x_softmax_train_max1=x_softmax_train_max1/x_softmax_train_max1.max(axis=0, keepdims=True)\n",
    "    \n",
    "    x_softmax_train_std = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    x_softmax_train_std=x_softmax_train_std/x_softmax_train_std.std(axis=0, keepdims=True)    \n",
    "    \n",
    "    x_nosoftmax_train = np.array(\n",
    "            [(x_dict_train[concept][:,0]) for concept in x_dict_train.keys()]\n",
    "        ).T            \n",
    "    \n",
    "    for j, concept in enumerate(concept_list):\n",
    "        fig=plt.figure(figsize=(16,3))\n",
    "        axes=fig.subplots(1,5)\n",
    "\n",
    "        axes[0].hist(x_nosoftmax_train[:,j])\n",
    "        axes[0].set_title(f\"Original (cosine sim)\\nmean: {x_nosoftmax_train[:,j].mean():.4f} std: {x_nosoftmax_train[:,j].std():.4f}\")\n",
    "        axes[1].hist(x_softmax_train_notemp[:,j])\n",
    "        axes[1].set_title(f\"softmax (temp=1)\\nmean: {x_softmax_train_notemp[:,j].mean():.4f} std: {x_softmax_train_notemp[:,j].std():.4f}\")\n",
    "        axes[2].hist(x_softmax_train_temp[:,j])\n",
    "        axes[2].set_title(f\"softmax (temp=0.02)\\nmean: {x_softmax_train_temp[:,j].mean():.4f} std: {x_softmax_train_temp[:,j].std():.4f}\")\n",
    "        \n",
    "        axes[3].hist(x_softmax_train_max1[:,j])\n",
    "        axes[3].set_title(f\"softmax and max to 1\\nmean: {x_softmax_train_max1[:,j].mean():.4f} std: {x_softmax_train_max1[:,j].std():.4f}\")        \n",
    "        \n",
    "        axes[4].hist(x_softmax_train_std[:,j])\n",
    "        axes[4].set_title(f\"softmax and divide by std\\nmean: {x_softmax_train_std[:,j].mean():.4f} std: {x_softmax_train_std[:,j].std():.4f}\")                \n",
    "        \n",
    "        \n",
    "        fig.suptitle(concept, y=1.1)\n",
    "        \n",
    "    return clf, clf_to1, clf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_with_best_temp_softmax_(model, image_features_train, image_features_test, ytrain, ytest, concept_list, temp, num_ref_concepts=5, use_template_as_reference=True):\n",
    "    image_features_train_norm = image_features_train / image_features_train.norm(dim=1, keepdim=True)\n",
    "    image_features_test_norm = image_features_test / image_features_test.norm(dim=1, keepdim=True)\n",
    "#     print(concept_list)\n",
    "\n",
    "    x_dict_train = {}\n",
    "    x_dict_test = {}\n",
    "\n",
    "\n",
    "    for j, concept in enumerate(concept_list):\n",
    "        similarity_list_train = []\n",
    "        similarity_list_test = []\n",
    "\n",
    "        concept_sampled=concept_dict[concept][:1]+np.random.choice(a=concept_dict[concept][1:], size=min(num_ref_concepts, len(concept_dict[concept][1:])), replace=False).tolist()\n",
    "        prompt_list=[f\"This is photo of {concept_value}\" for concept_value in concept_sampled]        \n",
    "        \n",
    "\n",
    "        print(\"prompt:\", prompt_list)\n",
    "        with torch.no_grad():\n",
    "            output = model.model_step_with_text(\n",
    "                {\"text\": clip.tokenize(prompt_list).to(model_device)}\n",
    "            )\n",
    "        for features in [output[\"text_features\"][0:1], output[\"text_features\"][1:].mean(axis=0, keepdims=True)]:            \n",
    "            similarity_train = get_similarity_score(\n",
    "                image_features=image_features_train_norm,\n",
    "                text_features_dict={0: features.detach().cpu()},\n",
    "            )[0]\n",
    "\n",
    "            similarity_test = get_similarity_score(\n",
    "                image_features=image_features_test_norm,\n",
    "                text_features_dict={0: features.detach().cpu()},\n",
    "            )[0]\n",
    "            \n",
    "            similarity_list_train.append(similarity_train)\n",
    "            similarity_list_test.append(similarity_test)            \n",
    "            \n",
    "        similarity_list_train = np.array(similarity_list_train).T\n",
    "        similarity_list_test = np.array(similarity_list_test).T\n",
    "\n",
    "#         similarity_list = similarity_list.T\n",
    "#         x_dict[concept] = np.array([similarity_list[:, 0], np.mean(similarity_list[:, 1:], axis=1)]).T\n",
    "        x_dict_train[concept] = similarity_list_train\n",
    "        x_dict_test[concept] = similarity_list_test\n",
    "#         print(x_dict[concept].shape)\n",
    "        # x[:,j]=sim_prob_list[:,0]\n",
    "    #print([(x_dict_train[concept] / 0.02)[:, :] for concept in x_dict_train.keys()])\n",
    "    \n",
    "    x_softmax_train = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    \n",
    "    x_softmax_test = np.array(\n",
    "        [softmax(x_dict_test[concept] / temp, axis=1)[:, 0] for concept in x_dict_test.keys()]\n",
    "    ).T    \n",
    "    clf = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=0.001)  # , eta0=1e-1)\n",
    "    clf.fit(x_softmax_train, ytrain)\n",
    "    \n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf.predict_proba(x_softmax_test)[:, 1])        \n",
    "    print(list(zip(concept_list,clf.coef_[0,:])), clf.intercept_)\n",
    "    print(auc)    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    clf_to1 = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=0.001)  # , eta0=1e-1)\n",
    "    clf_to1.fit(x_softmax_train/x_softmax_train.max(axis=0, keepdims=True), ytrain)\n",
    "    \n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf_to1.predict_proba(x_softmax_test/x_softmax_train.max(axis=0, keepdims=True))[:, 1])        \n",
    "    print(list(zip(concept_list,clf_to1.coef_[0,:])), clf_to1.intercept_)\n",
    "    print(auc)   \n",
    "    \n",
    "    \n",
    "    clf_std = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=0.001)  # , eta0=1e-1)\n",
    "    clf_std.fit(x_softmax_train/x_softmax_train.std(axis=0, keepdims=True), ytrain)\n",
    "    \n",
    "    print((x_softmax_train/x_softmax_train.std(axis=0, keepdims=True)).max(axis=0))\n",
    "\n",
    "    auc = roc_auc_score(ytest, \n",
    "                        clf_std.predict_proba(x_softmax_test/x_softmax_train.std(axis=0, keepdims=True))[:, 1])        \n",
    "    \n",
    "    print(list(zip(concept_list,clf_std.coef_[0,:])), clf_std.intercept_)\n",
    "    print(auc)       \n",
    "          \n",
    "    \n",
    "    x_softmax_train_temp = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T    \n",
    "    \n",
    "    x_softmax_train_notemp = np.array(\n",
    "            [softmax(x_dict_train[concept] / 1, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T \n",
    "    \n",
    "    x_softmax_train_max1 = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    x_softmax_train_max1=x_softmax_train_max1/x_softmax_train_max1.max(axis=0, keepdims=True)\n",
    "    \n",
    "    x_softmax_train_std = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T     \n",
    "    x_softmax_train_std=x_softmax_train_std/x_softmax_train_std.std(axis=0, keepdims=True)    \n",
    "    \n",
    "    x_nosoftmax_train = np.array(\n",
    "            [(x_dict_train[concept][:,0]) for concept in x_dict_train.keys()]\n",
    "        ).T            \n",
    "    \n",
    "    for j, concept in enumerate(concept_list):\n",
    "        fig=plt.figure(figsize=(16,3))\n",
    "        axes=fig.subplots(1,5)\n",
    "\n",
    "        axes[0].hist(x_nosoftmax_train[:,j])\n",
    "        axes[0].set_title(f\"Original (cosine sim)\\nmean: {x_nosoftmax_train[:,j].mean():.4f} std: {x_nosoftmax_train[:,j].std():.4f}\")\n",
    "        axes[1].hist(x_softmax_train_notemp[:,j])\n",
    "        axes[1].set_title(f\"softmax (temp=1)\\nmean: {x_softmax_train_notemp[:,j].mean():.4f} std: {x_softmax_train_notemp[:,j].std():.4f}\")\n",
    "        axes[2].hist(x_softmax_train_temp[:,j])\n",
    "        axes[2].set_title(f\"softmax (temp=0.02)\\nmean: {x_softmax_train_temp[:,j].mean():.4f} std: {x_softmax_train_temp[:,j].std():.4f}\")\n",
    "        \n",
    "        axes[3].hist(x_softmax_train_max1[:,j])\n",
    "        axes[3].set_title(f\"softmax and max to 1\\nmean: {x_softmax_train_max1[:,j].mean():.4f} std: {x_softmax_train_max1[:,j].std():.4f}\")        \n",
    "        \n",
    "        axes[4].hist(x_softmax_train_std[:,j])\n",
    "        axes[4].set_title(f\"softmax and divide by std\\nmean: {x_softmax_train_std[:,j].mean():.4f} std: {x_softmax_train_std[:,j].std():.4f}\")                \n",
    "        \n",
    "        \n",
    "        fig.suptitle(concept, y=1.1)\n",
    "        \n",
    "    return clf, clf_to1, clf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdb28f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_train_with_best_temp_softmax(model=model_select,\n",
    "                                 image_features_train=image_select_train,                           \n",
    "                                 image_features_test=image_select_test, \n",
    "                                 ytrain=y_select_train, \n",
    "                                 ytest=y_select_test,\n",
    "                                 concept_list=concept_list_target, \n",
    "                                 temp=0.02,\n",
    "                                 num_ref_concepts=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ed597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_train_with_best_temp_softmax(model=model_select,\n",
    "                                 image_features_train=image_select_train,                           \n",
    "                                 image_features_test=image_select_test, \n",
    "                                 ytrain=y_select_train, \n",
    "                                 ytest=y_select_test,\n",
    "                                 concept_list=concept_list_target, \n",
    "                                 temp=0.01,\n",
    "                                 num_ref_concepts=100, alpha=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23b99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54a6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024cc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e504dff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf, clf_to1, clf_std=return_train_with_best_temp_softmax_(model=model_select,\n",
    "                                 image_features_train=image_select_train,                           \n",
    "                                 image_features_test=image_select_test, \n",
    "                                 ytrain=y_select_train, \n",
    "                                 ytest=y_select_test,\n",
    "                                 concept_list=concept_list_target, \n",
    "                                 temp=0.02,\n",
    "                                 num_ref_concepts=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_skin=['clean', \"smooth\", 'Healthy', 'normal', 'soft', 'flat']\n",
    "concept_dict = {\n",
    "    \"Asymmetry\": [\"Asymmetry\", \"Symmetry\", \"Regular\", \"Uniform\"],\n",
    "    \"Irregular\": [\"Irregular\", \"Regular\", \"Smooth\"],\n",
    "    \"Black\": [\"Black\", \"White\", \"Creamy\", \"Colorless\", \"Unpigmented\"],\n",
    "    \"Blue\": [\"Blue\", \"Green\", \"Red\"],\n",
    "    \"White\": [\"White\", \"Black\", \"Colored\", \"Pigmented\"],\n",
    "    \"Brown\": [\"Brown\", \"Pale\", \"White\"],\n",
    "    \"Erosion\":[\"Erosion\", \"Deposition\", \"Buildup\"],\n",
    "    \"Multiple Colors\": [\"Multiple colors\", \"Single Color\", \"Unicolor\"],\n",
    "    \"Tiny\": [\"Tiny\", \"Large\", \"Big\"],\n",
    "    \"Regular\": [\"Regular\", \"Irregular\"],  \n",
    "}\n",
    "\n",
    "for key in concept_dict.keys():\n",
    "    print(f\"{key}: {concept_dict[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4add4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_dict_temp={}\n",
    "for concept_name in skincon_cols:    \n",
    "    prompt_dict, text_counter = concept_to_prompt(concept_name[8:])\n",
    "    prompt_engineered_list = []\n",
    "    for k, v in prompt_dict.items():\n",
    "        if k != \"original\":\n",
    "            prompt_engineered_list += v    \n",
    "    concept_term_list = list(set([prompt.replace(\"This is \", \"\").replace(\"This photo is \", \"\").replace(\"This lesion is \", \"\").replace(\"skin has become \", \"\").lower()\n",
    "                              for prompt in prompt_engineered_list]))    \n",
    "    \n",
    "    \n",
    "    if concept_name==\"skincon_Patch\":\n",
    "        negative_terms=[\"Spotted\"]    \n",
    "    elif concept_name == \"skincon_Exudate\":\n",
    "        negative_terms = [\"Absence\"]\n",
    "    elif concept_name == \"skincon_Xerosis\":\n",
    "        negative_terms = [\"Moisturized\"]\n",
    "    elif concept_name == \"skincon_Warty/Papillomatous\":\n",
    "        negative_terms = [\"Smooth\"]\n",
    "    elif concept_name == \"skincon_Dome-shaped\":\n",
    "        negative_terms = [\"Flat\"]\n",
    "    elif concept_name == \"skincon_Brown(Hyperpigmentation)\":\n",
    "        negative_terms = [\"Hypopigmentation\"]\n",
    "    elif concept_name == \"skincon_Translucent\":\n",
    "        negative_terms = [\"Opaque\"]\n",
    "    elif concept_name == \"skincon_White(Hypopigmentation)\":\n",
    "        negative_terms = [\"Hyperpigmentation\"]\n",
    "    elif concept_name == \"skincon_Purple\":\n",
    "        negative_terms = [\"Yellow\"]\n",
    "    elif concept_name == \"skincon_Yellow\":\n",
    "        negative_terms = [\"Purple\"]\n",
    "    elif concept_name == \"skincon_Black\":\n",
    "        negative_terms = [\"White\", \"Creamy\", \"Colorless\", \"Unpigmented\"]\n",
    "    elif concept_name == \"skincon_Lichenification\":\n",
    "        negative_terms = [\"Softening\"]\n",
    "    elif concept_name == \"skincon_Blue\":\n",
    "        negative_terms = [\"Orange\"]\n",
    "    elif concept_name == \"skincon_Gray\":\n",
    "        negative_terms = [\"Colorful\"]\n",
    "    else:\n",
    "        negative_terms = ['clean', 'smooth', 'Healthy', 'normal', 'soft', 'flat']\n",
    "        \n",
    "    concept_dict_temp[concept_name]=[concept_term_list[0]]+negative_terms\n",
    "concept_dict.update(concept_dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4710c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_list_curated=['Asymmetry', 'Irregular', 'Black', 'Blue', 'White', 'Brown', \n",
    "                      'Erosion',\n",
    "                      'Multiple Colors', 'Tiny', 'Regular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0281dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f17k_data_dir = \"/sdata/chanwkim/dermatology_datasets/fitzpatrick17k/final_image\"\n",
    "ddi_data_dir = \"/sdata/chanwkim/dermatology_datasets/ddi/final_image\"\n",
    "image_paths_f17k = [f17k_data_dir + \"/\" + image_id for image_id in list(metadata_all_f17k['index'])]\n",
    "image_paths_ddi = [ddi_data_dir + \"/\" + image_id for image_id in list(metadata_all_ddi['index'])]\n",
    "image_paths_all = image_paths_f17k + image_paths_ddi\n",
    "\n",
    "image_paths_f17k_filtered = [f17k_data_dir + \"/\" + image_id for image_id in list(metadata_all_f17k_filtered['index'])]\n",
    "image_paths_ddi_filtered = [ddi_data_dir + \"/\" + image_id for image_id in list(metadata_all_ddi_filtered['index'])]\n",
    "image_paths_all_filtered = image_paths_f17k_filtered + image_paths_ddi_filtered\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "norm_constants = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "image_path_dict_all=OrderedDict()\n",
    "for key, value in test_dataloader_ddi.dataset.image_path_dict.items():\n",
    "    image_path_dict_all[key]=value\n",
    "for key, value in test_dataloader_f17k_all.dataset.image_path_dict.items():\n",
    "    image_path_dict_all[key]=value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3324fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class ResNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths_list, labels):\n",
    "        assert len(image_paths_list)==len(labels)\n",
    "        self.image_paths_list = image_paths_list\n",
    "        self.transforms = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                convert_image_to_rgb,\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(*norm_constants),\n",
    "                            ])\n",
    "        self.labels = labels\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths_list[idx])\n",
    "#         print(image.size)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, output_dim, freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.resnet50(weights=\"ResNet50_Weights.IMAGENET1K_V1\")\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            if freeze_backbone:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "            # pass\n",
    "\n",
    "        head_in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.head = nn.Linear(head_in_features, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "def train_classifier(train_dataloader, val_dataloader, test_dataloader, freeze_backbone, lr, verbose):\n",
    "    classifier = Classifier(output_dim=1, freeze_backbone=freeze_backbone)\n",
    "    classifier_device = \"cuda:6\"\n",
    "    classifier.to(classifier_device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2, verbose=True)\n",
    "    early_stopper = EarlyStopper(patience=5, min_delta=0)\n",
    "\n",
    "    train_auroc = AUROC(task=\"binary\")\n",
    "    val_auroc = AUROC(task=\"binary\")\n",
    "    for epoch in range(50):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        classifier.train()\n",
    "        if verbose:\n",
    "            pbar=tqdm.tqdm(train_dataloader)\n",
    "        else:\n",
    "            pbar=train_dataloader\n",
    "        for batch in pbar:\n",
    "            image, label = batch[0].to(classifier_device), batch[1].to(classifier_device)\n",
    "            logits = classifier(image)\n",
    "            weight = torch.ones(label.shape[0], device=label.device)\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                input=logits[:, 0], target=(label == 1).float()\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            train_auroc.update(logits, (label == 1))\n",
    "\n",
    "        val_loss = 0\n",
    "        val_auc_best=0\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            if verbose:\n",
    "                pbar=tqdm.tqdm(val_dataloader)\n",
    "            else:\n",
    "                pbar=val_dataloader\n",
    "            for batch in pbar:\n",
    "                image, label = batch[0].to(classifier_device), batch[1].to(\n",
    "                    classifier_device\n",
    "                )\n",
    "                logits = classifier(image)\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    input=logits[:, 0], target=(label == 1).float()\n",
    "                )\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                val_auroc.update(logits, (label == 1))\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch}: Train loss: {train_loss/len(train_dataloader.dataset):.3f} AUROC: {train_auroc.compute():.3f} Val loss: {val_loss/len(val_dataloader.dataset):.3f} AUROC: {val_auroc.compute():.3f}\"\n",
    "            )\n",
    "        if val_auroc.compute() > val_auc_best:\n",
    "            val_auc_best = val_auroc.compute()        \n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            if verbose:\n",
    "                print(\"break\")\n",
    "            break\n",
    "        train_auroc.reset()\n",
    "        val_auroc.reset() \n",
    "        \n",
    "    test_auroc = AUROC(task=\"binary\")    \n",
    "    test_loss = 0\n",
    "    classifier.eval()\n",
    "    test_preds=[]\n",
    "    with torch.no_grad():\n",
    "        if verbose:\n",
    "            pbar=tqdm.tqdm(test_dataloader)\n",
    "        else:\n",
    "            pbar=test_dataloader        \n",
    "        for batch in pbar:\n",
    "            image, label = batch[0].to(classifier_device), batch[1].to(\n",
    "                classifier_device\n",
    "            )\n",
    "            logits = classifier(image)\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                input=logits[:, 0], target=(label == 1).float()\n",
    "            )\n",
    "            test_loss += loss.item() * image.size(0)\n",
    "            test_auroc.update(logits, (label == 1))\n",
    "            test_preds+=logits.detach().cpu().numpy().tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Test loss: {test_loss/len(test_dataloader.dataset):.3f} AUROC: {test_auroc.compute():.3f}\"\n",
    "        )   \n",
    "    \n",
    "    return classifier, test_auroc.compute(), test_preds\n",
    "\n",
    "def generate_data_and_train_resnet(metadata_select, y_select, train_idx, test_idx, freeze_backbone=False, lr=1e-3):  \n",
    "    train_idx_train, train_idx_valid=train_test_split(train_idx, random_state=random_seed, test_size=0.25, shuffle=True)\n",
    "    \n",
    "    train_dataset_resnet = ResNetDataset(image_paths_list=[image_path_dict_all[idx] for idx in metadata_select[\"index\"].iloc[train_idx_train]], \n",
    "                                         labels=np.array(y_select)[train_idx_train])\n",
    "    train_dataloader_resnet = torch.utils.data.DataLoader(\n",
    "            train_dataset_resnet, batch_size=32, shuffle=True, pin_memory=True,\n",
    "            drop_last=False, num_workers=4)\n",
    "\n",
    "    valid_dataset_resnet = ResNetDataset(image_paths_list=[image_path_dict_all[idx] for idx in metadata_select[\"index\"].iloc[train_idx_valid]], \n",
    "                                         labels=np.array(y_select)[train_idx_valid])\n",
    "    valid_dataloader_resnet = torch.utils.data.DataLoader(\n",
    "            valid_dataset_resnet, batch_size=32, shuffle=True, pin_memory=True,\n",
    "            drop_last=False, num_workers=4)\n",
    "\n",
    "    test_dataset_resnet = ResNetDataset(image_paths_list=[image_path_dict_all[idx] for idx in metadata_select[\"index\"].iloc[test_idx]], \n",
    "                                         labels=np.array(y_select)[test_idx])\n",
    "    test_dataloader_resnet = torch.utils.data.DataLoader(\n",
    "            test_dataset_resnet, batch_size=32, shuffle=False, pin_memory=True,\n",
    "            drop_last=False, num_workers=4)            \n",
    "    \n",
    "    classifier, auc_best, test_preds=train_classifier(train_dataloader_resnet, \n",
    "                                          valid_dataloader_resnet, \n",
    "                                          test_dataloader_resnet, freeze_backbone=freeze_backbone, lr=lr, verbose=False)\n",
    "    \n",
    "    return auc_best.item(), test_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zero_short(model, image_features_train, image_features_test, ytrain, ytest, temp, num_ref_concepts=5, use_template_as_reference=True):\n",
    "    image_features_train_norm = image_features_train / image_features_train.norm(dim=1, keepdim=True)\n",
    "    image_features_test_norm = image_features_test / image_features_test.norm(dim=1, keepdim=True)\n",
    "#     print(concept_list)\n",
    "\n",
    "    x_dict_train = {}\n",
    "    x_dict_test = {}\n",
    "\n",
    "\n",
    "    for j, concept in enumerate([\"melanoma\"]):\n",
    "        similarity_list_train = []\n",
    "        similarity_list_test = []\n",
    "        \n",
    "        prompt_list=[f\"This is photo of {concept}\", f\"This is photo\"]\n",
    "            \n",
    "        for prompt in prompt_list:\n",
    "            with torch.no_grad():\n",
    "                output = model.model_step_with_text(\n",
    "                    {\"text\": clip.tokenize(prompt).to(model_device)}\n",
    "                )\n",
    "                similarity_train = get_similarity_score(\n",
    "                    image_features=image_features_train_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "                similarity_test = get_similarity_score(\n",
    "                    image_features=image_features_test_norm,\n",
    "                    text_features_dict={0: output[\"text_features\"].detach().cpu()},\n",
    "                )[0]\n",
    "\n",
    "            similarity_list_train.append(similarity_train)\n",
    "            similarity_list_test.append(similarity_test)\n",
    "\n",
    "        \n",
    "        similarity_list_train = np.array(similarity_list_train).T\n",
    "        similarity_list_test = np.array(similarity_list_test).T\n",
    "\n",
    "\n",
    "#         similarity_list = similarity_list.T\n",
    "#         x_dict[concept] = np.array([similarity_list[:, 0], np.mean(similarity_list[:, 1:], axis=1)]).T\n",
    "        x_dict_train[concept] = similarity_list_train\n",
    "        x_dict_test[concept] = similarity_list_test\n",
    "#         print(x_dict[concept].shape)\n",
    "        # x[:,j]=sim_prob_list[:,0]\n",
    "    #print([(x_dict_train[concept] / 0.02)[:, :] for concept in x_dict_train.keys()])\n",
    "    print(x_dict_train.keys())\n",
    "    if num_ref_concepts>0:\n",
    "        x_softmax_train = np.array(\n",
    "            [softmax(x_dict_train[concept] / temp, axis=1)[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T\n",
    "\n",
    "        x_softmax_test = np.array(\n",
    "            [softmax(x_dict_test[concept] / temp, axis=1)[:, 0] for concept in x_dict_test.keys()]\n",
    "        ).T\n",
    "    else:\n",
    "        #print('ehere')\n",
    "        x_softmax_train = np.array(\n",
    "            [(x_dict_train[concept]/temp )[:, 0] for concept in x_dict_train.keys()]\n",
    "        ).T\n",
    "\n",
    "        x_softmax_test = np.array(\n",
    "            [(x_dict_test[concept]/temp )[:, 0] for concept in x_dict_test.keys()]\n",
    "        ).T        \n",
    "        \n",
    "\n",
    "\n",
    "#     xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "#         x_softmax, y, random_state=8, test_size=0.2, shuffle=True\n",
    "#     )\n",
    "\n",
    "    print(x_softmax_train.shape, x_softmax_test.shape, roc_auc_score(ytest, x_softmax_test[:,0]))\n",
    "    \n",
    "    clf = SGDClassifier(loss=\"log_loss\", penalty=\"l1\", alpha=0.001)  # , eta0=1e-1)\n",
    "    clf.fit(x_softmax_train, ytrain)\n",
    "\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(x_softmax_test)[:, 1])        \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d330d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skincon_cols.index(\"skincon_Ulcer\"), skincon_cols.index(\"skincon_Erosion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb856918",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_select_skincon_train[skincon_cols].values[:,9][y_select_train==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_select_skincon_train[skincon_cols].values[:,9][y_select_train==0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_select_skincon_train[skincon_cols].values[:,11][y_select_train==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ba9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_select_skincon_train[skincon_cols].values[:,11][y_select_train==0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.coef_[0], index=skincon_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aae9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skincon_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a115ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d68186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list_new=[]\n",
    "for record in record_all_list:\n",
    "    if \"alpha\" in record:\n",
    "        \n",
    "    else:\n",
    "        record_all_list_new.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72532baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "[record for record in record_all_list if \"alpha\" in record and record[\"alpha\"]==0.0001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554dba1d",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(y_melanoma)*0.8), int(len(y_malignancy)*0.8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a40639",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec2e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc372ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# record_all_list=[]\n",
    "for task in [\"melanoma\", \"malignancy\"]:\n",
    "# for task in [\"melanoma\"]:\n",
    "    #for is_clean in [\"clean_only\", \"all\"]:\n",
    "    for is_clean in [\"clean_only\"]:\n",
    "        if task==\"melanoma\" and is_clean==\"clean_only\":\n",
    "            metadata_select=metadata_all_melanoma[(metadata_all_melanoma[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            y_select=np.array(y_melanoma)[(metadata_all_melanoma[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_monet_select=image_features_all_melanoma[(metadata_all_melanoma[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_vanilla_select=image_features_all_melanoma_vanilla[(metadata_all_melanoma[\"skincon_Do not consider this image\"]!=1).values]\n",
    "        elif task==\"melanoma\" and is_clean==\"all\":\n",
    "            metadata_select=metadata_all_melanoma_all[(metadata_all_melanoma_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            y_select=np.array(y_melanoma_all)[(metadata_all_melanoma_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_monet_select=image_features_all_f17all_melanoma[(metadata_all_melanoma_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_vanilla_select=image_features_all_f17all_melanoma_vanilla[(metadata_all_melanoma_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "        elif task==\"malignancy\" and is_clean==\"clean_only\":\n",
    "            metadata_select=metadata_all_malignancy[(metadata_all_malignancy[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            y_select=np.array(y_malignancy)[(metadata_all_malignancy[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_monet_select=image_features_all_malignancy[(metadata_all_malignancy[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_vanilla_select=image_features_all_malignancy_vanilla[(metadata_all_malignancy[\"skincon_Do not consider this image\"]!=1).values]\n",
    "        elif task==\"malignancy\" and is_clean==\"all\":\n",
    "            metadata_select=metadata_all_malignancy_all[(metadata_all_malignancy_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            y_select=np.array(y_malignancy_all)[(metadata_all_malignancy_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_monet_select=image_features_all_f17all_malignancy[(metadata_all_malignancy_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "            image_vanilla_select=image_features_all_f17all_malignancy_vanilla[(metadata_all_malignancy_all[\"skincon_Do not consider this image\"]!=1).values]\n",
    "        else:\n",
    "            raise NotImplementedError(task, is_clean)        \n",
    "#         if task==\"melanoma\" and is_clean==\"clean_only\":\n",
    "#             y_select=y_melanoma\n",
    "#             metadata_select=metadata_all_melanoma\n",
    "#             image_monet_select=image_features_all_melanoma\n",
    "#             image_vanilla_select=image_features_all_melanoma_vanilla\n",
    "#         elif task==\"melanoma\" and is_clean==\"all\":\n",
    "#             y_select=y_melanoma_all\n",
    "#             metadata_select=metadata_all_melanoma_all            \n",
    "#             image_monet_select=image_features_all_f17all_melanoma\n",
    "#             image_vanilla_select=image_features_all_f17all_melanoma_vanilla            \n",
    "#         elif task==\"malignancy\" and is_clean==\"clean_only\":\n",
    "#             y_select=y_malignancy              \n",
    "#             metadata_select=metadata_all_malignancy\n",
    "#             image_monet_select=image_features_all_malignancy\n",
    "#             image_vanilla_select=image_features_all_malignancy_vanilla            \n",
    "#         elif task==\"malignancy\" and is_clean==\"all\":\n",
    "#             y_select=y_malignancy_all\n",
    "#             metadata_select=metadata_all_malignancy_all            \n",
    "#             image_monet_select=image_features_all_f17all_malignancy\n",
    "#             image_vanilla_select=image_features_all_f17all_malignancy_vanilla            \n",
    "#         else:\n",
    "#             raise NotImplementedError(task, is_clean)\n",
    "            \n",
    "        assert len(y_select)==len(metadata_select)==len(image_monet_select)==len(image_vanilla_select)\n",
    "        \n",
    "        for random_seed in tqdm.tqdm(range(1,20)):\n",
    "            train_idx, test_idx = train_test_split(np.arange(len(y_select)), random_state=random_seed, test_size=0.2, shuffle=True)\n",
    "\n",
    "            #print(task, is_clean, len(y_select), len(metadata_select), len(train_idx), len(test_idx))\n",
    "\n",
    "#             for method in [\"skincon_manual\"]:\n",
    "            for method in [\"skincon_manual\", \"automatic\", \"resnet\", \"resnet_freeze_backbone\"]:\n",
    "                if method==\"skincon_manual\":\n",
    "                    for test_mode in [\"full\", \"less_concept\", \"less_sample\"]:\n",
    "                        if test_mode==\"full\":\n",
    "                            #for alpha in [0.001, 0.0001]:\n",
    "                            for alpha in [0.001]:\n",
    "                                metadata_select_train=metadata_select[skincon_cols].iloc[train_idx]\n",
    "                                metadata_select_skincon_train=metadata_select_train[~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                metadata_select_test=metadata_select[skincon_cols].iloc[test_idx]\n",
    "                                metadata_select_skincon_test=metadata_select_test[~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                y_select_train=np.array(y_select)[train_idx][~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                y_select_test=np.array(y_select)[test_idx][~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                auc,_,y_test_pred=train_using_manual_labels(xtrain=metadata_select_skincon_train[skincon_cols].values,\n",
    "                                                          xtest=metadata_select_skincon_test[skincon_cols].values,\n",
    "                                                          ytrain=y_select_train,\n",
    "                                                          ytest=y_select_test,\n",
    "                                                                alpha=alpha,\n",
    "                                                         )\n",
    "\n",
    "                                print(task, is_clean, len(y_select), random_seed, method, test_mode, alpha, f\"{auc:.3f}\")\n",
    "                                record_all_list.append({\"task\": task,\n",
    "                                                        \"is_clean\": is_clean,\n",
    "                                                        \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                        \"num_sample_train\": len(y_select_train),\n",
    "                                                        \"num_sample_test\": len(y_select_test),\n",
    "                                                        \"random_seed\": random_seed,                                            \n",
    "                                                        \"method\": method+\"_\"+test_mode,\n",
    "                                                        \"auc\":auc,\n",
    "                                                        \"y_test\":y_select_test,\n",
    "                                                        \"y_test_pred\":y_test_pred,\n",
    "                                                        \"alpha\": alpha,\n",
    "                                                       })\n",
    "                            \n",
    "                        elif test_mode==\"less_concept\":\n",
    "                            for num_concept in [1]+list(range(5, len(skincon_cols), 5))+[len(skincon_cols)]:\n",
    "                                skincon_cols_select=np.random.choice(skincon_cols, \n",
    "                                                                     size=num_concept, \n",
    "                                                                     replace=False, p=None).tolist()                      \n",
    "                            \n",
    "                                metadata_select_train=metadata_select[skincon_cols].iloc[train_idx]\n",
    "                                metadata_select_skincon_train=metadata_select_train[~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                metadata_select_test=metadata_select[skincon_cols].iloc[test_idx]\n",
    "                                metadata_select_skincon_test=metadata_select_test[~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                y_select_train=np.array(y_select)[train_idx][~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                y_select_test=np.array(y_select)[test_idx][~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                auc,_,y_test_pred=train_using_manual_labels(xtrain=metadata_select_skincon_train[skincon_cols_select].values,\n",
    "                                                          xtest=metadata_select_skincon_test[skincon_cols_select].values,\n",
    "                                                          ytrain=y_select_train,\n",
    "                                                          ytest=y_select_test \n",
    "                                                         )\n",
    "                                print(task, is_clean, len(y_select), random_seed, method, test_mode, num_concept, f\"{auc:.3f}\")\n",
    "                                \n",
    "                                record_all_list.append({\"task\": task,\n",
    "                                                        \"is_clean\": is_clean,\n",
    "                                                        \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                        \"num_sample_train\": len(y_select_train),\n",
    "                                                        \"num_sample_test\": len(y_select_test),\n",
    "                                                        \"random_seed\": random_seed,                                            \n",
    "                                                        \"method\": method+\"_\"+test_mode,\n",
    "                                                        \"num_concept\": num_concept,\n",
    "                                                        \"auc\":auc,\n",
    "                                                        \"y_test\":y_select_test,\n",
    "                                                        \"y_test_pred\":y_test_pred,                                                        \n",
    "                                                       })\n",
    "                        elif test_mode==\"less_sample\":\n",
    "                            if len(train_idx)>600 and len(train_idx)<700:\n",
    "                                num_sample_train_select_range=[100, 200, 300, 400, 500, 600, len(train_idx)]\n",
    "                            elif len(train_idx)>3900 and len(train_idx)<4000:\n",
    "                                num_sample_train_select_range=[100, 500, 1000, 1500, 2000, 2500, 3000, 3500, len(train_idx)]\n",
    "                            else:\n",
    "                                raise\n",
    "                            for num_sample_train_select in num_sample_train_select_range:\n",
    "                                train_idx_select=np.random.choice(train_idx, size=num_sample_train_select, replace=False)                                                                    \n",
    "                                \n",
    "                                metadata_select_train=metadata_select[skincon_cols].iloc[train_idx_select]\n",
    "                                metadata_select_skincon_train=metadata_select_train[~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                metadata_select_test=metadata_select[skincon_cols].iloc[test_idx]\n",
    "                                metadata_select_skincon_test=metadata_select_test[~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                y_select_train=np.array(y_select)[train_idx_select][~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                y_select_test=np.array(y_select)[test_idx][~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n",
    "\n",
    "                                auc,_,y_test_pred=train_using_manual_labels(xtrain=metadata_select_skincon_train[skincon_cols].values,\n",
    "                                                          xtest=metadata_select_skincon_test[skincon_cols].values,\n",
    "                                                          ytrain=y_select_train,\n",
    "                                                          ytest=y_select_test \n",
    "                                                         )\n",
    "\n",
    "                                print(task, is_clean, len(y_select), random_seed, method, test_mode, num_sample_train_select, f\"{auc:.3f}\")\n",
    "                                record_all_list.append({\"task\": task,\n",
    "                                                        \"is_clean\": is_clean,\n",
    "                                                        \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                        \"num_sample_train\": len(y_select_train),\n",
    "                                                        \"num_sample_test\": len(y_select_test),\n",
    "                                                        \"random_seed\": random_seed,                                            \n",
    "                                                        \"method\": method+\"_\"+test_mode,\n",
    "                                                        \"num_sample_train_select\": num_sample_train_select,\n",
    "                                                        \"auc\":auc,\n",
    "                                                        \"y_test\":y_select_test,\n",
    "                                                        \"y_test_pred\":y_test_pred,                                                        \n",
    "                                                       })\n",
    "                                \n",
    "                                \n",
    "                    \n",
    "                elif method==\"resnet_freeze_backbone\":\n",
    "                    auc, y_test_pred=generate_data_and_train_resnet(metadata_select=metadata_select, \n",
    "                                                       y_select=y_select, \n",
    "                                                       train_idx=train_idx, \n",
    "                                                       test_idx=test_idx, \n",
    "                                                       freeze_backbone=True)\n",
    "                    \n",
    "                    print(task, is_clean, len(y_select), random_seed, method, f\"{auc:.3f}\")\n",
    "                    record_all_list.append({\"task\": task,\n",
    "                                            \"is_clean\": is_clean,\n",
    "                                            \"num_sample\": len(train_idx)+len(test_idx),\n",
    "                                            \"num_sample_train\": len(train_idx),\n",
    "                                            \"num_sample_test\": len(test_idx),                                            \n",
    "                                            \"random_seed\": random_seed,                                            \n",
    "                                            \"method\": method,\n",
    "                                            \"auc\":auc,\n",
    "                                            \"y_test\":np.array(y_select)[test_idx],\n",
    "                                            \"y_test_pred\":y_test_pred,                                              \n",
    "                                           })                     \n",
    "                    \n",
    "                elif method==\"resnet\":\n",
    "                    auc, y_test_pred=generate_data_and_train_resnet(metadata_select=metadata_select, \n",
    "                                                       y_select=y_select, \n",
    "                                                       train_idx=train_idx, \n",
    "                                                       test_idx=test_idx)\n",
    "                    \n",
    "                    print(task, is_clean, len(y_select), random_seed, method, f\"{auc:.3f}\")\n",
    "                    record_all_list.append({\"task\": task,\n",
    "                                            \"is_clean\": is_clean,\n",
    "                                            \"num_sample\": len(train_idx)+len(test_idx),\n",
    "                                            \"num_sample_train\": len(train_idx),\n",
    "                                            \"num_sample_test\": len(test_idx),                                            \n",
    "                                            \"random_seed\": random_seed,                                            \n",
    "                                            \"method\": method,\n",
    "                                            \"auc\":auc,\n",
    "                                            \"y_test\":np.array(y_select)[test_idx],\n",
    "                                            \"y_test_pred\":y_test_pred,                                             \n",
    "                                           }) \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                elif method==\"automatic\":\n",
    "                    for concept_list_type in [\"curated\", \"skincon\"]:\n",
    "                        if concept_list_type==\"curated\":\n",
    "                            concept_list_target=concept_list_curated\n",
    "                        elif concept_list_type==\"skincon\":\n",
    "                            concept_list_target=skincon_cols\n",
    "                        else:\n",
    "                            raise NotImplementedError                            \n",
    "                            \n",
    "                        for trained in [\"monet\", \"vanilla\"]:\n",
    "                            for test_mode in [\"full\", \"less_concept\", \"less_reference\", \"less_sample\"]:\n",
    "                                y_select_train=np.array(y_select)[train_idx]\n",
    "                                y_select_test=np.array(y_select)[test_idx]                         \n",
    "                                if trained==\"monet\":\n",
    "                                    image_select_train=image_monet_select[train_idx]\n",
    "                                    image_select_test=image_monet_select[test_idx]\n",
    "                                    model_select=model\n",
    "                                elif trained==\"vanilla\":\n",
    "                                    image_select_train=image_vanilla_select[train_idx]\n",
    "                                    image_select_test=image_vanilla_select[test_idx]\n",
    "                                    model_select=model_vanilla\n",
    "\n",
    "                                if test_mode==\"full\":\n",
    "                                    #for alpha in [0.001, 0.0001]:\n",
    "                                    for alpha in [0.001]:\n",
    "                                        #for temp in [0.02, 0.01, 0.005]:\n",
    "                                        for temp in [0.02]:\n",
    "                                            clf, auc, y_test_pred=train_with_best_temp_softmax(model=model_select,\n",
    "                                                                             image_features_train=image_select_train,                           \n",
    "                                                                             image_features_test=image_select_test, \n",
    "                                                                             ytrain=y_select_train, \n",
    "                                                                             ytest=y_select_test,\n",
    "                                                                             concept_list=concept_list_target, \n",
    "                                                                             temp=temp,\n",
    "                                                                             num_ref_concepts=100, alpha=alpha) \n",
    "                                            print(task, is_clean, len(y_select), random_seed, method, concept_list_type, trained, test_mode, alpha, temp, f\"{auc:.3f}\")\n",
    "                                            record_all_list.append({\"task\": task,\n",
    "                                                                    \"is_clean\": is_clean,\n",
    "                                                                    \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                                    \"num_sample_train\": len(y_select_train),\n",
    "                                                                    \"num_sample_test\": len(y_select_test),                                                        \n",
    "                                                                    \"random_seed\": random_seed,                                            \n",
    "                                                                    \"method\": method+\"_\"+concept_list_type+\"_\"+trained+\"_\"+test_mode,\n",
    "                                                                    \"auc\": auc,\n",
    "                                                                    \"y_test\":y_select_test,\n",
    "                                                                    \"y_test_pred\":y_test_pred,                                                                       \n",
    "                                                                    \"alpha\": alpha,\n",
    "                                                                    \"temp\": temp,\n",
    "                                                                    \"clf\":clf\n",
    "                                                                   })   \n",
    "\n",
    "\n",
    "\n",
    "                                elif test_mode==\"less_concept\":\n",
    "                                    if len(concept_list_target)>20:\n",
    "                                        num_concept_list=[1]+list(range(5, len(concept_list_target), 5))+[len(concept_list_target)]\n",
    "                                    else:\n",
    "                                        num_concept_list=list(range(1, len(concept_list_target)+1))\n",
    "                                    for num_concept in num_concept_list:\n",
    "                                        concept_list_target_select=np.random.choice(concept_list_target, \n",
    "                                                                                     size=num_concept, \n",
    "                                                                                     replace=False, p=None)\n",
    "\n",
    "                                        clf, auc, y_test_pred=train_with_best_temp_softmax(model=model_select,                                                    \n",
    "                                                                         image_features_train=image_select_train, \n",
    "                                                                         image_features_test=image_select_test, \n",
    "                                                                         ytrain=y_select_train, \n",
    "                                                                         ytest=y_select_test,\n",
    "                                                                         concept_list=concept_list_target_select, \n",
    "                                                                         temp=0.02,\n",
    "                                                                         num_ref_concepts=100) \n",
    "\n",
    "                                        print(task, is_clean, len(y_select), random_seed, method, concept_list_type, trained, test_mode, num_concept, f\"{auc:.3f}\")\n",
    "                                        record_all_list.append({\"task\": task,\n",
    "                                                                \"is_clean\": is_clean,\n",
    "                                                                \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                                \"num_sample_train\": len(y_select_train),\n",
    "                                                                \"num_sample_test\": len(y_select_test),                                                            \n",
    "                                                                \"random_seed\": random_seed,                                            \n",
    "                                                                \"method\": method+\"_\"+concept_list_type+\"_\"+trained+\"_\"+test_mode,\n",
    "                                                                \"num_concept\": num_concept,\n",
    "                                                                \"auc\":auc,\n",
    "                                                                    \"y_test\":y_select_test,\n",
    "                                                                    \"y_test_pred\":y_test_pred,                                                                  \n",
    "                                                               })  \n",
    "\n",
    "                                elif test_mode==\"less_reference\":\n",
    "                                    for num_ref_concepts in range(0, 5+1):\n",
    "                                        clf, auc, y_test_pred=train_with_best_temp_softmax(model=model_select,                       \n",
    "                                                                         image_features_train=image_select_train,                               \n",
    "                                                                         image_features_test=image_select_test, \n",
    "                                                                         ytrain=y_select_train, \n",
    "                                                                         ytest=y_select_test,\n",
    "                                                                         concept_list=concept_list_target, \n",
    "                                                                         temp=0.02,\n",
    "                                                                         num_ref_concepts=num_ref_concepts)\n",
    "                                        print(task, is_clean, len(y_select), random_seed, method, concept_list_type, trained, test_mode, num_ref_concepts, f\"{auc:.3f}\")\n",
    "                                        record_all_list.append({\"task\": task,\n",
    "                                                                \"is_clean\": is_clean,\n",
    "                                                                \"num_sample\": len(y_select_train)+len(y_select_test),\n",
    "                                                                \"num_sample_train\": len(y_select_train),\n",
    "                                                                \"num_sample_test\": len(y_select_test),                                                               \n",
    "                                                                \"random_seed\": random_seed,                                            \n",
    "                                                                \"method\": method+\"_\"+concept_list_type+\"_\"+trained+\"_\"+test_mode,\n",
    "                                                                \"num_ref_concepts\": num_ref_concepts,\n",
    "                                                                \"auc\":auc,\n",
    "                                                                    \"y_test\":y_select_test,\n",
    "                                                                    \"y_test_pred\":y_test_pred,                                                                  \n",
    "                                                               })         \n",
    "\n",
    "\n",
    "\n",
    "                                elif test_mode==\"less_sample\":\n",
    "                                    for sample_prop in [0.1, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "                                        sample_select=np.random.choice(np.arange(len(image_select_train)), size=int(len(image_select_train)*sample_prop), replace=False)                                    \n",
    "                                        clf, auc, y_test_pred=train_with_best_temp_softmax(model=model_select,                                                     \n",
    "                                                                         image_features_train=image_select_train[sample_select], \n",
    "                                                                         image_features_test=image_select_test, \n",
    "                                                                         ytrain=y_select_train[sample_select], \n",
    "                                                                         ytest=y_select_test,\n",
    "                                                                         concept_list=concept_list_target, \n",
    "                                                                         temp=0.02,\n",
    "                                                                         num_ref_concepts=100)                                    \n",
    "\n",
    "                                        print(task, is_clean, len(y_select), random_seed, method, concept_list_type, trained, test_mode, sample_prop, f\"{auc:.3f}\")\n",
    "                                        record_all_list.append({\"task\": task,\n",
    "                                                                \"is_clean\": is_clean,\n",
    "                                                                \"num_sample\": len(y_select_train[sample_select])+len(y_select_test),\n",
    "                                                                \"num_sample_train\": len(y_select_train[sample_select]),\n",
    "                                                                \"num_sample_test\": len(y_select_test),                                                               \n",
    "                                                                \"random_seed\": random_seed,                                            \n",
    "                                                                \"method\": method+\"_\"+concept_list_type+\"_\"+trained+\"_\"+test_mode,\n",
    "                                                                \"sample_prop\": sample_prop,\n",
    "                                                                \"auc\":auc,\n",
    "                                                                    \"y_test\":y_select_test,\n",
    "                                                                    \"y_test_pred\":y_test_pred,                                                                  \n",
    "                                                               })\n",
    "                                else:\n",
    "                                    raise NotImplementedError\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                #print(task, is_clean, len(y_select), random_seed, method, f\"{auc:.3f}\")\n",
    "                #print(y_select)\n",
    "            #print(method, train_using_manual_labels(xtrain= ))\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(record_all_list, f=log_dir/\"experiment_results\"/\"cbm_complete_valid_230607.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffeec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe81348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 50)\n",
    "x=pd.DataFrame(record_all_list)\n",
    "x[x[\"method\"]==\"skincon_manual_full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x[\"method\"]==\"automatic_skincon_monet_full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795413ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "775*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fae435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334465ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_malignancy)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b11993",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_melanoma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d7eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3f6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list_0513=torch.load(f=log_dir/\"experiment_results\"/\"cbm_complete_230513.pt\", \n",
    "                                map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list_0501=torch.load(f=log_dir/\"experiment_results\"/\"cbm_complete_230501.pt\", \n",
    "                                map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb1716",
   "metadata": {},
   "outputs": [],
   "source": [
    " cbm_complete_230501.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd94324",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(record_all_list_0513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746814ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "379+304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877949a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeede76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list_0501).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad19c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list).apply(lambda x: sklearn.metrics.roc_auc_score(x[\"y_test\"], x[\"y_test_pred\"]), \n",
    "                                    axis=1)\\\n",
    "-pd.DataFrame(record_all_list)['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "~metadata_select_test[\"skincon_Vesicle\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84162f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_roc_test(ground_truth, predictions_one, predictions_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ed2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(~metadata_all_melanoma[\"skincon_Cyst\"].isnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list[19][\"y_test_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list[-1][\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list_new=torch.load(f=log_dir/\"experiment_results\"/\"cbm_complete_230513.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list_new)[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diff=pd.DataFrame(record_all_list_new).groupby([\"task\", \"method\"]).apply(lambda x: x.sort_values(\"random_seed\")[\"auc\"].values)\\\n",
    ".loc[\"malignancy\", \"automatic_curated_monet_full\"]-\\\n",
    "pd.DataFrame(record_all_list_new).groupby([\"task\", \"method\"]).apply(lambda x: x.sort_values(\"random_seed\")[\"auc\"].values)\\\n",
    ".loc[\"malignancy\", \"resnet_freeze_backbone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff = np.mean(score_diff)\n",
    "\n",
    "numerator = avg_diff * np.sqrt(cv)\n",
    "denominator = np.sqrt(\n",
    "    sum([(diff - avg_diff) ** 2 for diff in score_diff]) / (cv - 1)\n",
    ")\n",
    "t_stat = numerator / denominator\n",
    "\n",
    "pvalue = scipy.stats.t.sf(np.abs(t_stat), cv - 1) * 2.0\n",
    "float(t_stat), float(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c7a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7913147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa068c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list[19][\"auc\"], record_all_list[42][\"auc\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b44a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(a=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff = np.mean(score_diff)\n",
    "\n",
    "numerator = avg_diff * np.sqrt(cv)\n",
    "denominator = np.sqrt(\n",
    "    sum([(diff - avg_diff) ** 2 for diff in score_diff]) / (cv - 1)\n",
    ")\n",
    "t_stat = numerator / denominator\n",
    "\n",
    "pvalue = stats.t.sf(np.abs(t_stat), cv - 1) * 2.0\n",
    "return float(t_stat), float(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d52f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe45cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b651fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delong_roc_test(ground_truth=record_all_list[-1][\"y_test\"], \n",
    "             predictions_one=record_all_list[19][\"y_test_pred\"], \n",
    "             predictions_two=np.array(record_all_list[42][\"y_test_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7f505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43635c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815d458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(record_all_list)#.apply(lambda x: x[\"y_test\"].sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11fb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a70cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(17*40)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6b429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                            for num_sample_train_select in num_sample_train_select_range:\n",
    "                                train_idx_select=np.random.choice(train_idx, size=num_sample_train_select, replace=False)                                                                    \n",
    "                                \n",
    "                                metadata_select_train=metadata_select[skincon_cols].iloc[train_idx_select]\n",
    "                                metadata_select_skincon_train=metadata_select_train[~metadata_select_train[\"skincon_Vesicle\"].isnull()]\n",
    "                                metadata_select_test=metadata_select[skincon_cols].iloc[test_idx]\n",
    "                                metadata_select_skincon_test=metadata_select_test[~metadata_select_test[\"skincon_Vesicle\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx_select), len(y_select_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6f277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e44640",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample_train_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e10d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc36d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6423d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9640b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx)=657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be840037",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_select_train), len(y_select_test), y_select_train.sum(), y_select_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd50e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample_train_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005072f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list).groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7569b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list).groupby([\"task\", \"is_clean\", \"method\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716af9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f02add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767847c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4f26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignancy\n",
    "Use negative 0.811498\n",
    "Use template 0.812509\n",
    "No reference 0.804630\n",
    "\n",
    "melanoma\n",
    "Use negative 0.907219\n",
    "Use template 0.877861\n",
    "No reference 0.832318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ca981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in concept_dict.items():\n",
    "    print(key+\":\",\", \".join(value[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df=pd.DataFrame(record_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ba191",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df.groupby([\"task\", \"is_clean\", \"method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666741a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(record_all_list, f=log_dir/\"experiment_results\"/\"cbm_complete_230501.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(log_dir/\"experiment_results\"/\"cbm_complete_230501.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(record_all_list, f=log_dir/\"experiment_results\"/\"cbm_complete_230513.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6179975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list=torch.load(log_dir/\"experiment_results\"/\"cbm_complete_230501.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a33a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#record_all_df[record_all_df[\"method\"].str.contains(\"skincon_manual\")].groupby([\"task\", \"is_clean\", \"method\", \"num_concept\"]).mean()\n",
    "#record_all_df[record_all_df[\"method\"].str.contains(\"skincon_manual\")].groupby([\"task\", \"is_clean\", \"method\", \"num_sample_train\"]).mean()\n",
    "#record_all_df[record_all_df[\"method\"].str.contains(\"automatic_skincon_monet\")]\n",
    "#record_all_df[record_all_df[\"method\"].str.contains(\"automatic_skincon_monet\")].groupby([\"task\", \"is_clean\", \"method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a05b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list=torch.load(f=log_dir/\"experiment_results\"/\"cbm_result.pt\")\n",
    "record_all_list_new=torch.load(f=log_dir/\"experiment_results\"/\"cbm_result_new.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(record_all_list, f=log_dir/\"cbm.result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa702d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(record_all_list)[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /System/Library/Fonts/Supplemental ~/.local/share/fonts/\n",
    "# rm -fr ~/.cache/matplotlib\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.edgecolor']='1.0'\n",
    "plt.rcParams['legend.framealpha']=0\n",
    "\n",
    "# https://github.com/dsc/colorbrewer-python/blob/master/colorbrewer.py\n",
    "\n",
    "Set1 = {\n",
    "    3: [[228,26,28], [55,126,184], [77,175,74]],\n",
    "    4: [[228,26,28], [55,126,184], [77,175,74], [152,78,163]],\n",
    "    5: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0]],\n",
    "    6: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51]],\n",
    "    7: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40]],\n",
    "    8: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191]],\n",
    "    9: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191], [153,153,153]],\n",
    "}\n",
    "\n",
    "Paired = {\n",
    "    3: [(166,206,227), [31,120,180], [178,223,138]],\n",
    "    4: [[166,206,227], [31,120,180], [178,223,138], [51,160,44]],\n",
    "    5: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153]],\n",
    "    6: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28]],\n",
    "    7: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111]],\n",
    "    8: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0]],\n",
    "    9: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214]],\n",
    "    10: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154]],\n",
    "    11: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153]],\n",
    "    12: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153], [177,89,40]]\n",
    "}\n",
    "\n",
    "color_qual_7=['#F53345',\n",
    "            '#87D303',\n",
    "            '#04CBCC',\n",
    "            '#8650CD',\n",
    "            (160/256, 95/256, 0),\n",
    "            '#F5A637',              \n",
    "            '#DBD783',            \n",
    "             ]\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_method_name(method_name):\n",
    "    if method_name==\"automatic_monet_full\":\n",
    "        short_name=\"MONET+CBM (Curated)\"\n",
    "    elif method_name==\"automatic_curated_monet_full\":\n",
    "        short_name=\"MONET+CBM (Curated)\"       \n",
    "    elif method_name==\"automatic_curated_vanilla_full\":\n",
    "        short_name=\"CLIP+CBM\"               \n",
    "    elif method_name==\"automatic_skincon_monet_full\":\n",
    "        short_name=\"MONET+CBM (SkinCon)\"   \n",
    "    elif method_name==\"skincon_manual\":\n",
    "        short_name=\"Manual Label (SkinCon)\"\n",
    "    elif method_name==\"skincon_manual_full\":\n",
    "        short_name=\"Manual Label (SkinCon)\"        \n",
    "    elif method_name==\"resnet\":\n",
    "        short_name=\"Supervised (ResNet-50)\"\n",
    "    elif method_name==\"resnet_freeze_backbone\":\n",
    "        short_name=\"Linear probing (ResNet-50)\"\n",
    "    elif method_name==\"automatic_vanilla_full\":\n",
    "        short_name=\"CLIP+CBM\"\n",
    "        \n",
    "    return short_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac35b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_all_list=torch.load(f=log_dir/\"experiment_results\"/\"cbm_complete_new.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636028dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e497c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list=torch.load(f=log_dir/\"experiment_results\"/\"cbm_complete_230513.pt\", \n",
    "                           map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51319b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df=pd.DataFrame(record_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225eccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df[record_all_df[\"method\"]==\"automatic_skincon_monet_full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df[record_all_df[\"method\"]==\"skincon_manual_full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd612746",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "\n",
    "main_method_list=[\"automatic_curated_monet_full\", \n",
    "                  \"skincon_manual_full\", \n",
    "                  \"resnet\", \n",
    "                  \"resnet_freeze_backbone\", \n",
    "                  \"automatic_curated_vanilla_full\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3*10, 3*(3 + 2.5 + 4 + 3 + 0.35*3)))\n",
    "\n",
    "box1 = gridspec.GridSpec(4,1,\n",
    "                         height_ratios=[3, 2.5, 4, 3],\n",
    "                         wspace=0.0,\n",
    "                         hspace=0.35)\n",
    "\n",
    "\n",
    "# temp array([  nan, 0.02 , 0.01 , 0.005])\n",
    "# alpha array([0.001 , 0.0001,    nan])\n",
    "alpha=0.001\n",
    "temp=0.02\n",
    "\n",
    "axd={}\n",
    "for idx1, stage in enumerate([\"overview\", \"skincon\", \"performance\", \"weight\"]):\n",
    "    if stage==\"overview\":\n",
    "        plot_key=stage\n",
    "        ax=plt.Subplot(fig, box1[idx1])\n",
    "        fig.add_subplot(ax) \n",
    "        axd[plot_key]=ax\n",
    "    elif stage==\"empty\":\n",
    "        plot_key=stage\n",
    "        ax=plt.Subplot(fig, box1[idx1])\n",
    "        fig.add_subplot(ax) \n",
    "        axd[plot_key]=ax        \n",
    "    elif stage==\"performance\":\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 4,\n",
    "                        subplot_spec=box1[idx1], \n",
    "                        width_ratios=[0.1, 1, 0.1, 1], wspace=0., hspace=0.)        \n",
    "        for idx2, task in enumerate([\"empty_malignancy\", \"malignancy\", \"empty_melanoma\", \"melanoma\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{task}\"\n",
    "            ax=plt.Subplot(fig, box2[idx2])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[plot_key]=ax  \n",
    "            \n",
    "    elif stage==\"weight\":\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 4,\n",
    "                        subplot_spec=box1[idx1], \n",
    "                        width_ratios=[0.15, 1, 0.15, 1], wspace=0.1, hspace=0.)        \n",
    "        for idx2, task in enumerate([\"empty_malignancy\", \"malignancy\", \"empty_melanoma\", \"melanoma\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{task}\"\n",
    "            ax=plt.Subplot(fig, box2[idx2])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[plot_key]=ax  \n",
    "            \n",
    "    elif stage==\"skincon\":\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 8,\n",
    "                        subplot_spec=box1[idx1], width_ratios=[0.15, 1, 0.15, 1,     0.27, 1, 0.15, 1], wspace=0.0, hspace=0.)        \n",
    "        \n",
    "        \n",
    "        for idx2, variable in enumerate([\"empty\", \"malignancy_num_concept\", \"empty1\", \"malignancy_num_sample\", \n",
    "                                         \"empty2\", \"melanoma_num_concept\", \"empty3\", \"melanoma_num_sample\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{variable}\"\n",
    "            ax=plt.Subplot(fig, box2[idx2])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[plot_key]=ax              \n",
    "            \n",
    "        \n",
    "for plot_key in axd.keys():\n",
    "    if 'overview' in plot_key:\n",
    "        axd[plot_key].set_xticks([])\n",
    "        axd[plot_key].set_yticks([])\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            axd[plot_key].spines[axis].set_linewidth(0) \n",
    "            \n",
    "    if 'empty' in plot_key:\n",
    "        axd[plot_key].set_xticks([])\n",
    "        axd[plot_key].set_yticks([])\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            axd[plot_key].spines[axis].set_linewidth(0)           \n",
    "        \n",
    "for idx1, stage in enumerate([\"overview\", \"performance\", \"weight\", \"skincon\"]):\n",
    "    if stage==\"overview\":\n",
    "        plot_key=stage\n",
    "        \n",
    "        axd[plot_key].text(x=-0.0, y=1.0, transform=axd[plot_key].transAxes,\n",
    "                                 s=\"A\", fontsize=35, weight='bold')           \n",
    "\n",
    "    elif stage==\"performance\":   \n",
    "        for idx2, task in enumerate([\"empty_malignancy\", \"malignancy\", \"empty_melanoma\", \"melanoma\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{task}\"\n",
    "            \n",
    "            if task==\"malignancy\" or task==\"melanoma\":\n",
    "                record_all_df_perf=pd.DataFrame(record_all_list)\n",
    "                record_all_df_perf=record_all_df_perf[record_all_df_perf[\"random_seed\"]<20]\n",
    "                record_all_df_perf_filtered=record_all_df_perf[record_all_df_perf[\"is_clean\"]==\"clean_only\"]\n",
    "                record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"method\"].isin(main_method_list)]\n",
    "                record_all_df_perf_filtered=record_all_df_perf_filtered[(~record_all_df_perf_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))|\\\n",
    "                                                             ((record_all_df_perf_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))&(record_all_df_perf_filtered[\"alpha\"]==alpha)&(record_all_df_perf_filtered[\"temp\"]==temp))]\n",
    "                \n",
    "#                 record_all_df_new=pd.DataFrame(record_all_list_new)\n",
    "#                 record_all_df_filtered_new=record_all_df_new[record_all_df_new[\"is_clean\"]==\"clean_only\"]\n",
    "#                 record_all_df_filtered_new=record_all_df_filtered_new[record_all_df_filtered_new[\"method\"]==\"automatic_skincon_monet_full\"]\n",
    "#                 record_all_df_filtered=pd.concat([record_all_df_filtered, record_all_df_filtered_new], axis=0)\n",
    "#                 dsdsdsds\n",
    "                if task==\"malignancy\":\n",
    "#                     dsds\n",
    "                    record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"task\"]==\"malignancy\"]\n",
    "                    axd[plot_key].set_ylim(0.49, 1.01)\n",
    "                elif task==\"melanoma\":\n",
    "                    record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"task\"]==\"melanoma\"]\n",
    "                    axd[plot_key].set_ylim(0.49, 1.01)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "#                 sdsdsd\n",
    "                b=sns.boxplot(x=\"method\", y=\"auc\", \n",
    "                              order=main_method_list,\n",
    "                              width=0.5,\n",
    "                              linewidth=3,\n",
    "                              saturation=1.3,\n",
    "                              boxprops=dict(alpha=.9),\n",
    "                              data=record_all_df_perf_filtered, \n",
    "                            ax=axd[plot_key])\n",
    "                \n",
    "                \n",
    "                sns.swarmplot(x=\"method\", y=\"auc\", \n",
    "                              order=main_method_list,\n",
    "                              color='black', \n",
    "                              alpha=0.8,\n",
    "                              size=9,\n",
    "                              data=record_all_df_perf_filtered, ax=axd[plot_key])\n",
    " \n",
    "\n",
    "                record_all_df_perf_filtered_pvalue=record_all_df_perf_filtered.groupby(\"task\")\\\n",
    "                .apply(lambda x: x.groupby(\"method\")\\\n",
    "                .apply(lambda y: \n",
    "                scipy.stats.ttest_rel(y.set_index('random_seed')[\"auc\"], \n",
    "                x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"], alternative=\"less\").pvalue)).T\n",
    "\n",
    "    \n",
    "                count=0\n",
    "                for method_name in main_method_list[::-1]:\n",
    "#                     continue\n",
    "                    if method_name==\"automatic_curated_monet_full\":\n",
    "                        continue\n",
    "                        \n",
    "                    pvalue_x1=main_method_list.index(\"automatic_curated_monet_full\")\n",
    "                    pvalue_x2=main_method_list.index(method_name)\n",
    "                    \n",
    "                    pvalue_y=record_all_df_perf_filtered[record_all_df_perf_filtered[\"method\"]==\"automatic_curated_monet_full\"][\"auc\"].max()\n",
    "                    pvalue_y_=record_all_df_perf_filtered[record_all_df_perf_filtered[\"method\"]==method_name][\"auc\"].max()\n",
    "                    \n",
    "                    \n",
    "                    print(method_name, record_all_df_perf_filtered_pvalue.loc[method_name][task])\n",
    "                    if record_all_df_perf_filtered_pvalue.loc[method_name][task]<0.001:\n",
    "                        pvalue_str=\"***\"\n",
    "                    elif record_all_df_perf_filtered_pvalue.loc[method_name][task]<0.01:\n",
    "                        pvalue_str=\"**\"\n",
    "                    elif record_all_df_perf_filtered_pvalue.loc[method_name][task]<0.05:\n",
    "                        pvalue_str=\"*\"                        \n",
    "                    else:\n",
    "                        pvalue_str=\"ns\"  \n",
    "                        \n",
    "                    axd[plot_key].text((pvalue_x2), \n",
    "                                       pvalue_y_+0.0035,\n",
    "                             s=pvalue_str, \n",
    "                             fontsize=25,\n",
    "                             ha='center', \n",
    "                             va='bottom', \n",
    "                             color=\"k\")\n",
    "                    count+=1   \n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                    axd[plot_key].plot([pvalue_x1, \n",
    "                                        pvalue_x1, \n",
    "                                        pvalue_x2, \n",
    "                                        pvalue_x2], \n",
    "                                       [pvalue_y+0.013+0.023*(count),\n",
    "                                        pvalue_y+0.013+0.023*(count)+0.005, \n",
    "                                        pvalue_y+0.013+0.023*(count)+0.005, \n",
    "                                        pvalue_y+0.013+0.023*(count)], \n",
    "                                       lw=3, c='black')\n",
    "                      \n",
    "                    \n",
    "\n",
    "                    \n",
    "                print(task, record_all_df_perf_filtered.groupby(\"method\")[\"auc\"].apply(lambda x: {\"mean\": x.mean(),\n",
    "                                                                      \"std\": x.std(),\n",
    "                                                                      \"q3\": x.quantile(q=0.75),                                                                      \n",
    "                                                                      \"median\": x.median(),\n",
    "                                                                      \"q1\": x.quantile(q=0.25),\n",
    "                                                                     }))\n",
    "\n",
    "                if task==\"malignancy\":\n",
    "                    axd[plot_key].set_title(\"Malignancy\", fontsize=30)\n",
    "                if task==\"melanoma\":\n",
    "                    axd[plot_key].set_title(\"Melanoma\", fontsize=30)\n",
    "\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    axd[plot_key].spines[axis].set_linewidth(3)                \n",
    "\n",
    "                if idx2==1: \n",
    "                    axd[plot_key].set_ylabel('Area under the ROC curve', fontsize=25)\n",
    "                if idx2==3: \n",
    "                    axd[plot_key].set_ylabel('')                    \n",
    "\n",
    "                axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "                axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "                axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "                #axd[plot_key].yaxis.grid(True, which='minor', linewidth=2, alpha=0.1)\n",
    "\n",
    "                axd[plot_key].spines['right'].set_visible(False)\n",
    "                axd[plot_key].spines['top'].set_visible(False)                   \n",
    "                axd[plot_key].spines['bottom'].set_visible(False)    \n",
    "\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=25)\n",
    "                axd[plot_key].tick_params(axis='y', which='major', labelsize=25)   \n",
    "\n",
    "                axd[plot_key].tick_params(\n",
    "                    axis='x',          # changes apply to the x-axis\n",
    "                    which='both',      # both major and minor ticks are affected\n",
    "                    bottom=False,\n",
    "                    labelbottom=False,      # ticks along the bottom edge are off\n",
    "                    )            \n",
    "\n",
    "                axd[plot_key].set_xlabel(None)\n",
    "            \n",
    "            if task==\"empty_malignancy\":\n",
    "                axd[plot_key].text(x=-0.05, y=1.02, transform=axd[plot_key].transAxes,\n",
    "                                     s=\"F\", fontsize=35, weight='bold') \n",
    "                \n",
    "            if task==\"malignancy\":\n",
    "                \n",
    "                legend_elements=[Patch(facecolor=plt.rcParams[\"axes.prop_cycle\"].by_key()['color'][method_idx], \n",
    "                                       edgecolor=\"black\", linewidth=2, \n",
    "                                       label=shorten_method_name(method_name)) for method_idx, method_name in enumerate(main_method_list)]\n",
    "                \n",
    "\n",
    "                axd[plot_key].legend(handles=legend_elements, \n",
    "                            ncol=5, \n",
    "                            handlelength=2.5,\n",
    "                            handletextpad=0.4, \n",
    "                            columnspacing=1.3,\n",
    "                            fontsize=23,\n",
    "                            loc='lower center', bbox_to_anchor=(1., -0.1))                   \n",
    "                \n",
    "                #axd[plot_key].set_ylabel('Concepts', fontsize=30)\n",
    "                \n",
    "                \n",
    "            if task==\"empty_melanoma\":\n",
    "                axd[plot_key].text(x=-0.0, y=1.02, transform=axd[plot_key].transAxes,\n",
    "                                     s=\"G\", fontsize=35, weight='bold')  \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    elif stage==\"weight\":  \n",
    "        for idx2, task in enumerate([\"empty_malignancy\", \"malignancy\", \"empty_melanoma\", \"melanoma\"]):\n",
    "            plot_key=f\"{stage}_{task}\"\n",
    "            if task==\"malignancy\" or task==\"melanoma\":\n",
    "                record_all_df_weight=pd.DataFrame(record_all_list)\n",
    "                record_all_df_weight=record_all_df_weight[record_all_df_weight[\"random_seed\"]<20]\n",
    "                record_all_df_weight_filtered=record_all_df_weight[record_all_df_weight[\"is_clean\"]==\"clean_only\"]\n",
    "                record_all_df_weight_filtered=record_all_df_weight_filtered[(record_all_df_weight_filtered[\"method\"]==\"automatic_curated_monet_full\")&(record_all_df_weight_filtered[\"alpha\"]==alpha)&(record_all_df_weight_filtered[\"temp\"]==temp)]\n",
    "                \n",
    "#                 record_all_df_filtered=record_all_df_filtered[record_all_df_filtered[\"method\"].isin(main_method_list)]\n",
    "#                 record_all_df_filtered=record_all_df_filtered[(~record_all_df_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))|\\\n",
    "#                                                              ((record_all_df_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))&(record_all_df_filtered[\"alpha\"]==alpha)&(record_all_df_filtered[\"temp\"]==temp))]                \n",
    "                \n",
    "                #print(record_all_df_filtered[\"alpha\"])\n",
    "\n",
    "                if task==\"malignancy\":\n",
    "                    record_all_df_weight_filtered=record_all_df_weight_filtered[record_all_df_weight_filtered[\"task\"]==\"malignancy\"]\n",
    "                elif task==\"melanoma\":\n",
    "                    record_all_df_weight_filtered=record_all_df_weight_filtered[record_all_df_weight_filtered[\"task\"]==\"melanoma\"]\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "                coef_dict_list=[]\n",
    "                for clf_idx, clf in enumerate(record_all_df_weight_filtered[\"clf\"]):\n",
    "                    for concept_name, coef in zip(concept_list_curated, clf.coef_[0]):\n",
    "                        coef_dict_list.append({\"concept_name\": concept_name,\n",
    "                                               \"coef\": coef,\n",
    "                                               \"clf_idx\": clf_idx\n",
    "                                              })\n",
    "\n",
    "\n",
    "                #pd.DataFrame(coef_dict_list).groupby(\"concept_name\")[\"coef\"].to_csv(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}_{task}.csv\")\n",
    "                print(task, pd.DataFrame(coef_dict_list).groupby(\"concept_name\")[\"coef\"].mean())\n",
    "                \n",
    "                \n",
    "                weight_bar=sns.barplot(y=\"concept_name\", x=\"coef\", \n",
    "                            color=np.array(Paired[12][7])/256,\n",
    "                            edgecolor='black',\n",
    "                            linewidth=2,\n",
    "                            width=0.5,    \n",
    "                            order=['Asymmetry', 'Irregular', 'Erosion',\n",
    "                                       'Black', 'Blue', 'White', 'Brown',\n",
    "                                    'Multiple Colors', 'Tiny', 'Regular'],\n",
    "                            errwidth=5,\n",
    "                                       \n",
    "                            data=pd.DataFrame(coef_dict_list), ax=axd[plot_key])\n",
    "                \n",
    "#                 for container in weight_bar.containers:\n",
    "#                     axd[plot_key].bar_label(container)                \n",
    "                    \n",
    "#                 for p in weight_bar.patches:\n",
    "#                     _x = p.get_x() + p.get_width() / 2\n",
    "#                     _y = p.get_y() + p.get_height()\n",
    "#                     value = '{:.2f}'.format(p.get_height())\n",
    "#                     weight_bar.text(_x, _y, value, ha=\"center\")  \n",
    "                \n",
    "                #rint(axd[plot_key].get_yticks())\n",
    "        \n",
    "#                 bar_labels=[]\n",
    "#                 for concept_name in concept_list_curated:\n",
    "#                     temp=pd.DataFrame(coef_dict_list)\n",
    "#                     temp=temp[temp[\"concept_name\"]==concept_name]\n",
    "                    \n",
    "#                     if temp[\"coef\"].mean()>3:\n",
    "#                         bar_labels.append()\n",
    "#                     else:\n",
    "#                         bar_labels.append(\"\")\n",
    "#                 print(temp, bar_labels)\n",
    "#                 axd[plot_key].bar_label(weight_bar.containers[0], labels=bar_labels, fontsize=20)\n",
    "    \n",
    "                for p, concept_name in zip(weight_bar.patches, ['Asymmetry', 'Irregular', 'Erosion',\n",
    "                                       'Black', 'Blue', 'White', 'Brown',\n",
    "                                    'Multiple Colors', 'Tiny', 'Regular']):\n",
    "                    _x = p.get_x() + p.get_width() / 2\n",
    "                    _y = p.get_y() + p.get_height()\n",
    "                    \n",
    "                    coef_dict_list_df=pd.DataFrame(coef_dict_list)\n",
    "                    coef_dict_list_df=coef_dict_list_df[coef_dict_list_df[\"concept_name\"]==concept_name]\n",
    "                    \n",
    "                    if coef_dict_list_df[\"coef\"].mean()>3:\n",
    "                        value=f\"{coef_dict_list_df['coef'].mean():.2f} (±{1.96*coef_dict_list_df['coef'].std()/ np.sqrt(len(coef_dict_list_df)) :.2f})\"\n",
    "                        axd[plot_key].text(2.8, _y+0.6, value, ha=\"center\", fontsize=20, zorder=100)\n",
    "                    \n",
    "                    #value = '{:.2f}'.format(p.get_height())\n",
    "                    \n",
    "                \n",
    "#                 for c in weight_bar.containers:\n",
    "#                     c_mean=c.datavalues.mean()\n",
    "#                     c_mean=np.round(c_mean,2)\n",
    "#                     ci=1.96*c.datavalues.std()/np.sqrt(len(c.datavalues))\n",
    "#                     ci=np.round(ci,2)\n",
    "                    #axd[plot_key].bar_label(c, labels=[f\"{c_mean:.2f} (±{ci})\"], fontsize=20)\n",
    "\n",
    "    #             sns.boxplot(x=\"method\", y=\"auc\", \n",
    "    #                         data=record_all_df_filtered, \n",
    "    #                         width=0.5,\n",
    "    #                         linewidth=3,\n",
    "    #                         ax=axd[plot_key])\n",
    "    #             sns.swarmplot(x=\"method\", y=\"auc\", \n",
    "    #                           color='black', \n",
    "    #                           alpha=0.8,\n",
    "    #                           size=10,\n",
    "    #                           data=record_all_df_filtered, ax=axd[plot_key])\n",
    "\n",
    "\n",
    "#             if task==\"empty_malignancy\":\n",
    "#                 axd[plot_key].text(x=-0.0, y=1.0, transform=axd[plot_key].transAxes,\n",
    "#                                                          s=\"D\", fontsize=35, weight='bold')\n",
    "#             if task==\"empty_melanoma\":\n",
    "#                 axd[plot_key].text(x=-0.0, y=1.0, transform=axd[plot_key].transAxes,\n",
    "#                                                          s=\"E\", fontsize=35, weight='bold')\n",
    "\n",
    "\n",
    "            if task==\"empty_malignancy\":\n",
    "                axd[plot_key].text(x=-0., y=1.05, transform=axd[plot_key].transAxes,\n",
    "                                     s=\"H\", fontsize=35, weight='bold')              \n",
    "                \n",
    "                #axd[plot_key].set_ylabel('Concepts', fontsize=30)\n",
    "                \n",
    "                \n",
    "            if task==\"empty_melanoma\":\n",
    "                axd[plot_key].text(x=-0.1, y=1.05, transform=axd[plot_key].transAxes,\n",
    "                                     s=\"I\", fontsize=35, weight='bold')    \n",
    "\n",
    "            if task==\"malignancy\":\n",
    "                axd[plot_key].set_title(\"Malignancy\", fontsize=30, pad=20)\n",
    "            if task==\"melanoma\":\n",
    "                axd[plot_key].set_title(\"Melanoma\", fontsize=30, pad=20)\n",
    "\n",
    "            if task==\"malignancy\" or task==\"melanoma\":\n",
    "                if task==\"malignancy\":\n",
    "                    axd[plot_key].set_xlim(-3,3)\n",
    "                elif task==\"melanoma\":\n",
    "                    axd[plot_key].set_xlim(-3,3)\n",
    "                else:\n",
    "                    raise ValueError            \n",
    "            \n",
    "                axd[plot_key].axvline(x=0, ymin=0, ymax=1, color='black', alpha=0.7, linewidth=5, zorder=-5)\n",
    "\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    axd[plot_key].spines[axis].set_linewidth(3)                \n",
    "\n",
    "                axd[plot_key].set_ylabel('Area under the curve', fontsize=25)\n",
    "\n",
    "    #             axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "    #             axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "                axd[plot_key].xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "                axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        \n",
    "                axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                #axd[plot_key].yaxis.grid(True, which='minor', linewidth=2, alpha=0.1)\n",
    "\n",
    "                axd[plot_key].spines['left'].set_visible(False)\n",
    "                axd[plot_key].spines['right'].set_visible(False)\n",
    "                axd[plot_key].spines['top'].set_visible(False)                   \n",
    "                #axd[plot_key].spines['bottom'].set_visible(False)    \n",
    "\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "                axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "                axd[plot_key].tick_params(\n",
    "                    axis='x',          # changes apply to the x-axis\n",
    "                    which='both',      # both major and minor ticks are affected\n",
    "                    top=False,\n",
    "                    labeltop=False,      # ticks along the bottom edge are off                    \n",
    "                    bottom=True,\n",
    "                    labelbottom=True,      # ticks along the bottom edge are off\n",
    "                    )            \n",
    "\n",
    "                axd[plot_key].set_ylabel(None)\n",
    "                axd[plot_key].set_xlabel(\"Coefficients of linear model\", fontsize=25, labelpad=5)\n",
    "                #axd[plot_key].xaxis.set_label_position('top') \n",
    "    elif stage==\"skincon\":       \n",
    "        for idx2, variable in enumerate([\"malignancy_num_concept\", \"malignancy_num_sample\", \n",
    "                                         \"melanoma_num_concept\", \"melanoma_num_sample\", ]):\n",
    "            plot_key=f\"{stage}_{variable}\"    \n",
    "            \n",
    "            record_all_df_skincon=pd.DataFrame(record_all_list)\n",
    "            record_all_df_skincon=record_all_df_skincon[record_all_df_skincon[\"random_seed\"]<20]\n",
    "            record_all_df_skincon_filtered=record_all_df_skincon[record_all_df_skincon[\"is_clean\"]==\"clean_only\"]\n",
    "            record_all_df_skincon_filtered=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"].str.contains(\"skincon\")]\n",
    "            \n",
    "\n",
    "            if variable.startswith(\"malignancy\"):\n",
    "                record_all_df_skincon_filtered=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"task\"]==\"malignancy\"]\n",
    "            elif variable.startswith(\"melanoma\"):\n",
    "                record_all_df_skincon_filtered=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"task\"]==\"melanoma\"]\n",
    "            else:\n",
    "                raise ValueError\n",
    "            \n",
    "            \n",
    "            record_all_df_skincon_filtered_ref=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"]==\"automatic_skincon_monet_full\"]\n",
    "            if variable.endswith(\"num_sample\"):\n",
    "                record_all_df_skincon_filtered_obs=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"]==\"skincon_manual_less_sample\"]\n",
    "                if variable.startswith(\"melanoma\"):\n",
    "                    pass\n",
    "#                     sdsd\n",
    "                record_all_df_skincon_filtered_obs_sample_prop=record_all_df_skincon_filtered_obs.groupby(\"num_sample_train_select\")[\"num_sample_train\"].mean()\n",
    "                record_all_df_skincon_filtered_obs[\"num_sample_train_pseudo\"]=record_all_df_skincon_filtered_obs.apply(lambda x: record_all_df_skincon_filtered_obs_sample_prop[x[\"num_sample_train_select\"]], axis=1)\n",
    "                b=sns.lineplot(x=\"num_sample_train_pseudo\", y=\"auc\", \n",
    "                               color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][1], linewidth=4,\n",
    "                               data=record_all_df_skincon_filtered_obs, ax=axd[plot_key])\n",
    "                if b.legend_ is not None:\n",
    "                    b.legend_.remove()\n",
    "                #axd[plot_key].axhline(y=ref_value, xmin=0, xmax=100000, color='red', alpha=0.7, linewidth=3, zorder=-5)\n",
    "                \n",
    "                \n",
    "                axd[plot_key].scatter(0, record_all_df_skincon_filtered_ref[\"auc\"].mean(), s=300, marker='X', color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0])\n",
    "                print(stage, variable, record_all_df_skincon_filtered_ref[\"auc\"].mean())\n",
    "#                 record_all_df_skincon_filtered_ref_matched=pd.DataFrame(list(itertools.product(record_all_df_skincon_filtered_obs_sample_prop.values, \n",
    "#                                                     record_all_df_skincon_filtered_ref[\"auc\"].values)),\n",
    "#                             columns=[\"num_sample_train_pseudo\", \"auc\"])                \n",
    "#                 b=sns.lineplot(x=\"num_sample_train_pseudo\", y=\"auc\", \n",
    "#                                color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0], linewidth=4, linestyle=\"--\",\n",
    "#                                data=record_all_df_skincon_filtered_ref_matched, ax=axd[plot_key])\n",
    "#                 if b.legend_ is not None:\n",
    "#                     b.legend_.remove()\n",
    "                #axd[plot_key].set_xlim(record_all_df_skincon_filtered_obs[\"num_sample_train_pseudo\"].min(), record_all_df_skincon_filtered_obs[\"num_sample_train_pseudo\"].max())\n",
    "                \n",
    "            elif variable.endswith(\"num_concept\"):\n",
    "                record_all_df_skincon_filtered_obs=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"]==\"skincon_manual_less_concept\"]\n",
    "                b=sns.lineplot(x=\"num_concept\", y=\"auc\", \n",
    "                               color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][1], linewidth=4,\n",
    "                               data=record_all_df_skincon_filtered_obs, ax=axd[plot_key])\n",
    "                if b.legend_ is not None:\n",
    "                    b.legend_.remove()\n",
    "                    \n",
    "                    \n",
    "                axd[plot_key].scatter(48, record_all_df_skincon_filtered_ref[\"auc\"].mean(), s=300, marker='X', color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0])\n",
    "                print(stage, variable, record_all_df_skincon_filtered_ref[\"auc\"].mean())\n",
    "                #sds\n",
    "                #axd[plot_key].axhline(y=ref_value, xmin=0, xmax=100000, color='red', alpha=0.7, linewidth=3, zorder=-5)                    \n",
    "                \n",
    "#                 record_all_df_skincon_filtered_ref_matched=pd.DataFrame(list(itertools.product(record_all_df_skincon_filtered_obs[\"num_concept\"].unique(), \n",
    "#                                                     record_all_df_skincon_filtered_ref[\"auc\"].values)),\n",
    "#                             columns=[\"num_sample_train_pseudo\", \"auc\"])                \n",
    "#                 b=sns.lineplot(x=\"num_sample_train_pseudo\", y=\"auc\", \n",
    "#                                color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0], linewidth=4, linestyle=\"--\",\n",
    "#                                data=record_all_df_skincon_filtered_ref_matched, ax=axd[plot_key])                \n",
    "#                 if b.legend_ is not None:\n",
    "#                     b.legend_.remove()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "#             dsds  \n",
    "#             ref_value=record_all_df_skincon_filtered_ref[record_all_df_skincon_filtered_ref[\"task\"]==\"melanoma\"][\"auc\"].mean()\n",
    "            \n",
    "#             #\n",
    "\n",
    "#             #sns.lineplot(x=\"sample_prop\", y=\"auc\", hue=\"task\", style=\"method\", data=record_all_df_skincon_filtered, ax=axd[plot_key])\n",
    "#             dsdsd\n",
    "\n",
    "\n",
    "#             \n",
    "#             axd[plot_key].set_xlim(0, record_all_df_skincon_filtered[\"num_sample_train\"].max())\n",
    "#                 #axd[plot_key].set_xlim(1-0.2, 11.5)\n",
    "\n",
    "#             record_all_df_skincon_filtered     \n",
    "\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "            axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)    \n",
    "            axd[plot_key].tick_params(axis='y', which='major', labelsize=20)\n",
    "            \n",
    "            if variable.endswith(\"num_concept\"):\n",
    "                axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "                axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "                \n",
    "                \n",
    "                axd[plot_key].set_xlabel(\"Num. of concepts\", fontsize=25)\n",
    "                axd[plot_key].set_xlim(-0.1, 49)\n",
    "                \n",
    "                \n",
    "#                 axd[plot_key].tick_params(\n",
    "#                     axis='y',          # changes apply to the x-axis\n",
    "#                     which='both',      # both major and minor ticks are affected\n",
    "#                     labelleft=False)                \n",
    "                \n",
    "            elif variable==\"num_reference\":\n",
    "                axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "                \n",
    "                \n",
    "                       \n",
    "            elif variable.endswith(\"num_sample\"):\n",
    "                #axd[plot_key].set_xticks([0.05, 0.1 , 0.2 , 0.4 , 0.6 , 0.8 , 1.])\n",
    "                #.set_xticks([2,4,6,8,10])\n",
    "                if variable.startswith(\"malignancy\"):\n",
    "                    axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "                    axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))                \n",
    "                elif variable.startswith(\"malignancy\"):\n",
    "                    axd[plot_key].xaxis.set_major_locator(MultipleLocator(100))\n",
    "                    axd[plot_key].xaxis.set_minor_locator(MultipleLocator(50))                                    \n",
    "                \n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "                \n",
    "                axd[plot_key].set_xlabel(\"Num. of expert-labeled samples\", fontsize=25)#, labelpad=-10)\n",
    "            \n",
    "            if idx2==0:\n",
    "                axd[plot_key].set_ylabel(\"Area under the ROC curve\", fontsize=25)\n",
    "            else:\n",
    "                axd[plot_key].set_ylabel(None)    \n",
    "            \n",
    "                \n",
    "                #axd[plot_key].tick_params(axis='x', which='major', left=False, labelleft=False)\n",
    "                \n",
    "            if variable.startswith(\"malignancy\"):\n",
    "                #axd[plot_key].set_ylim(0.61, 0.98)\n",
    "                #axd[plot_key].set_ylim(0.531, 0.881)\n",
    "                axd[plot_key].set_ylim(0.49, 1.01)\n",
    "                axd[plot_key].set_title(\"Malignancy\", fontsize=25, pad=20)\n",
    "            elif variable.startswith(\"melanoma\"):                \n",
    "                axd[plot_key].set_title(\"Melanoma\", fontsize=25, pad=20)\n",
    "                axd[plot_key].set_ylim(0.49, 1.01)\n",
    "                \n",
    "            if variable.endswith(\"num_sample\"):\n",
    "                if variable.startswith(\"malignancy\"):\n",
    "                    axd[plot_key].set_xlim(left=-50)\n",
    "                elif variable.startswith(\"melanoma\"):    \n",
    "                    axd[plot_key].set_xlim(left=-10)\n",
    "                \n",
    "            if variable.endswith(\"num_concept\"):\n",
    "                axd[plot_key].set_xlim(left=-1)\n",
    "                axd[plot_key].set_xlim(right=50) \n",
    "                \n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(3)                     \n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            axd[plot_key].text(x=-0.15, y=1.05, transform=axd[plot_key].transAxes,\n",
    "                                     s=[\"B\", \"C\", \"D\", \"E\"][idx2], fontsize=35, weight='bold')  \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if idx2==1:\n",
    "                legend_elements=[Line2D([], [], color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0], label=\"MONET+CBM (SkinCon)\", linestyle='None', marker='X', markersize=20),\n",
    "                                 Line2D([0], [0], color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][1], linewidth=10, label=\"Manual Label (SkinCon)\")]\n",
    "                axd[plot_key].legend(handles=legend_elements, \n",
    "                            ncol=2, \n",
    "                            handlelength=3,\n",
    "                            handletextpad=0.6, \n",
    "                            columnspacing=1.5,\n",
    "                            fontsize=23,\n",
    "                            loc='lower center', \n",
    "                            bbox_to_anchor=(1, -0.33)).set_zorder(100)              \n",
    "            \n",
    "            #record_all_df_filtered=record_all_df_filtered[record_all_df_filtered[\"method\"]==\"automatic_monet_full\"]    \n",
    "\n",
    "# fig.savefig(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}.pdf\", bbox_inches='tight')\n",
    "\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.pdf\", bbox_inches='tight')\n",
    "# # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([65, 75, 86, 69, 60, 81,  88, 53, 75, 73])\n",
    "x2  = np.array([77, 98, 92, 77, 65, 77, 100, 73, 93, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x1-x2)/np.std(x1-x2, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered_pvalue=record_all_df_perf_filtered.groupby(\"task\")\\\n",
    ".apply(lambda x: x.groupby(\"method\")\\\n",
    ".apply(lambda y: \n",
    "       \n",
    "    \n",
    "    (\n",
    "        scipy.stats.ttest_rel(y.set_index('random_seed')[\"auc\"], \n",
    "        x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"], alternative=\"less\").pvalue,\n",
    "       \n",
    "        (np.mean(y.set_index('random_seed')[\"auc\"]-x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"]))\\\n",
    "        /(np.std(y.set_index('random_seed')[\"auc\"]-x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"], ddof=1)),\n",
    "    \n",
    "        (np.mean(y.set_index('random_seed')[\"auc\"]-x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"]))\n",
    "    )\n",
    "      \n",
    "      )\n",
    "      \n",
    ").T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered_pvalue.loc[\"automatic_curated_vanilla_full\"][\"melanoma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099d36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd4800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594460d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e55515",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.jpg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.svg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed01160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3f0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1117ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec434485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac62ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dc959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424ef44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d23bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87f756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77e45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a65c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6701d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343a8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc417d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7480e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdcc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b14a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3defc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397da515",
   "metadata": {},
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2d077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa65c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840b87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b4adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72d3e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecf71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2bc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf=pd.DataFrame(record_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf.groupby([\"task\", \"method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca2890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5fec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73f578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6f1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74e661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c267d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ca236",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(coef_dict_list)[\"concept_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.png\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.jpg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.svg\", bbox_inches='tight')\n",
    "fig.savefig(log_dir/\"plots\"/\"main_cbm.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dda13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8052b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_all_df_perf_filtered.groupby([\"task\",\"random_seed\"]).apply(lambda x: \n",
    "# ((x[x[\"method\"]==\"resnet\"][\"auc\"].iloc[0]-x[x[\"method\"]==\"automatic_curated_monet_full\"][\"auc\"].iloc[0])>0)\n",
    "# )\n",
    "\n",
    "record_all_df_perf=pd.DataFrame(record_all_list)\n",
    "record_all_df_perf=record_all_df_perf[record_all_df_perf[\"random_seed\"]<20]\n",
    "record_all_df_perf_filtered=record_all_df_perf[record_all_df_perf[\"is_clean\"]==\"clean_only\"]\n",
    "record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"method\"].isin(main_method_list)]\n",
    "record_all_df_perf_filtered=record_all_df_perf_filtered[(~record_all_df_perf_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))|\\\n",
    "                                             ((record_all_df_perf_filtered[\"method\"].isin([\"automatic_curated_vanilla_full\", \"automatic_curated_monet_full\"]))&(record_all_df_perf_filtered[\"alpha\"]==alpha)&(record_all_df_perf_filtered[\"temp\"]==temp))]\n",
    "\n",
    "record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"task\"]==\"malignancy\"]\n",
    "# record_all_df_perf_filtered=record_all_df_perf_filtered[record_all_df_perf_filtered[\"task\"]==\"melanoma\"]\n",
    "\n",
    "record_all_df_perf_filtered.groupby(\"task\")\\\n",
    ".apply(lambda x: x.groupby(\"method\")\\\n",
    ".apply(lambda y: \n",
    "((y.set_index('random_seed')[\"auc\"] - x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"])>0)\\\n",
    ".sum())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54414e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_all_df_perf_filtered.groupby([\"task\",\"random_seed\"]).apply(lambda x: \n",
    "# ((x[x[\"method\"]==\"resnet\"][\"auc\"].iloc[0]-x[x[\"method\"]==\"automatic_curated_monet_full\"][\"auc\"].iloc[0])>0)\n",
    "# )\n",
    "\n",
    "record_all_df_perf_filtered.groupby(\"task\")\\\n",
    ".apply(lambda x: x.groupby(\"method\")\\\n",
    ".apply(lambda y: \n",
    "1-scipy.stats.ttest_rel(y.set_index('random_seed')[\"auc\"], \n",
    "x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"], alternative=\"greater\").pvalue)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f444fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_all_df_perf_filtered.groupby([\"task\",\"random_seed\"]).apply(lambda x: \n",
    "# ((x[x[\"method\"]==\"resnet\"][\"auc\"].iloc[0]-x[x[\"method\"]==\"automatic_curated_monet_full\"][\"auc\"].iloc[0])>0)\n",
    "# )\n",
    "\n",
    "record_all_df_perf_filtered.groupby(\"task\")\\\n",
    ".apply(lambda x: x.groupby(\"method\")\\\n",
    ".apply(lambda y: \n",
    "scipy.stats.ttest_rel(y.set_index('random_seed')[\"auc\"], \n",
    "x[x[\"method\"]==\"automatic_curated_monet_full\"].set_index(\"random_seed\")[\"auc\"], alternative=\"less\").pvalue)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da926a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebd73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cfc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_obs.plot.scatter(x=\"num_sample\", y=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2849f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_obs.plot.scatter(x=\"sample_prop\", y=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_obs.plot.scatter(x=\"num_sample_train\", y=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8361093",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61890056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 record_all_df_skincon_filtered_ref_matched=pd.DataFrame(list(itertools.product(record_all_df_skincon_filtered_obs_sample_prop.values, \n",
    "#                                                     record_all_df_skincon_filtered_ref[\"auc\"].values)),\n",
    "#                             columns=[\"num_sample_train_pseudo\", \"auc\"])                \n",
    "#                 b=sns.lineplot(x=\"num_sample_train_pseudo\", y=\"auc\", \n",
    "#                                color=plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0], linewidth=4, linestyle=\"--\",\n",
    "#                                data=record_all_df_skincon_filtered_ref_matched, ax=axd[plot_key])\n",
    "#                 if b.legend_ is not None:\n",
    "#                     b.legend_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd45bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4ec19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b00956",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered.groupby([\"method\"]).apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_method_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7848fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74643ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered.groupby(\"method\")[\"auc\"].apply(lambda x: {\"mean\": x.mean(),\n",
    "                                                                      \"std\": x.std(),\n",
    "                                                                      \"q3\": x.quantile(q=0.75),                                                                      \n",
    "                                                                      \"median\": x.median(),\n",
    "                                                                      \"q1\": x.quantile(q=0.25),\n",
    "                                                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c94581",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(coef_dict_list).groupby(\"concept_name\")[\"coef\"].to_csv(log_dir/\"plots\"/f\"main_cbm_a_{alpha:.1e}_t_{temp:.1e}_{task}.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_weight_filtered.groupby(\"method\")[\"auc\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef22eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_perf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b1b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f62f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56884bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc65b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d7b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf27c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"].str.contains(\"skincon\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cd094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8532d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"main_cbm_a={alpha:.1e}_t={temp:.1e}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9392c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71325143",
   "metadata": {},
   "outputs": [],
   "source": [
    "(record_all_df_filtered[\"method\"]!=\"automatic_curated_monet_full\")&\\\n",
    "((record_all_df_filtered[\"method\"]==\"automatic_curated_monet_full\")&(record_all_df_filtered[\"alpha\"]==alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_method_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"automatic_curated_monet_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594c7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_filtered[\"temp\"].unique()\n",
    "# temp array([  nan, 0.02 , 0.01 , 0.005])\n",
    "# alpha array([0.001 , 0.0001,    nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ea074",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_filtered[\"alpha\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55002920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a5c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b37966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12602d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442220ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80458c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df2c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc25e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ba1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"]=cycler('color', [np.array(i)/256 for i in [Paired[12][1], \n",
    "                                                                                Paired[12][3],\n",
    "                                                                                Paired[12][5],\n",
    "                                                                                Paired[12][7],\n",
    "                                                                                Paired[12][9],\n",
    "                                                                                Paired[12][11]\n",
    "                                                                                ]])\n",
    "\n",
    "main_method_list=[\"automatic_monet_full\", \n",
    "                  \"skincon_manual\", \n",
    "                  \"resnet\", \n",
    "                  \"resnet_freeze_backbone\", \n",
    "                  \"automatic_vanilla_full\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3*10, 3*(2.5) + 0.25*3))\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 1,\n",
    "                         height_ratios=[2.5],\n",
    "                         wspace=0.0,\n",
    "                         hspace=0.25)\n",
    "\n",
    "axd={}\n",
    "for idx1, stage in enumerate([\"ablation\"]):\n",
    "            \n",
    "    if stage==\"ablation\":\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 2,\n",
    "                        subplot_spec=box1[idx1], width_ratios=[1, 1], wspace=0.2, hspace=0.)        \n",
    "        for idx2, variable in enumerate([\"num_concept\", \"num_samples\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{variable}\"\n",
    "            ax=plt.Subplot(fig, box2[idx2])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[plot_key]=ax    \n",
    "            \n",
    "for idx1, stage in enumerate([\"ablation\"]):            \n",
    "    if stage==\"ablation\":\n",
    "  \n",
    "        for idx2, variable in enumerate([\"num_concept\",  \"num_samples\"]):\n",
    "#             elif investigation_type==\"statistics\":\n",
    "            plot_key=f\"{stage}_{variable}\"    \n",
    "    \n",
    "            record_all_df=pd.DataFrame(record_all_list)\n",
    "            record_all_df_filtered=record_all_df[record_all_df[\"is_clean\"]==\"clean_only\"]\n",
    "#             sdsd\n",
    "            if variable==\"num_concept\":\n",
    "                record_all_df_filtered=record_all_df_filtered[record_all_df_filtered[\"method\"]==\"automatic_curated_monet_less_concept\"]\n",
    "                b=sns.lineplot(x=\"num_concept\", y=\"auc\", hue=\"task\", data=record_all_df_filtered, ax=axd[plot_key])\n",
    "                b.legend_.remove()\n",
    "                \n",
    "                axd[plot_key].set_xlabel(\"Num. of concepts\", fontsize=30)\n",
    "                axd[plot_key].set_xlim(1-0.2, 11.5)\n",
    "            elif variable==\"num_reference\":\n",
    "                record_all_df_filtered=record_all_df_filtered[record_all_df_filtered[\"method\"]==\"automatic_curated_monet_less_reference\"]\n",
    "                b=sns.lineplot(x=\"num_ref_concepts\", y=\"auc\", hue=\"task\", data=record_all_df_filtered, ax=axd[plot_key])\n",
    "                b.legend_.remove()\n",
    "                \n",
    "                axd[plot_key].set_xlabel(\"Num. of reference concepts\", fontsize=30)\n",
    "                axd[plot_key].set_xlim(-0.2, 5.1)\n",
    "                \n",
    "            elif variable==\"num_samples\":\n",
    "                record_all_df_filtered=record_all_df_filtered[record_all_df_filtered[\"method\"]==\"automatic_curated_monet_less_sample\"]                \n",
    "                b=sns.lineplot(x=\"sample_prop\", y=\"auc\", hue=\"task\", data=record_all_df_filtered, ax=axd[plot_key])\n",
    "                b.legend_.remove()\n",
    "                \n",
    "                axd[plot_key].set_xlabel(\"Proportion of training data\", fontsize=30)\n",
    "            else:\n",
    "                raise ValueError\n",
    "                \n",
    "            axd[plot_key].set_ylim(0.61, 0.94)\n",
    "            \n",
    "                \n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "            axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)    \n",
    "            axd[plot_key].tick_params(axis='y', which='major', labelsize=25)\n",
    "            \n",
    "            if variable==\"num_concept\":\n",
    "                axd[plot_key].xaxis.set_major_locator(MultipleLocator(2))\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=25)                \n",
    "                \n",
    "            elif variable==\"num_reference\":\n",
    "                axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=25)\n",
    "                       \n",
    "            elif variable==\"num_samples\":\n",
    "                #axd[plot_key].set_xticks([0.05, 0.1 , 0.2 , 0.4 , 0.6 , 0.8 , 1.])\n",
    "                #.set_xticks([2,4,6,8,10])\n",
    "                axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "                axd[plot_key].tick_params(axis='x', which='major', labelsize=30)\n",
    "            \n",
    "            if idx2==0:\n",
    "                axd[plot_key].set_ylabel(\"Area under the ROC curve\", fontsize=30)\n",
    "            else:\n",
    "                #axd[plot_key].set_ylabel(None)    \n",
    "                axd[plot_key].set_ylabel(\"Area under the ROC curve\", fontsize=30)\n",
    "            \n",
    "                \n",
    "                #axd[plot_key].tick_params(axis='x', which='major', left=False, labelleft=False)\n",
    "                \n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(3)                     \n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            axd[plot_key].text(x=-0.15, y=1.0, transform=axd[plot_key].transAxes,\n",
    "                                     s=[\"A\", \"B\"][idx2], fontsize=35, weight='bold')               \n",
    "            \n",
    "            if idx2==1:\n",
    "                legend_elements=[Line2D([0], [0], color=np.array(Paired[12][1])/256, linewidth=10, label=\"Malignancy\"),\n",
    "                                 Line2D([0], [0], color=np.array(Paired[12][3])/256, linewidth=10, label=\"Melanoma\")]\n",
    "                axd[plot_key].legend(handles=legend_elements, \n",
    "                            ncol=2, \n",
    "                            handlelength=3,\n",
    "                            handletextpad=0.6, \n",
    "                            columnspacing=1.5,\n",
    "                            fontsize=30,\n",
    "                            loc='lower center', bbox_to_anchor=(-0.15, -0.3))              \n",
    "            \n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm_ablation.png\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm_ablation.jpg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm_ablation.svg\", bbox_inches='tight')\n",
    "# fig.savefig(log_dir/\"plots\"/\"main_cbm_ablation.pdf\", bbox_inches='tight')\n",
    "#plt.close(fig)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_filtered[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa3f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3b086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trianglex = [ 1, 10, 7, 1 ] \n",
    "triangley = [ 2, 8, 4, 2 ]    \n",
    "triangle2x = [ 13, 25, 21, 13]\n",
    "triangle2y = [ 5,  7 , 14, 5 ]\n",
    "\n",
    "plt.figure('Triangles')\n",
    "for i in range(3):\n",
    "    plt.plot(trianglex, triangley, 'o-')\n",
    "plt.fill(trianglex, triangley)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf638e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aff96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "box2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767332f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f95fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.2f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904cdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5858ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8827fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rect in weight_bar:\n",
    "    height = rect.get_height()\n",
    "    print(height)\n",
    "    #plt.text(rect.get_x() + rect.get_width() / 2.0, height, f'{height:.0f}', ha='center', va='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ab30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e5cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b796e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c58ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_ref=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"]==\"automatic_skincon_monet_full\"]\n",
    "if variable.endswith(\"num_sample\"):\n",
    "    record_all_df_skincon_filtered_obs=record_all_df_skincon_filtered[record_all_df_skincon_filtered[\"method\"]==\"skincon_manual_less_sample\"]\n",
    "    record_all_df_skincon_filtered_obs_sample_prop=record_all_df_skincon_filtered_obs.groupby(\"sample_prop\")[\"num_sample_train\"].mean()\n",
    "    record_all_df_skincon_filtered_obs[\"num_sample_train_pseudo\"]=record_all_df_skincon_filtered_obs.apply(lambda x: record_all_df_skincon_filtered_obs_sample_prop[x[\"sample_prop\"]], axis=1)\n",
    "    b=sns.lineplot(x=\"num_sample_train_pseudo\", y=\"auc\", style=\"method\", data=record_all_df_skincon_filtered_obs, ax=axd[plot_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd04f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_obs_sample_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b6be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_ref[\"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_all_df_skincon_filtered_obs_sample_prop.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MONET",
   "language": "python",
   "name": "monet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
