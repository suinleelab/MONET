{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(os.path.abspath(\"revision_analysis.ipynb\"), pythonpath=True)\n",
    "\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import tqdm\n",
    "from IPython import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce635793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /System/Library/Fonts/Supplemental ~/.local/share/fonts/\n",
    "# rm -fr ~/.cache/matplotlib\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.edgecolor']='1.0'\n",
    "plt.rcParams['legend.framealpha']=0\n",
    "\n",
    "# https://github.com/dsc/colorbrewer-python/blob/master/colorbrewer.py\n",
    "\n",
    "Set1 = {\n",
    "    3: [[228,26,28], [55,126,184], [77,175,74]],\n",
    "    4: [[228,26,28], [55,126,184], [77,175,74], [152,78,163]],\n",
    "    5: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0]],\n",
    "    6: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51]],\n",
    "    7: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40]],\n",
    "    8: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191]],\n",
    "    9: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191], [153,153,153]],\n",
    "}\n",
    "\n",
    "Paired = {\n",
    "    3: [(166,206,227), [31,120,180], [178,223,138]],\n",
    "    4: [[166,206,227], [31,120,180], [178,223,138], [51,160,44]],\n",
    "    5: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153]],\n",
    "    6: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28]],\n",
    "    7: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111]],\n",
    "    8: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0]],\n",
    "    9: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214]],\n",
    "    10: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154]],\n",
    "    11: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153]],\n",
    "    12: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153], [177,89,40]]\n",
    "}\n",
    "\n",
    "color_qual_7=['#F53345',\n",
    "            '#87D303',\n",
    "            '#04CBCC',\n",
    "            '#8650CD',\n",
    "            (160/256, 95/256, 0),\n",
    "            '#F5A637',              \n",
    "            '#DBD783',            \n",
    "             ]\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad22418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "import tqdm.contrib.concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(sys.modules[\"MONET.utils.static\"])\n",
    "# from MONET.utils.static import (\n",
    "#     concept_to_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MONET.datamodules.multiplex_datamodule import MultiplexDatamodule\n",
    "from MONET.utils.loader import custom_collate_per_key, dataloader_apply_func\n",
    "from MONET.utils.metrics import skincon_calcualte_auc_all\n",
    "from MONET.utils.static import (\n",
    "    concept_to_prompt,\n",
    "    fitzpatrick17k_disease_label,\n",
    "    fitzpatrick17k_ninelabel,\n",
    "    fitzpatrick17k_threelabel,\n",
    "    skincon_cols,\n",
    ")\n",
    "from MONET.utils.text_processing import generate_prompt_token_from_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314de78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_to_exppath(wandb, log_path=\"/gscratch/cse/chanwkim/MONET_log/train/runs\"):\n",
    "    log_path = Path(log_path)\n",
    "    for experiment in os.listdir(log_path):\n",
    "        if os.path.exists(log_path / experiment / \"wandb\"):\n",
    "            filenames = os.listdir(log_path / experiment / \"wandb\")\n",
    "            filename = [filename for filename in filenames if filename.startswith(\"run\")][0][-8:]\n",
    "            if filename == wandb:\n",
    "                return log_path / experiment\n",
    "    raise RuntimeError(\"not found\")\n",
    "\n",
    "\n",
    "exppath = wandb_to_exppath(\n",
    "    wandb=\"baqqmm5v\", log_path=\"/projects/leelab2/chanwkim/dermatology_datasets/logs/train/runs\"\n",
    ")\n",
    "print([exppath / \"checkpoints\" / ckpt for ckpt in os.listdir(exppath / \"checkpoints/\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7eeb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2912731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataloader(dataset_name):\n",
    "    if dataset_name==\"clinical_fd_clean_nodup\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"clinical_fd_clean_nodup=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()      \n",
    "    \n",
    "    elif dataset_name==\"fitzpatrick17k_clean_threelabel_nodup\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"fitzpatrick17k_clean_threelabel_nodup=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()    \n",
    "    \n",
    "    elif dataset_name==\"fitzpatrick17k_skincon\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"fitzpatrick17k_skincon=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()\n",
    "        \n",
    "    elif dataset_name==\"ddi\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"ddi=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()  \n",
    "        \n",
    "    elif dataset_name==\"ddiskincon\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"ddiskincon=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()          \n",
    "        \n",
    "    elif dataset_name==\"isic\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"isic=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()  \n",
    "\n",
    "        \n",
    "    elif dataset_name==\"derm7pt_derm\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"derm7pt_derm=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()     \n",
    "        \n",
    "        dataloader = dm.test_dataloader()           \n",
    "        \n",
    "    elif dataset_name==\"allpubmedtextbook\":\n",
    "        cfg_dm = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"multiplex.yaml\")\n",
    "        # cfg.data_dir=\"/scr/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.data_dir = \"/sdata/chanwkim/dermatology_datasets\"\n",
    "        cfg_dm.dataset_name_test = \"pubmed=all,textbook=all\"\n",
    "        cfg_dm.split_seed = 42\n",
    "\n",
    "        dm = hydra.utils.instantiate(cfg_dm)\n",
    "        dm.setup()\n",
    "        \n",
    "        dataloader = dm.test_dataloader()   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "    return {\"dataloader\": dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup\", \"fitzpatrick17k_clean_threelabel_nodup\", \"fitzpatrick17k_skincon\", \"ddi\", \"ddiskincon\", \"isic\", \"allpubmedtextbook\"]:\n",
    "    variable_dict.setdefault(dataset_name, {})\n",
    "    variable_dict[dataset_name].update(setup_dataloader(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"clinical_fd_clean_nodup\", \"isic\", \"derm7pt_derm\", \"allpubmedtextbook\"]:\n",
    "    variable_dict.setdefault(dataset_name, {})\n",
    "    variable_dict[dataset_name].update(setup_dataloader(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "efficientnet_device=\"cuda:6\"\n",
    "efficientnet = torchvision.models.efficientnet_v2_s(\n",
    "    weights=torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    ").to(efficientnet_device)\n",
    "efficientnet.eval()\n",
    "\n",
    "def get_layer_feature(model, feature_layer_name, image):\n",
    "    # image = self.normalize(self.toTensor(img)).unsqueeze(0).to(self.device)\n",
    "    # embedding = torch.zeros(image.shape[0], num_features, 1, 1).to(image.device)\n",
    "    feature_layer = model._modules.get(feature_layer_name)\n",
    "\n",
    "    embedding = []\n",
    "\n",
    "    def copyData(module, input, output):\n",
    "        embedding.append(output.data)\n",
    "\n",
    "    h = feature_layer.register_forward_hook(copyData)\n",
    "    out = model(image.to(image.device))\n",
    "    h.remove()\n",
    "    embedding = embedding[0]\n",
    "    assert embedding.shape[0] == image.shape[0], f\"{embedding.shape[0]} != {image.shape[0]}\"\n",
    "    assert embedding.shape[2] == 1, f\"{embedding.shape[2]} != 1\"\n",
    "    assert embedding.shape[2] == 1, f\"{embedding.shape[3]} != 1\"\n",
    "    return embedding[:, :, 0, 0]\n",
    "\n",
    "def batch_func(batch):\n",
    "    with torch.no_grad():\n",
    "        efficientnet_feature = get_layer_feature(\n",
    "            efficientnet, \"avgpool\", batch[\"image\"].to(efficientnet_device)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"efficientnet_feature\": efficientnet_feature.detach().cpu(),\n",
    "        \"metadata\": batch[\"metadata\"],\n",
    "    }\n",
    "\n",
    "def setup_efficientnet_features(dataset_name, dataloader):\n",
    "    loader_applied = dataloader_apply_func(\n",
    "        dataloader=dataloader,\n",
    "        func=batch_func,\n",
    "        collate_fn=custom_collate_per_key,\n",
    "    )    \n",
    "    efficientnet_feature=loader_applied[\"efficientnet_feature\"].cpu()\n",
    "    efficientnet_metadata=loader_applied[\"metadata\"]\n",
    "    \n",
    "    return {\"efficientnet_feature\":efficientnet_feature, \n",
    "            \"efficientnet_metadata\": efficientnet_metadata}\n",
    "\n",
    "for dataset_name in [\"clinical_fd_clean_nodup\", \"isic\", \"derm7pt_derm\", \"allpubmedtextbook\"]:\n",
    "    print(\"Featurizing...\")\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(setup_efficientnet_features(dataset_name, variable_dict[dataset_name][\"dataloader\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calculate_pca(efficientnet_feature):\n",
    "    pca = PCA(n_components=50, svd_solver=\"auto\")\n",
    "    pca.fit(efficientnet_feature)\n",
    "    efficientnet_feature_pc=pca.transform(efficientnet_feature)\n",
    "    return {\"efficientnet_feature_pc\": efficientnet_feature_pc}\n",
    "\n",
    "for dataset_name in [\"clinical_fd_clean_nodup\", \"isic\", \"derm7pt_derm\", \"allpubmedtextbook\"]:\n",
    "    print(\"Calculating PCA...\")\n",
    "    print(dataset_name)\n",
    "    variable_dict[dataset_name].update(calculate_pca(variable_dict[dataset_name][\"efficientnet_feature\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(variable_dict, \"logs/experiment_results/revision_0813.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_dict= torch.load(\"logs/experiment_results/revision_0813.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f18f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "def get_idx_from_concat_dataset(idx, concat_dataset):\n",
    "    offset=0\n",
    "    assert isinstance(concat_dataset, list)\n",
    "    assert isinstance(concat_dataset[0], torch.utils.data.Dataset)\n",
    "    \n",
    "    for count, dataset in enumerate(concat_dataset):\n",
    "        if idx-offset>=len(dataset):\n",
    "            offset+=len(dataset)\n",
    "            continue\n",
    "        return count, idx-offset\n",
    "\n",
    "def overlap_check(target_features, \n",
    "                  target_dataset,\n",
    "                  ref_features,\n",
    "                  ref_dataset):   \n",
    "\n",
    "    \n",
    "    pca = PCA(n_components=50, svd_solver=\"auto\")\n",
    "    pca.fit(ref_features)\n",
    "    ref_features=pca.transform(ref_features)    \n",
    "    target_features=pca.transform(target_features)    \n",
    "    \n",
    "    \n",
    "    start_idx=0\n",
    "    end_idx=0+500\n",
    "    cut_off=0.9\n",
    "\n",
    "    similarity_matrix=sklearn.metrics.pairwise.cosine_similarity(X=target_features, Y=ref_features)\n",
    "    n_top=5\n",
    "    n_row=((((similarity_matrix[start_idx:end_idx])>cut_off).sum(axis=1))>0).sum()\n",
    "\n",
    "    print('total',((((similarity_matrix)>cut_off).sum(axis=1))>0).sum(), similarity_matrix.shape)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n_row, ncols=n_top+1, figsize=(5,n_row))\n",
    "\n",
    "    row_count=0\n",
    "    for idx_count in range(len(ref_dataset)):\n",
    "        if row_count>=n_row:\n",
    "            break\n",
    "\n",
    "        if idx_count not in range(start_idx,end_idx):\n",
    "            continue\n",
    "\n",
    "\n",
    "#         diff_array_sort=np.sort(1-image_features_f17k_efficientnet_pc_cos[idx_count])\n",
    "#         diff_array_argsort=np.argsort(1-image_features_f17k_efficientnet_pc_cos[idx_count])\n",
    "\n",
    "        similarity_array_argsort=np.argsort(similarity_matrix[idx_count])[::-1]\n",
    "        similarity_array_sort=similarity_matrix[idx_count][similarity_array_argsort]\n",
    "\n",
    "        if similarity_array_sort[0]<=cut_off:\n",
    "            continue       \n",
    "            \n",
    "            \n",
    "        image_target=target_dataset.getitem(idx_count)[\"image\"]\n",
    "        axes[row_count, 0].imshow(image_target.resize((200,200)))\n",
    "\n",
    "        axes[row_count, 0].set_xticks([])\n",
    "        axes[row_count, 0].set_yticks([])    \n",
    "        axes[row_count, 0].set_title(str(idx_count), y=0.6, fontdict={'color': 'red', \"fontsize\":7})\n",
    "\n",
    "        col_count=1\n",
    "        plotted_idx=[]\n",
    "        for similarity_idx, similarity in zip(similarity_array_argsort, similarity_array_sort):\n",
    "            if similarity<=cut_off:\n",
    "                break                        \n",
    "            if col_count>=n_top+1:\n",
    "                break\n",
    "    #         if diff_idx<idx_count:\n",
    "    #             continue\n",
    "            concat_dataset_idx, sample_idx = get_idx_from_concat_dataset(\n",
    "            idx=similarity_idx,\n",
    "            concat_dataset=ref_dataset.datasets\n",
    "            )     \n",
    "            image_ref=ref_dataset.datasets[concat_dataset_idx].getitem(sample_idx)[\"image\"]\n",
    "\n",
    "            plotted_idx.append(similarity_idx)\n",
    "            axes[row_count, col_count].imshow(image_ref.resize((200,200)))\n",
    "\n",
    "            axes[row_count, col_count].set_xticks([])\n",
    "            axes[row_count, col_count].set_yticks([])         \n",
    "\n",
    "            axes[row_count, col_count].set_title(str(similarity_idx)+', '+f\"{similarity:.2f}\", y=0.6, fontdict={'color': 'red', \n",
    "                                                                                                   \"fontsize\":7})\n",
    "            col_count+=1\n",
    "        print(', '.join([str(i) for i in [idx_count]+plotted_idx]))\n",
    "\n",
    "\n",
    "        for col_count_idx in range(col_count, n_top+1):\n",
    "            axes[row_count, col_count_idx].set_xticks([])\n",
    "            axes[row_count, col_count_idx].set_yticks([])                     \n",
    "        row_count+=1 \n",
    "\n",
    "    #     similarity_matrix=variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_feature_norm\"]\\\n",
    "    #     @variable_dict[\"allpubmedtextbook\"][\"efficientnet_feature_norm\"].T    \n",
    "    \n",
    "    \n",
    "overlap_check(target_features=variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_feature\"],\n",
    "              target_dataset=variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset,\n",
    "              ref_features=variable_dict[\"allpubmedtextbook\"][\"efficientnet_feature\"],\n",
    "              ref_dataset=variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_found=pd.read_csv(\"scripts/preprocess/training_duplicate.csv\", names=['target_idx', 1, 2, 3, 4, 5])\n",
    "# ㄴㅇㄴ\n",
    "dup_found[\"target_idx\"]=variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset.metadata_all.iloc[dup_found[\"target_idx\"]].index.values\n",
    "for i in range(1,5+1):\n",
    "    dup_found[i]=dup_found[i].map(lambda x: np.nan if np.isnan(x) else variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset[int(x)][\"metadata\"].name)\n",
    "# dup_found.to_csv(\"data/fitzpatrick17k/training_overlap.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_info=pd.read_csv(\"data/fitzpatrick17k/training_overlap.csv\", index_col=0)\n",
    "duplicate_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_duplicate(duplicate_info,\n",
    "                  target_features, \n",
    "                  target_metadata,\n",
    "                  target_dataset,\n",
    "                  ref_features,\n",
    "                  ref_metadata,\n",
    "                  ref_dataset):\n",
    "\n",
    "    \n",
    "    pca = PCA(n_components=50, svd_solver=\"auto\")\n",
    "    pca.fit(ref_features)\n",
    "    ref_features=pca.transform(ref_features)    \n",
    "    target_features=pca.transform(target_features)    \n",
    "    \n",
    "    cut_off=0.9\n",
    "\n",
    "    similarity_matrix=sklearn.metrics.pairwise.cosine_similarity(X=target_features, Y=ref_features)\n",
    "    n_top=5\n",
    "    n_row=len(duplicate_info)\n",
    "\n",
    "    print('total',((((similarity_matrix)>cut_off).sum(axis=1))>0).sum(), similarity_matrix.shape)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n_row, ncols=n_top+1, figsize=(5,n_row))\n",
    "\n",
    "    row_count=0\n",
    "    for target_idx, row in duplicate_info.iterrows():\n",
    "        \n",
    "        image_target=target_dataset.getitem(target_metadata.index.tolist().index(target_idx))[\"image\"]\n",
    "        axes[row_count, 0].imshow(image_target.resize((200,200)))\n",
    "\n",
    "        axes[row_count, 0].set_xticks([])\n",
    "        axes[row_count, 0].set_yticks([])    \n",
    "        axes[row_count, 0].set_title(str(target_idx)[:5], y=0.6, fontdict={'color': 'red', \"fontsize\":7})\n",
    "\n",
    "        col_count=1\n",
    "        plotted_idx=[]\n",
    "        for ref_idx in row:\n",
    "            if not isinstance(ref_idx, str) and np.isnan(ref_idx):\n",
    "                break            \n",
    "            \n",
    "            \n",
    "            concat_dataset_idx, sample_idx = get_idx_from_concat_dataset(\n",
    "            idx=ref_metadata.index.tolist().index(ref_idx),\n",
    "            concat_dataset=ref_dataset.datasets\n",
    "            )     \n",
    "            image_ref=ref_dataset.datasets[concat_dataset_idx].getitem(sample_idx)[\"image\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             plotted_idx.append(similarity_idx)\n",
    "            axes[row_count, col_count].imshow(image_ref.resize((200,200)))\n",
    "\n",
    "            axes[row_count, col_count].set_xticks([])\n",
    "            axes[row_count, col_count].set_yticks([])         \n",
    "\n",
    "            axes[row_count, col_count].set_title(str(ref_idx)[:5] + \"\\n\" + f\"{similarity_matrix[target_metadata.index.tolist().index(target_idx), ref_metadata.index.tolist().index(ref_idx)]:.2f}\", y=0.6, fontdict={'color': 'red', \n",
    "                                                                                                   \"fontsize\":7})\n",
    "            col_count+=1\n",
    "#         print(', '.join([str(i) for i in [idx_count]+plotted_idx]))\n",
    "\n",
    "\n",
    "        for col_count_idx in range(col_count, n_top+1):\n",
    "            axes[row_count, col_count_idx].set_xticks([])\n",
    "            axes[row_count, col_count_idx].set_yticks([])                     \n",
    "        row_count+=1 \n",
    "        \n",
    "plot_duplicate(duplicate_info=duplicate_info.iloc[:],\n",
    "              target_features=variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_feature\"],\n",
    "              target_metadata=variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_metadata\"],\n",
    "              target_dataset=variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset,\n",
    "              ref_features=variable_dict[\"allpubmedtextbook\"][\"efficientnet_feature\"],\n",
    "              ref_metadata=variable_dict[\"allpubmedtextbook\"][\"efficientnet_metadata\"],\n",
    "              ref_dataset=variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset,\n",
    "             )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05388e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960e127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2bcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259470c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6990628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38368a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a7ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35b1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0672b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06782aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11131e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_found[\"target_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50f966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset.metadata_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff062e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763191cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"https://raw.githubusercontent.com/ISIC-Research/expert-annotation-agreement-data/main/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"exemplar\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a877c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7ff01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be047e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be42fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d1bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae664996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca2dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac90145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989816e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d43c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3736bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d49eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca82781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_feature_pc\"]\n",
    "\n",
    "b=variable_dict[\"allpubmedtextbook\"][\"efficientnet_feature_pc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2485171",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(a).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd863b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59077d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def30a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f794740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730babe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict[\"clinical_fd_clean_nodup\"][\"efficientnet_feature_norm\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cdf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e7e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220bb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_max=similarity_matrix.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb481dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_max_sorted=pd.DataFrame(\n",
    "    {\n",
    "        \"max_value\":similarity_matrix_max.values,\n",
    "        \"ref_idx\": similarity_matrix_max.indices.numpy()\n",
    "    }).sort_values(\"max_value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_matrix_max_sorted=sim_matrix_max_sorted.astype({\"ref_idx\": np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8660b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_max_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdace3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_max_sorted[sim_matrix_max_sorted[\"max_value\"]>0.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (target_idx, row) in enumerate(similarity_matrix_max_sorted[similarity_matrix_max_sorted[\"max_value\"]>0.9].iterrows()):\n",
    "    print(row)\n",
    "    if idx>10:\n",
    "        break\n",
    "    max_val=row[\"max_value\"]\n",
    "    ref_idx=row[\"ref_idx\"]\n",
    "    \n",
    "    print(target_idx, ref_idx, max_val)\n",
    "\n",
    "\n",
    "    image_target=variable_dict[\"clinical_fd_clean_nodup\"][\"dataloader\"].dataset.getitem(target_idx)[\"image\"]        \n",
    "\n",
    "    concat_dataset_idx, sample_idx = get_idx_from_concat_dataset(\n",
    "        idx=int(ref_idx),\n",
    "        concat_dataset=variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset.datasets\n",
    "    )     \n",
    "    image_ref=variable_dict[\"allpubmedtextbook\"][\"dataloader\"].dataset.datasets[concat_dataset_idx].getitem(sample_idx)[\"image\"]        \n",
    "\n",
    "\n",
    "    display(image_target.resize((100,100)))\n",
    "    display(image_ref.resize((100,100)))\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_max_sorted[similarity_matrix_max_sorted[\"max_value\"]>0.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1224ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
